{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import io\n",
    "import subprocess\n",
    "import os\n",
    "\n",
    "from tensorflow.compat.v1.keras import layers\n",
    "import tensorflow.compat.v1 as tf\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from tf_graph_util import convert_variables_to_constants\n",
    "from lstm import create_lstm\n",
    "\n",
    "from seq2seq import create_seq2seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "RANDOM_SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "def benchmark_model(model, cmd=None):\n",
    "    bench_path = f\"{model.name}_benchmark.txt\"\n",
    "    if not os.path.exists(f\"{model.name}.pbtxt\") and not os.path.exists(bench_path):\n",
    "        if not os.path.exists(f\"{model.name}.pbtxt\"):\n",
    "            print(\"Saving model...\")\n",
    "#             tf.keras.backend.clear_session()\n",
    "            sess = tf.keras.backend.get_session()\n",
    "    #         output_graph_def = tf.graph_util.convert_variables_to_constants(\n",
    "            output_graph_def = convert_variables_to_constants(\n",
    "                sess,\n",
    "                sess.graph.as_graph_def(),\n",
    "                [node.op.name for node in model.outputs])\n",
    "            tf.io.write_graph(output_graph_def, './', f'{model.name}.pbtxt')\n",
    "        else:\n",
    "            print(\"Retrieving saved model.\")\n",
    "    \n",
    "    \n",
    "        if not os.path.exists(bench_path):\n",
    "            if not cmd:\n",
    "                input_shape = f\"1,{','.join(str(dim) for dim in model.input.shape[1:])}\"\n",
    "                cmd = f'../tensorflow/bazel-bin/tensorflow/tools/benchmark/benchmark_model --graph={model.name}.pbtxt --input_layer=\"{model.input.name}\" --input_layer_shape=\"{input_shape}\" --output_layer=\"{model.output.name}\"'\n",
    "                print(cmd)\n",
    "            print(\"Running benchmark...\")\n",
    "            benchmark = subprocess.run([cmd], stderr=subprocess.PIPE, shell=True)\n",
    "            print(\"Done.\")\n",
    "\n",
    "            output = benchmark.stderr.decode('unicode_escape')\n",
    "            split_output = output[output.find('Run Order'):output.find('Top by Computation Time')].split('\\n')\n",
    "\n",
    "            with open(bench_path, 'w') as f:\n",
    "                f.write(\"\\n\".join(split_output[1:-2]))\n",
    "        else:\n",
    "            print(\"Retrieving saved benchmark results.\")\n",
    "    else:\n",
    "        print(\"Retrieving saved model and benchmark results.\")\n",
    "    \n",
    "    f = open(bench_path)\n",
    "    benchmark = pd.read_csv(f, sep=\"\\t\").rename(columns=lambda x: x.strip())\n",
    "    benchmark = benchmark.drop(benchmark.columns[0], axis=1)\n",
    "    benchmark['name'] = benchmark['[Name]'].apply(lambda x: x.split('/')[0])\n",
    "    return benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_layer_features(model):\n",
    "    layers = pd.DataFrame()\n",
    "    layers['name'] = pd.Series([layer.name for layer in model.layers])\n",
    "    \n",
    "#     input_dims = {layer.name: [dim.value for dim in layer.input.shape.dims] for layer in model.layers}\n",
    "    \n",
    "#     layers['input_shape'] = pd.Series([[dim.value for dim in layer.input.shape.dims] for layer in model.layers])\n",
    "#     layers['output_shape'] = pd.Series([[dim.value for dim in layer.output.shape.dims] for layer in model.layers])\n",
    "    layers['input_shape'] = pd.Series([layer.input_shape for layer in model.layers])\n",
    "    layers['output_shape'] = pd.Series([layer.output_shape for layer in model.layers])\n",
    "\n",
    "    features = ['units','filters','activation','strides','kernel_size']\n",
    "    for feature in features:\n",
    "        layers[feature] = pd.Series(\n",
    "            [layer.get_config()[feature] if feature in layer.get_config() else None for layer in model.layers])\n",
    "    return layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def join_benchmark(features, benchmark):\n",
    "    speed = benchmark[['name', '[avg ms]']].groupby('name').sum()\n",
    "    mem = benchmark[['name', '[mem KB]']].groupby('name').max()\n",
    "    \n",
    "    return features.join(speed, on='name').join(mem, on='name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def flatten_shape(shape):\n",
    "    if not shape:\n",
    "        return None\n",
    "    \n",
    "    def reduce(tup):\n",
    "        acc = 1\n",
    "        for val in tup:\n",
    "            if val:\n",
    "                acc *= val\n",
    "        return acc\n",
    "    \n",
    "    if isinstance(shape, list):\n",
    "        return sum(reduce(tup) for tup in shape)\n",
    "    \n",
    "    return reduce(shape)\n",
    "\n",
    "\n",
    "def clean(data, inference=False):\n",
    "    if inference:\n",
    "        cleaned = pd.get_dummies(data, columns=['activation'], dummy_na=True)\n",
    "    else:\n",
    "        cleaned = pd.get_dummies(\n",
    "            data.dropna(subset=['[avg ms]', '[mem KB]']), columns=['activation'], dummy_na=True)\n",
    "    \n",
    "    for activation in ['selu', 'elu', 'softmax', 'softplus', 'softsign', 'relu', 'tanh', 'sigmoid', 'hard_sigmoid', 'exponential', 'linear']:\n",
    "        col = f\"activation_{activation}\"\n",
    "        if col not in cleaned.columns:\n",
    "            cleaned[col] = pd.Series(0)\n",
    "    \n",
    "\n",
    "    cleaned['input_size'] = cleaned['input_shape'].apply(flatten_shape)\n",
    "    cleaned['output_size'] = cleaned['output_shape'].apply(flatten_shape)\n",
    "    cleaned['stride_size'] = cleaned['strides'].apply(flatten_shape)\n",
    "    cleaned['kernel_size'] = cleaned['kernel_size'].apply(flatten_shape)\n",
    "\n",
    "    return cleaned.fillna(-1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rf_regression_model(data, column):\n",
    "    X = data.drop(['name', '[avg ms]', '[mem KB]', 'input_shape', 'output_shape', 'strides'], axis=1)  # Features\n",
    "    y = data[column]  # Labels\n",
    "\n",
    "    # Split dataset into training set and test set\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.3, random_state = RANDOM_SEED) # 70% training and 30% test\n",
    "\n",
    "    # Instantiate model with 1000 decision trees\n",
    "    rf = RandomForestRegressor(n_estimators = 1000, random_state = RANDOM_SEED)\n",
    "    # Train the model on training data\n",
    "    rf.fit(X_train, y_train);\n",
    "\n",
    "    return rf, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.svm import LinearSVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "\n",
    "def stacked_regression_model(data, column):\n",
    "\n",
    "    X = data.drop(['name', '[avg ms]', '[mem KB]', 'input_shape', 'output_shape', 'strides'], axis=1)  # Features\n",
    "    y = data[column]  # Labels\n",
    "\n",
    "    estimators = [\n",
    "        ('rf', RandomForestRegressor(n_estimators=1000, random_state=RANDOM_SEED)),\n",
    "        ('lr', RidgeCV()),\n",
    "        ('svr', LinearSVR(random_state=42)),\n",
    "        \n",
    "    ]\n",
    "    reg = StackingRegressor(\n",
    "        estimators=estimators,\n",
    "#         final_estimator=RandomForestRegressor(n_estimators=1000, random_state=RANDOM_SEED)\n",
    "    )\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "    \n",
    "    reg.fit(X_train, y_train).score(X_test, y_test)\n",
    "    \n",
    "    return reg, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "def stacked_regression_model_2(data, column):\n",
    "\n",
    "    X = data.drop(['name', '[avg ms]', '[mem KB]', 'input_shape', 'output_shape', 'strides'], axis=1)  # Features\n",
    "    y = data[column]  # Labels\n",
    "    \n",
    "    poly = Pipeline([\n",
    "        ('poly', PolynomialFeatures(degree=5)),\n",
    "        ('linear', LinearRegression(fit_intercept=False))\n",
    "    ])\n",
    "\n",
    "    estimators = [\n",
    "        ('poly', poly),\n",
    "        ('lr', RidgeCV()),\n",
    "        ('svr', LinearSVR(random_state=42)),\n",
    "        \n",
    "    ]\n",
    "    reg = StackingRegressor(\n",
    "        estimators=estimators,\n",
    "#         final_estimator=RandomForestRegressor(n_estimators=1000, random_state=RANDOM_SEED)\n",
    "    )\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "    \n",
    "    reg.fit(X_train, y_train).score(X_test, y_test)\n",
    "    \n",
    "    return reg, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/brian/anaconda/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session() # IMPORTANT for layer names to match up.\n",
    "model = tf.keras.applications.vgg16.VGG16(\n",
    "    include_top=True,\n",
    "    weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving saved model and benchmark results.\n"
     ]
    }
   ],
   "source": [
    "benchmark = benchmark_model(model)\n",
    "features = get_layer_features(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vgg_df = join_benchmark(features, benchmark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving saved model and benchmark results.\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session() # IMPORTANT for layer names to match up.\n",
    "tf.keras.backend.set_learning_phase(0)\n",
    "inception = tf. keras.applications.inception_v3.InceptionV3(\n",
    "    include_top=True, weights='imagenet')\n",
    "inception_benchmark = benchmark_model(inception)\n",
    "inception_features = get_layer_features(inception)\n",
    "inception_df = join_benchmark(inception_features, inception_benchmark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # lstm.summary()\n",
    "\n",
    "# tf.keras.backend.clear_session() # IMPORTANT for layer names to match up.\n",
    "\n",
    "# lstm = create_lstm()\n",
    "\n",
    "# # tf.keras.backend.set_learning_phase(0)\n",
    "# lstm_benchmark = benchmark_model(lstm)\n",
    "# lstm_features = get_layer_features(lstm)\n",
    "# lstm_df = join_benchmark(lstm_features, lstm_benchmark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>input_shape</th>\n",
       "      <th>output_shape</th>\n",
       "      <th>units</th>\n",
       "      <th>filters</th>\n",
       "      <th>activation</th>\n",
       "      <th>strides</th>\n",
       "      <th>kernel_size</th>\n",
       "      <th>[avg ms]</th>\n",
       "      <th>[mem KB]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>batch_normalization_28</td>\n",
       "      <td>(None, 35, 35, 96)</td>\n",
       "      <td>(None, 35, 35, 96)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>activation_35</td>\n",
       "      <td>(None, 17, 17, 128)</td>\n",
       "      <td>(None, 17, 17, 128)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.849</td>\n",
       "      <td>147.968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>conv2d_89</td>\n",
       "      <td>(None, 8, 8, 2048)</td>\n",
       "      <td>(None, 8, 8, 448)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>448.0</td>\n",
       "      <td>linear</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>activation_84</td>\n",
       "      <td>(None, 8, 8, 192)</td>\n",
       "      <td>(None, 8, 8, 192)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.719</td>\n",
       "      <td>49.152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>batch_normalization_45</td>\n",
       "      <td>(None, 17, 17, 160)</td>\n",
       "      <td>(None, 17, 17, 160)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>activation_61</td>\n",
       "      <td>(None, 17, 17, 192)</td>\n",
       "      <td>(None, 17, 17, 192)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1.203</td>\n",
       "      <td>221.952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>mixed10</td>\n",
       "      <td>[(None, 8, 8, 320), (None, 8, 8, 768), (None, ...</td>\n",
       "      <td>(None, 8, 8, 2048)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.159</td>\n",
       "      <td>524.288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>batch_normalization_15</td>\n",
       "      <td>(None, 35, 35, 64)</td>\n",
       "      <td>(None, 35, 35, 64)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>batch_normalization_84</td>\n",
       "      <td>(None, 8, 8, 192)</td>\n",
       "      <td>(None, 8, 8, 192)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>max_pooling2d_2</td>\n",
       "      <td>(None, 35, 35, 288)</td>\n",
       "      <td>(None, 17, 17, 288)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>None</td>\n",
       "      <td>0.340</td>\n",
       "      <td>332.928</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       name  \\\n",
       "91   batch_normalization_28   \n",
       "106           activation_35   \n",
       "280               conv2d_89   \n",
       "278           activation_84   \n",
       "137  batch_normalization_45   \n",
       "207           activation_61   \n",
       "310                 mixed10   \n",
       "42   batch_normalization_15   \n",
       "274  batch_normalization_84   \n",
       "99          max_pooling2d_2   \n",
       "\n",
       "                                           input_shape         output_shape  \\\n",
       "91                                  (None, 35, 35, 96)   (None, 35, 35, 96)   \n",
       "106                                (None, 17, 17, 128)  (None, 17, 17, 128)   \n",
       "280                                 (None, 8, 8, 2048)    (None, 8, 8, 448)   \n",
       "278                                  (None, 8, 8, 192)    (None, 8, 8, 192)   \n",
       "137                                (None, 17, 17, 160)  (None, 17, 17, 160)   \n",
       "207                                (None, 17, 17, 192)  (None, 17, 17, 192)   \n",
       "310  [(None, 8, 8, 320), (None, 8, 8, 768), (None, ...   (None, 8, 8, 2048)   \n",
       "42                                  (None, 35, 35, 64)   (None, 35, 35, 64)   \n",
       "274                                  (None, 8, 8, 192)    (None, 8, 8, 192)   \n",
       "99                                 (None, 35, 35, 288)  (None, 17, 17, 288)   \n",
       "\n",
       "     units  filters activation strides kernel_size  [avg ms]  [mem KB]  \n",
       "91     NaN      NaN       None    None        None     0.007     0.000  \n",
       "106    NaN      NaN       relu    None        None     0.849   147.968  \n",
       "280    NaN    448.0     linear  (1, 1)      (1, 1)     0.002     0.000  \n",
       "278    NaN      NaN       relu    None        None     0.719    49.152  \n",
       "137    NaN      NaN       None    None        None     0.005     0.000  \n",
       "207    NaN      NaN       relu    None        None     1.203   221.952  \n",
       "310    NaN      NaN       None    None        None     0.159   524.288  \n",
       "42     NaN      NaN       None    None        None     0.003     0.000  \n",
       "274    NaN      NaN       None    None        None     0.003     0.000  \n",
       "99     NaN      NaN       None  (2, 2)        None     0.340   332.928  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.concat([vgg_df, inception_df])\n",
    "data.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>input_shape</th>\n",
       "      <th>output_shape</th>\n",
       "      <th>units</th>\n",
       "      <th>filters</th>\n",
       "      <th>strides</th>\n",
       "      <th>kernel_size</th>\n",
       "      <th>[avg ms]</th>\n",
       "      <th>[mem KB]</th>\n",
       "      <th>activation_linear</th>\n",
       "      <th>...</th>\n",
       "      <th>activation_elu</th>\n",
       "      <th>activation_softplus</th>\n",
       "      <th>activation_softsign</th>\n",
       "      <th>activation_tanh</th>\n",
       "      <th>activation_sigmoid</th>\n",
       "      <th>activation_hard_sigmoid</th>\n",
       "      <th>activation_exponential</th>\n",
       "      <th>input_size</th>\n",
       "      <th>output_size</th>\n",
       "      <th>stride_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>block1_conv1</td>\n",
       "      <td>(None, 224, 224, 3)</td>\n",
       "      <td>(None, 224, 224, 64)</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.657</td>\n",
       "      <td>12845.056</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>150528</td>\n",
       "      <td>3211264</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>block1_conv2</td>\n",
       "      <td>(None, 224, 224, 64)</td>\n",
       "      <td>(None, 224, 224, 64)</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>9.0</td>\n",
       "      <td>18.123</td>\n",
       "      <td>12845.056</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>3211264</td>\n",
       "      <td>3211264</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>block1_pool</td>\n",
       "      <td>(None, 224, 224, 64)</td>\n",
       "      <td>(None, 112, 112, 64)</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>3.437</td>\n",
       "      <td>3211.264</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>3211264</td>\n",
       "      <td>802816</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>block2_conv1</td>\n",
       "      <td>(None, 112, 112, 64)</td>\n",
       "      <td>(None, 112, 112, 128)</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.181</td>\n",
       "      <td>6422.528</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>802816</td>\n",
       "      <td>1605632</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>block2_conv2</td>\n",
       "      <td>(None, 112, 112, 128)</td>\n",
       "      <td>(None, 112, 112, 128)</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>9.0</td>\n",
       "      <td>13.004</td>\n",
       "      <td>6422.528</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1605632</td>\n",
       "      <td>1605632</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           name            input_shape           output_shape  units  filters  \\\n",
       "1  block1_conv1    (None, 224, 224, 3)   (None, 224, 224, 64)   -1.0     64.0   \n",
       "2  block1_conv2   (None, 224, 224, 64)   (None, 224, 224, 64)   -1.0     64.0   \n",
       "3   block1_pool   (None, 224, 224, 64)   (None, 112, 112, 64)   -1.0     -1.0   \n",
       "4  block2_conv1   (None, 112, 112, 64)  (None, 112, 112, 128)   -1.0    128.0   \n",
       "5  block2_conv2  (None, 112, 112, 128)  (None, 112, 112, 128)   -1.0    128.0   \n",
       "\n",
       "  strides  kernel_size  [avg ms]   [mem KB]  activation_linear  ...  \\\n",
       "1  (1, 1)          9.0     2.657  12845.056                  0  ...   \n",
       "2  (1, 1)          9.0    18.123  12845.056                  0  ...   \n",
       "3  (2, 2)         -1.0     3.437   3211.264                  0  ...   \n",
       "4  (1, 1)          9.0     7.181   6422.528                  0  ...   \n",
       "5  (1, 1)          9.0    13.004   6422.528                  0  ...   \n",
       "\n",
       "   activation_elu  activation_softplus  activation_softsign  activation_tanh  \\\n",
       "1            -1.0                 -1.0                 -1.0             -1.0   \n",
       "2            -1.0                 -1.0                 -1.0             -1.0   \n",
       "3            -1.0                 -1.0                 -1.0             -1.0   \n",
       "4            -1.0                 -1.0                 -1.0             -1.0   \n",
       "5            -1.0                 -1.0                 -1.0             -1.0   \n",
       "\n",
       "   activation_sigmoid  activation_hard_sigmoid  activation_exponential  \\\n",
       "1                -1.0                     -1.0                    -1.0   \n",
       "2                -1.0                     -1.0                    -1.0   \n",
       "3                -1.0                     -1.0                    -1.0   \n",
       "4                -1.0                     -1.0                    -1.0   \n",
       "5                -1.0                     -1.0                    -1.0   \n",
       "\n",
       "   input_size  output_size  stride_size  \n",
       "1      150528      3211264          1.0  \n",
       "2     3211264      3211264          1.0  \n",
       "3     3211264       802816          4.0  \n",
       "4      802816      1605632          1.0  \n",
       "5     1605632      1605632          1.0  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned = clean(data)\n",
    "\n",
    "cleaned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 17.10178814125108\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>units</th>\n",
       "      <th>filters</th>\n",
       "      <th>kernel_size</th>\n",
       "      <th>activation_linear</th>\n",
       "      <th>activation_relu</th>\n",
       "      <th>activation_softmax</th>\n",
       "      <th>activation_nan</th>\n",
       "      <th>activation_selu</th>\n",
       "      <th>activation_elu</th>\n",
       "      <th>activation_softplus</th>\n",
       "      <th>activation_softsign</th>\n",
       "      <th>activation_tanh</th>\n",
       "      <th>activation_sigmoid</th>\n",
       "      <th>activation_hard_sigmoid</th>\n",
       "      <th>activation_exponential</th>\n",
       "      <th>input_size</th>\n",
       "      <th>output_size</th>\n",
       "      <th>stride_size</th>\n",
       "      <th>avg_ms_actual</th>\n",
       "      <th>avg_ms_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>221952</td>\n",
       "      <td>221952</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.182</td>\n",
       "      <td>0.237503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>78400</td>\n",
       "      <td>78400</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.683</td>\n",
       "      <td>0.920930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>221952</td>\n",
       "      <td>55488</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>36992</td>\n",
       "      <td>36992</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.992</td>\n",
       "      <td>0.882680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>221952</td>\n",
       "      <td>221952</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.272</td>\n",
       "      <td>0.237503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>55488</td>\n",
       "      <td>55488</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.005435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>55488</td>\n",
       "      <td>55488</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.005435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>55488</td>\n",
       "      <td>55488</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.005435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>55488</td>\n",
       "      <td>55488</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.654</td>\n",
       "      <td>0.911988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>55488</td>\n",
       "      <td>55488</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.546</td>\n",
       "      <td>0.911988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>78400</td>\n",
       "      <td>78400</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.003876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>235200</td>\n",
       "      <td>78400</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>36992</td>\n",
       "      <td>36992</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.868</td>\n",
       "      <td>0.882680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>24576</td>\n",
       "      <td>24576</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.089</td>\n",
       "      <td>0.924709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>117600</td>\n",
       "      <td>117600</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.043</td>\n",
       "      <td>1.366511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>55488</td>\n",
       "      <td>55488</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.999</td>\n",
       "      <td>0.911988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>352800</td>\n",
       "      <td>78400</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.014869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>55488</td>\n",
       "      <td>55488</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.002422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>55488</td>\n",
       "      <td>55488</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>81920</td>\n",
       "      <td>12288</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.003071</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     units  filters  kernel_size  activation_linear  activation_relu  \\\n",
       "228   -1.0     -1.0         -1.0                  0                0   \n",
       "89    -1.0     -1.0         -1.0                  0                1   \n",
       "197   -1.0    192.0          1.0                  1                0   \n",
       "111   -1.0     -1.0         -1.0                  0                1   \n",
       "164   -1.0     -1.0         -1.0                  0                0   \n",
       "158   -1.0     -1.0         -1.0                  0                0   \n",
       "190   -1.0     -1.0         -1.0                  0                0   \n",
       "212   -1.0     -1.0         -1.0                  0                0   \n",
       "214   -1.0     -1.0         -1.0                  0                1   \n",
       "162   -1.0     -1.0         -1.0                  0                1   \n",
       "78    -1.0     -1.0         -1.0                  0                0   \n",
       "18    -1.0     64.0          1.0                  1                0   \n",
       "117   -1.0     -1.0         -1.0                  0                1   \n",
       "256   -1.0     -1.0         -1.0                  0                1   \n",
       "84    -1.0     -1.0         -1.0                  0                1   \n",
       "208   -1.0     -1.0         -1.0                  0                1   \n",
       "64    -1.0     64.0          1.0                  1                0   \n",
       "210   -1.0    192.0          7.0                  1                0   \n",
       "191   -1.0     -1.0         -1.0                  0                0   \n",
       "268   -1.0    192.0          1.0                  1                0   \n",
       "\n",
       "     activation_softmax  activation_nan  activation_selu  activation_elu  \\\n",
       "228                   0               1             -1.0            -1.0   \n",
       "89                    0               0             -1.0            -1.0   \n",
       "197                   0               0             -1.0            -1.0   \n",
       "111                   0               0             -1.0            -1.0   \n",
       "164                   0               1             -1.0            -1.0   \n",
       "158                   0               1             -1.0            -1.0   \n",
       "190                   0               1             -1.0            -1.0   \n",
       "212                   0               1             -1.0            -1.0   \n",
       "214                   0               0             -1.0            -1.0   \n",
       "162                   0               0             -1.0            -1.0   \n",
       "78                    0               1             -1.0            -1.0   \n",
       "18                    0               0             -1.0            -1.0   \n",
       "117                   0               0             -1.0            -1.0   \n",
       "256                   0               0             -1.0            -1.0   \n",
       "84                    0               0             -1.0            -1.0   \n",
       "208                   0               0             -1.0            -1.0   \n",
       "64                    0               0             -1.0            -1.0   \n",
       "210                   0               0             -1.0            -1.0   \n",
       "191                   0               1             -1.0            -1.0   \n",
       "268                   0               0             -1.0            -1.0   \n",
       "\n",
       "     activation_softplus  activation_softsign  activation_tanh  \\\n",
       "228                 -1.0                 -1.0             -1.0   \n",
       "89                  -1.0                 -1.0             -1.0   \n",
       "197                 -1.0                 -1.0             -1.0   \n",
       "111                 -1.0                 -1.0             -1.0   \n",
       "164                 -1.0                 -1.0             -1.0   \n",
       "158                 -1.0                 -1.0             -1.0   \n",
       "190                 -1.0                 -1.0             -1.0   \n",
       "212                 -1.0                 -1.0             -1.0   \n",
       "214                 -1.0                 -1.0             -1.0   \n",
       "162                 -1.0                 -1.0             -1.0   \n",
       "78                  -1.0                 -1.0             -1.0   \n",
       "18                  -1.0                 -1.0             -1.0   \n",
       "117                 -1.0                 -1.0             -1.0   \n",
       "256                 -1.0                 -1.0             -1.0   \n",
       "84                  -1.0                 -1.0             -1.0   \n",
       "208                 -1.0                 -1.0             -1.0   \n",
       "64                  -1.0                 -1.0             -1.0   \n",
       "210                 -1.0                 -1.0             -1.0   \n",
       "191                 -1.0                 -1.0             -1.0   \n",
       "268                 -1.0                 -1.0             -1.0   \n",
       "\n",
       "     activation_sigmoid  activation_hard_sigmoid  activation_exponential  \\\n",
       "228                -1.0                     -1.0                    -1.0   \n",
       "89                 -1.0                     -1.0                    -1.0   \n",
       "197                -1.0                     -1.0                    -1.0   \n",
       "111                -1.0                     -1.0                    -1.0   \n",
       "164                -1.0                     -1.0                    -1.0   \n",
       "158                -1.0                     -1.0                    -1.0   \n",
       "190                -1.0                     -1.0                    -1.0   \n",
       "212                -1.0                     -1.0                    -1.0   \n",
       "214                -1.0                     -1.0                    -1.0   \n",
       "162                -1.0                     -1.0                    -1.0   \n",
       "78                 -1.0                     -1.0                    -1.0   \n",
       "18                 -1.0                     -1.0                    -1.0   \n",
       "117                -1.0                     -1.0                    -1.0   \n",
       "256                -1.0                     -1.0                    -1.0   \n",
       "84                 -1.0                     -1.0                    -1.0   \n",
       "208                -1.0                     -1.0                    -1.0   \n",
       "64                 -1.0                     -1.0                    -1.0   \n",
       "210                -1.0                     -1.0                    -1.0   \n",
       "191                -1.0                     -1.0                    -1.0   \n",
       "268                -1.0                     -1.0                    -1.0   \n",
       "\n",
       "     input_size  output_size  stride_size  avg_ms_actual  avg_ms_pred  \n",
       "228      221952       221952         -1.0          0.182     0.237503  \n",
       "89        78400        78400         -1.0          0.683     0.920930  \n",
       "197      221952        55488          1.0          0.002     0.002323  \n",
       "111       36992        36992         -1.0          0.992     0.882680  \n",
       "164      221952       221952         -1.0          0.272     0.237503  \n",
       "158       55488        55488         -1.0          0.006     0.005435  \n",
       "190       55488        55488         -1.0          0.007     0.005435  \n",
       "212       55488        55488         -1.0          0.006     0.005435  \n",
       "214       55488        55488         -1.0          0.654     0.911988  \n",
       "162       55488        55488         -1.0          0.546     0.911988  \n",
       "78        78400        78400         -1.0          0.005     0.003876  \n",
       "18       235200        78400          1.0          0.002     0.002029  \n",
       "117       36992        36992         -1.0          0.868     0.882680  \n",
       "256       24576        24576         -1.0          1.089     0.924709  \n",
       "84       117600       117600         -1.0          1.043     1.366511  \n",
       "208       55488        55488         -1.0          0.999     0.911988  \n",
       "64       352800        78400          1.0          0.002     0.014869  \n",
       "210       55488        55488          1.0          0.003     0.002422  \n",
       "191       55488        55488         -1.0          0.005     0.005435  \n",
       "268       81920        12288          1.0          0.002     0.003071  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "X = cleaned.drop(['name', '[avg ms]', '[mem KB]', 'input_shape', 'output_shape', 'strides'], axis=1)  # Features\n",
    "y = cleaned['[avg ms]']  # Labels\n",
    "\n",
    "# Split dataset into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3) # 70% training and 30% test\n",
    "\n",
    "# Instantiate model with 1000 decision trees\n",
    "rf = RandomForestRegressor(n_estimators = 1000, random_state = 42)\n",
    "# Train the model on training data\n",
    "rf.fit(X_train, y_train);\n",
    "\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "print(\"MSE:\", mean_squared_error(y_test, y_pred))\n",
    "\n",
    "pd.concat([X_test, pd.DataFrame({'avg_ms_actual': y_test, 'avg_ms_pred': y_pred})], axis=1).sample(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 317183.27335722075\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>units</th>\n",
       "      <th>filters</th>\n",
       "      <th>kernel_size</th>\n",
       "      <th>activation_linear</th>\n",
       "      <th>activation_relu</th>\n",
       "      <th>activation_softmax</th>\n",
       "      <th>activation_nan</th>\n",
       "      <th>activation_selu</th>\n",
       "      <th>activation_elu</th>\n",
       "      <th>activation_softplus</th>\n",
       "      <th>activation_softsign</th>\n",
       "      <th>activation_tanh</th>\n",
       "      <th>activation_sigmoid</th>\n",
       "      <th>activation_hard_sigmoid</th>\n",
       "      <th>activation_exponential</th>\n",
       "      <th>input_size</th>\n",
       "      <th>output_size</th>\n",
       "      <th>stride_size</th>\n",
       "      <th>mem_KB_actual</th>\n",
       "      <th>mem_KB_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>36992</td>\n",
       "      <td>36992</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>147.968</td>\n",
       "      <td>147.710592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>384.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>24576</td>\n",
       "      <td>24576</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>55488</td>\n",
       "      <td>55488</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>78400</td>\n",
       "      <td>117600</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>14.896512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>55488</td>\n",
       "      <td>55488</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>58800</td>\n",
       "      <td>58800</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>235.200</td>\n",
       "      <td>230.245248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>55488</td>\n",
       "      <td>12288</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>46.583680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>55488</td>\n",
       "      <td>55488</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>46240</td>\n",
       "      <td>46240</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>117600</td>\n",
       "      <td>117600</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2.772352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>58800</td>\n",
       "      <td>58800</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>55488</td>\n",
       "      <td>55488</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>55488</td>\n",
       "      <td>55488</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>352800</td>\n",
       "      <td>78400</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2.330496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>55488</td>\n",
       "      <td>55488</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>117600</td>\n",
       "      <td>117600</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2.359296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>221952</td>\n",
       "      <td>221952</td>\n",
       "      <td>1.0</td>\n",
       "      <td>887.808</td>\n",
       "      <td>899.217408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>221952</td>\n",
       "      <td>36992</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>81920</td>\n",
       "      <td>12288</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.008192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>58800</td>\n",
       "      <td>58800</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     units  filters  kernel_size  activation_linear  activation_relu  \\\n",
       "111   -1.0     -1.0         -1.0                  0                1   \n",
       "291   -1.0    384.0          3.0                  1                0   \n",
       "222   -1.0     -1.0         -1.0                  0                0   \n",
       "68    -1.0     96.0          9.0                  1                0   \n",
       "218   -1.0    192.0          7.0                  1                0   \n",
       "25    -1.0     -1.0         -1.0                  0                1   \n",
       "242   -1.0    192.0          9.0                  1                0   \n",
       "209   -1.0    192.0          7.0                  1                0   \n",
       "178   -1.0    160.0          7.0                  1                0   \n",
       "76    -1.0     96.0          9.0                  1                0   \n",
       "46    -1.0     -1.0         -1.0                  0                0   \n",
       "238   -1.0     -1.0         -1.0                  0                0   \n",
       "230   -1.0     -1.0         -1.0                  0                0   \n",
       "87    -1.0     64.0          1.0                  1                0   \n",
       "200   -1.0    192.0          7.0                  1                0   \n",
       "80    -1.0     -1.0         -1.0                  0                0   \n",
       "119   -1.0     -1.0         -1.0                  0                0   \n",
       "107   -1.0    128.0          1.0                  1                0   \n",
       "268   -1.0    192.0          1.0                  1                0   \n",
       "69    -1.0     -1.0         -1.0                  0                0   \n",
       "\n",
       "     activation_softmax  activation_nan  activation_selu  activation_elu  \\\n",
       "111                   0               0             -1.0            -1.0   \n",
       "291                   0               0             -1.0            -1.0   \n",
       "222                   0               1             -1.0            -1.0   \n",
       "68                    0               0             -1.0            -1.0   \n",
       "218                   0               0             -1.0            -1.0   \n",
       "25                    0               0             -1.0            -1.0   \n",
       "242                   0               0             -1.0            -1.0   \n",
       "209                   0               0             -1.0            -1.0   \n",
       "178                   0               0             -1.0            -1.0   \n",
       "76                    0               0             -1.0            -1.0   \n",
       "46                    0               1             -1.0            -1.0   \n",
       "238                   0               1             -1.0            -1.0   \n",
       "230                   0               1             -1.0            -1.0   \n",
       "87                    0               0             -1.0            -1.0   \n",
       "200                   0               0             -1.0            -1.0   \n",
       "80                    0               1             -1.0            -1.0   \n",
       "119                   0               1             -1.0            -1.0   \n",
       "107                   0               0             -1.0            -1.0   \n",
       "268                   0               0             -1.0            -1.0   \n",
       "69                    0               1             -1.0            -1.0   \n",
       "\n",
       "     activation_softplus  activation_softsign  activation_tanh  \\\n",
       "111                 -1.0                 -1.0             -1.0   \n",
       "291                 -1.0                 -1.0             -1.0   \n",
       "222                 -1.0                 -1.0             -1.0   \n",
       "68                  -1.0                 -1.0             -1.0   \n",
       "218                 -1.0                 -1.0             -1.0   \n",
       "25                  -1.0                 -1.0             -1.0   \n",
       "242                 -1.0                 -1.0             -1.0   \n",
       "209                 -1.0                 -1.0             -1.0   \n",
       "178                 -1.0                 -1.0             -1.0   \n",
       "76                  -1.0                 -1.0             -1.0   \n",
       "46                  -1.0                 -1.0             -1.0   \n",
       "238                 -1.0                 -1.0             -1.0   \n",
       "230                 -1.0                 -1.0             -1.0   \n",
       "87                  -1.0                 -1.0             -1.0   \n",
       "200                 -1.0                 -1.0             -1.0   \n",
       "80                  -1.0                 -1.0             -1.0   \n",
       "119                 -1.0                 -1.0             -1.0   \n",
       "107                 -1.0                 -1.0             -1.0   \n",
       "268                 -1.0                 -1.0             -1.0   \n",
       "69                  -1.0                 -1.0             -1.0   \n",
       "\n",
       "     activation_sigmoid  activation_hard_sigmoid  activation_exponential  \\\n",
       "111                -1.0                     -1.0                    -1.0   \n",
       "291                -1.0                     -1.0                    -1.0   \n",
       "222                -1.0                     -1.0                    -1.0   \n",
       "68                 -1.0                     -1.0                    -1.0   \n",
       "218                -1.0                     -1.0                    -1.0   \n",
       "25                 -1.0                     -1.0                    -1.0   \n",
       "242                -1.0                     -1.0                    -1.0   \n",
       "209                -1.0                     -1.0                    -1.0   \n",
       "178                -1.0                     -1.0                    -1.0   \n",
       "76                 -1.0                     -1.0                    -1.0   \n",
       "46                 -1.0                     -1.0                    -1.0   \n",
       "238                -1.0                     -1.0                    -1.0   \n",
       "230                -1.0                     -1.0                    -1.0   \n",
       "87                 -1.0                     -1.0                    -1.0   \n",
       "200                -1.0                     -1.0                    -1.0   \n",
       "80                 -1.0                     -1.0                    -1.0   \n",
       "119                -1.0                     -1.0                    -1.0   \n",
       "107                -1.0                     -1.0                    -1.0   \n",
       "268                -1.0                     -1.0                    -1.0   \n",
       "69                 -1.0                     -1.0                    -1.0   \n",
       "\n",
       "     input_size  output_size  stride_size  mem_KB_actual  mem_KB_pred  \n",
       "111       36992        36992         -1.0        147.968   147.710592  \n",
       "291       24576        24576          1.0          0.000     0.000000  \n",
       "222       55488        55488         -1.0          0.000     0.000000  \n",
       "68        78400       117600          1.0          0.000    14.896512  \n",
       "218       55488        55488          1.0          0.000     0.000000  \n",
       "25        58800        58800         -1.0        235.200   230.245248  \n",
       "242       55488        12288          4.0          0.000    46.583680  \n",
       "209       55488        55488          1.0          0.000     0.000000  \n",
       "178       46240        46240          1.0          0.000     0.000000  \n",
       "76       117600       117600          1.0          0.000     2.772352  \n",
       "46        58800        58800         -1.0          0.000     0.000000  \n",
       "238       55488        55488         -1.0          0.000     0.000000  \n",
       "230       55488        55488         -1.0          0.000     0.000000  \n",
       "87       352800        78400          1.0          0.000     2.330496  \n",
       "200       55488        55488          1.0          0.000     0.000000  \n",
       "80       117600       117600         -1.0          0.000     2.359296  \n",
       "119      221952       221952          1.0        887.808   899.217408  \n",
       "107      221952        36992          1.0          0.000     0.000000  \n",
       "268       81920        12288          1.0          0.000     0.008192  \n",
       "69        58800        58800         -1.0          0.000     0.000000  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "X = cleaned.drop(['name', '[avg ms]', '[mem KB]', 'input_shape', 'output_shape', 'strides'], axis=1)  # Features\n",
    "y = cleaned['[mem KB]']  # Labels\n",
    "\n",
    "# Split dataset into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3) # 70% training and 30% test\n",
    "\n",
    "# Instantiate model with 1000 decision trees\n",
    "rf = RandomForestRegressor(n_estimators = 1000, random_state = 42)\n",
    "# Train the model on training data\n",
    "rf.fit(X_train, y_train);\n",
    "\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "print(\"MSE:\", mean_squared_error(y_test, y_pred))\n",
    "\n",
    "pd.concat([X_test, pd.DataFrame({'mem_KB_actual': y_test, 'mem_KB_pred': y_pred})], axis=1).sample(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.3499471311167615\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>units</th>\n",
       "      <th>filters</th>\n",
       "      <th>kernel_size</th>\n",
       "      <th>activation_linear</th>\n",
       "      <th>activation_relu</th>\n",
       "      <th>activation_softmax</th>\n",
       "      <th>activation_nan</th>\n",
       "      <th>activation_selu</th>\n",
       "      <th>activation_elu</th>\n",
       "      <th>activation_softplus</th>\n",
       "      <th>activation_softsign</th>\n",
       "      <th>activation_tanh</th>\n",
       "      <th>activation_sigmoid</th>\n",
       "      <th>activation_hard_sigmoid</th>\n",
       "      <th>activation_exponential</th>\n",
       "      <th>input_size</th>\n",
       "      <th>output_size</th>\n",
       "      <th>stride_size</th>\n",
       "      <th>avg_ms_actual</th>\n",
       "      <th>avg_ms_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>78400</td>\n",
       "      <td>78400</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>221952</td>\n",
       "      <td>55488</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>512.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>100352</td>\n",
       "      <td>100352</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.547</td>\n",
       "      <td>5.884671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>12288</td>\n",
       "      <td>12288</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.287</td>\n",
       "      <td>0.836314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>28672</td>\n",
       "      <td>28672</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.006932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>131072</td>\n",
       "      <td>131072</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.762</td>\n",
       "      <td>0.479530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>78400</td>\n",
       "      <td>78400</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.004020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>58800</td>\n",
       "      <td>78400</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.004720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>256.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>401408</td>\n",
       "      <td>802816</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.049</td>\n",
       "      <td>6.026361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>39200</td>\n",
       "      <td>39200</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.434</td>\n",
       "      <td>0.799501</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     units  filters  kernel_size  activation_linear  activation_relu  \\\n",
       "56    -1.0     -1.0         -1.0                  0                0   \n",
       "155   -1.0    192.0          1.0                  1                0   \n",
       "17    -1.0    512.0          9.0                  0                1   \n",
       "309   -1.0     -1.0         -1.0                  0                1   \n",
       "250   -1.0     -1.0         -1.0                  0                0   \n",
       "293   -1.0     -1.0         -1.0                  0                0   \n",
       "42    -1.0     -1.0         -1.0                  0                0   \n",
       "52    -1.0     64.0         25.0                  1                0   \n",
       "7     -1.0    256.0          9.0                  0                1   \n",
       "39    -1.0     -1.0         -1.0                  0                1   \n",
       "\n",
       "     activation_softmax  activation_nan  activation_selu  activation_elu  \\\n",
       "56                    0               1             -1.0            -1.0   \n",
       "155                   0               0             -1.0            -1.0   \n",
       "17                    0               0             -1.0            -1.0   \n",
       "309                   0               0             -1.0            -1.0   \n",
       "250                   0               1             -1.0            -1.0   \n",
       "293                   0               1             -1.0            -1.0   \n",
       "42                    0               1             -1.0            -1.0   \n",
       "52                    0               0             -1.0            -1.0   \n",
       "7                     0               0             -1.0            -1.0   \n",
       "39                    0               0             -1.0            -1.0   \n",
       "\n",
       "     activation_softplus  activation_softsign  activation_tanh  \\\n",
       "56                  -1.0                 -1.0             -1.0   \n",
       "155                 -1.0                 -1.0             -1.0   \n",
       "17                  -1.0                 -1.0             -1.0   \n",
       "309                 -1.0                 -1.0             -1.0   \n",
       "250                 -1.0                 -1.0             -1.0   \n",
       "293                 -1.0                 -1.0             -1.0   \n",
       "42                  -1.0                 -1.0             -1.0   \n",
       "52                  -1.0                 -1.0             -1.0   \n",
       "7                   -1.0                 -1.0             -1.0   \n",
       "39                  -1.0                 -1.0             -1.0   \n",
       "\n",
       "     activation_sigmoid  activation_hard_sigmoid  activation_exponential  \\\n",
       "56                 -1.0                     -1.0                    -1.0   \n",
       "155                -1.0                     -1.0                    -1.0   \n",
       "17                 -1.0                     -1.0                    -1.0   \n",
       "309                -1.0                     -1.0                    -1.0   \n",
       "250                -1.0                     -1.0                    -1.0   \n",
       "293                -1.0                     -1.0                    -1.0   \n",
       "42                 -1.0                     -1.0                    -1.0   \n",
       "52                 -1.0                     -1.0                    -1.0   \n",
       "7                  -1.0                     -1.0                    -1.0   \n",
       "39                 -1.0                     -1.0                    -1.0   \n",
       "\n",
       "     input_size  output_size  stride_size  avg_ms_actual  avg_ms_pred  \n",
       "56        78400        78400         -1.0          0.004     0.004020  \n",
       "155      221952        55488          1.0          0.002     0.002239  \n",
       "17       100352       100352          1.0          4.547     5.884671  \n",
       "309       12288        12288         -1.0          1.287     0.836314  \n",
       "250       28672        28672         -1.0          0.005     0.006932  \n",
       "293      131072       131072          1.0          0.762     0.479530  \n",
       "42        78400        78400         -1.0          0.003     0.004020  \n",
       "52        58800        78400          1.0          0.002     0.004720  \n",
       "7        401408       802816          1.0          7.049     6.026361  \n",
       "39        39200        39200         -1.0          0.434     0.799501  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# AVG MS RF\n",
    "cnn_ms_rf, X_test, y_test = rf_regression_model(cleaned, '[avg ms]')\n",
    "\n",
    "y_pred = cnn_ms_rf.predict(X_test)\n",
    "\n",
    "print(\"MSE:\", mean_squared_error(y_test, y_pred))\n",
    "\n",
    "cnn_ms_rf_mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "pd.concat([X_test, pd.DataFrame({'avg_ms_actual': y_test, 'avg_ms_pred': y_pred})], axis=1).sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 70984.64512575942\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>units</th>\n",
       "      <th>filters</th>\n",
       "      <th>kernel_size</th>\n",
       "      <th>activation_linear</th>\n",
       "      <th>activation_relu</th>\n",
       "      <th>activation_softmax</th>\n",
       "      <th>activation_nan</th>\n",
       "      <th>activation_selu</th>\n",
       "      <th>activation_elu</th>\n",
       "      <th>activation_softplus</th>\n",
       "      <th>activation_softsign</th>\n",
       "      <th>activation_tanh</th>\n",
       "      <th>activation_sigmoid</th>\n",
       "      <th>activation_hard_sigmoid</th>\n",
       "      <th>activation_exponential</th>\n",
       "      <th>input_size</th>\n",
       "      <th>output_size</th>\n",
       "      <th>stride_size</th>\n",
       "      <th>mem_kb_actual</th>\n",
       "      <th>mem_kb_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>221952</td>\n",
       "      <td>55488</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>268203</td>\n",
       "      <td>710432</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>400.351360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>221952</td>\n",
       "      <td>221952</td>\n",
       "      <td>1.0</td>\n",
       "      <td>887.808</td>\n",
       "      <td>888.982528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>117600</td>\n",
       "      <td>117600</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>470.400</td>\n",
       "      <td>463.789312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>100352</td>\n",
       "      <td>25088</td>\n",
       "      <td>4.0</td>\n",
       "      <td>100.352</td>\n",
       "      <td>117.181696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1382976</td>\n",
       "      <td>341056</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1364.224</td>\n",
       "      <td>1497.272128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>221952</td>\n",
       "      <td>55488</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>235200</td>\n",
       "      <td>58800</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>55488</td>\n",
       "      <td>55488</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>24576</td>\n",
       "      <td>24576</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>98.304</td>\n",
       "      <td>98.304000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     units  filters  kernel_size  activation_linear  activation_relu  \\\n",
       "229   -1.0    192.0          1.0                  1                0   \n",
       "1     -1.0     32.0          9.0                  1                0   \n",
       "151   -1.0     -1.0         -1.0                  0                0   \n",
       "92    -1.0     -1.0         -1.0                  0                1   \n",
       "18    -1.0     -1.0         -1.0                  0                0   \n",
       "10    -1.0     -1.0         -1.0                  0                0   \n",
       "123   -1.0    192.0          1.0                  1                0   \n",
       "21    -1.0     48.0          1.0                  1                0   \n",
       "232   -1.0    192.0          7.0                  1                0   \n",
       "288   -1.0     -1.0         -1.0                  0                1   \n",
       "\n",
       "     activation_softmax  activation_nan  activation_selu  activation_elu  \\\n",
       "229                   0               0             -1.0            -1.0   \n",
       "1                     0               0             -1.0            -1.0   \n",
       "151                   0               1             -1.0            -1.0   \n",
       "92                    0               0             -1.0            -1.0   \n",
       "18                    0               1             -1.0            -1.0   \n",
       "10                    0               1             -1.0            -1.0   \n",
       "123                   0               0             -1.0            -1.0   \n",
       "21                    0               0             -1.0            -1.0   \n",
       "232                   0               0             -1.0            -1.0   \n",
       "288                   0               0             -1.0            -1.0   \n",
       "\n",
       "     activation_softplus  activation_softsign  activation_tanh  \\\n",
       "229                 -1.0                 -1.0             -1.0   \n",
       "1                   -1.0                 -1.0             -1.0   \n",
       "151                 -1.0                 -1.0             -1.0   \n",
       "92                  -1.0                 -1.0             -1.0   \n",
       "18                  -1.0                 -1.0             -1.0   \n",
       "10                  -1.0                 -1.0             -1.0   \n",
       "123                 -1.0                 -1.0             -1.0   \n",
       "21                  -1.0                 -1.0             -1.0   \n",
       "232                 -1.0                 -1.0             -1.0   \n",
       "288                 -1.0                 -1.0             -1.0   \n",
       "\n",
       "     activation_sigmoid  activation_hard_sigmoid  activation_exponential  \\\n",
       "229                -1.0                     -1.0                    -1.0   \n",
       "1                  -1.0                     -1.0                    -1.0   \n",
       "151                -1.0                     -1.0                    -1.0   \n",
       "92                 -1.0                     -1.0                    -1.0   \n",
       "18                 -1.0                     -1.0                    -1.0   \n",
       "10                 -1.0                     -1.0                    -1.0   \n",
       "123                -1.0                     -1.0                    -1.0   \n",
       "21                 -1.0                     -1.0                    -1.0   \n",
       "232                -1.0                     -1.0                    -1.0   \n",
       "288                -1.0                     -1.0                    -1.0   \n",
       "\n",
       "     input_size  output_size  stride_size  mem_kb_actual  mem_kb_pred  \n",
       "229      221952        55488          1.0          0.000     0.000000  \n",
       "1        268203       710432          4.0          0.000   400.351360  \n",
       "151      221952       221952          1.0        887.808   888.982528  \n",
       "92       117600       117600         -1.0        470.400   463.789312  \n",
       "18       100352        25088          4.0        100.352   117.181696  \n",
       "10      1382976       341056          4.0       1364.224  1497.272128  \n",
       "123      221952        55488          1.0          0.000     0.000000  \n",
       "21       235200        58800          1.0          0.000     0.000000  \n",
       "232       55488        55488          1.0          0.000     0.000000  \n",
       "288       24576        24576         -1.0         98.304    98.304000  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MEM KB RF\n",
    "cnn_mem_rf, X_test, y_test = rf_regression_model(cleaned, '[mem KB]')\n",
    "\n",
    "y_pred = cnn_mem_rf.predict(X_test)\n",
    "\n",
    "print(\"MSE:\", mean_squared_error(y_test, y_pred))\n",
    "cnn_mem_rf_mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "pd.concat([X_test, pd.DataFrame({'mem_kb_actual': y_test, 'mem_kb_pred': y_pred})], axis=1).sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brian/anaconda/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/brian/anaconda/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/brian/anaconda/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/brian/anaconda/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/brian/anaconda/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/brian/anaconda/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 2.2940391907913917\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>units</th>\n",
       "      <th>filters</th>\n",
       "      <th>kernel_size</th>\n",
       "      <th>activation_linear</th>\n",
       "      <th>activation_relu</th>\n",
       "      <th>activation_softmax</th>\n",
       "      <th>activation_nan</th>\n",
       "      <th>activation_selu</th>\n",
       "      <th>activation_elu</th>\n",
       "      <th>activation_softplus</th>\n",
       "      <th>activation_softsign</th>\n",
       "      <th>activation_tanh</th>\n",
       "      <th>activation_sigmoid</th>\n",
       "      <th>activation_hard_sigmoid</th>\n",
       "      <th>activation_exponential</th>\n",
       "      <th>input_size</th>\n",
       "      <th>output_size</th>\n",
       "      <th>stride_size</th>\n",
       "      <th>avg_ms_actual</th>\n",
       "      <th>avg_ms_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>221952</td>\n",
       "      <td>46240</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.420535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>78400</td>\n",
       "      <td>78400</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.263402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>55488</td>\n",
       "      <td>55488</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.286609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>12288</td>\n",
       "      <td>12288</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.287</td>\n",
       "      <td>0.749305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>221952</td>\n",
       "      <td>55488</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.336043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>55488</td>\n",
       "      <td>55488</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.708</td>\n",
       "      <td>0.992539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>117600</td>\n",
       "      <td>117600</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.290</td>\n",
       "      <td>1.376630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>78400</td>\n",
       "      <td>78400</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.925</td>\n",
       "      <td>0.824567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>58800</td>\n",
       "      <td>58800</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.450</td>\n",
       "      <td>0.522446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>55488</td>\n",
       "      <td>55488</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.671</td>\n",
       "      <td>0.992539</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     units  filters  kernel_size  activation_linear  activation_relu  \\\n",
       "139   -1.0    160.0          1.0                  1                0   \n",
       "55    -1.0     -1.0         -1.0                  0                0   \n",
       "125   -1.0     -1.0         -1.0                  0                0   \n",
       "309   -1.0     -1.0         -1.0                  0                1   \n",
       "216   -1.0    192.0          1.0                  1                0   \n",
       "129   -1.0     -1.0         -1.0                  0                1   \n",
       "49    -1.0     -1.0         -1.0                  0                1   \n",
       "83    -1.0     -1.0         -1.0                  0                1   \n",
       "25    -1.0     -1.0         -1.0                  0                1   \n",
       "239   -1.0     -1.0         -1.0                  0                1   \n",
       "\n",
       "     activation_softmax  activation_nan  activation_selu  activation_elu  \\\n",
       "139                   0               0             -1.0            -1.0   \n",
       "55                    0               1             -1.0            -1.0   \n",
       "125                   0               1             -1.0            -1.0   \n",
       "309                   0               0             -1.0            -1.0   \n",
       "216                   0               0             -1.0            -1.0   \n",
       "129                   0               0             -1.0            -1.0   \n",
       "49                    0               0             -1.0            -1.0   \n",
       "83                    0               0             -1.0            -1.0   \n",
       "25                    0               0             -1.0            -1.0   \n",
       "239                   0               0             -1.0            -1.0   \n",
       "\n",
       "     activation_softplus  activation_softsign  activation_tanh  \\\n",
       "139                 -1.0                 -1.0             -1.0   \n",
       "55                  -1.0                 -1.0             -1.0   \n",
       "125                 -1.0                 -1.0             -1.0   \n",
       "309                 -1.0                 -1.0             -1.0   \n",
       "216                 -1.0                 -1.0             -1.0   \n",
       "129                 -1.0                 -1.0             -1.0   \n",
       "49                  -1.0                 -1.0             -1.0   \n",
       "83                  -1.0                 -1.0             -1.0   \n",
       "25                  -1.0                 -1.0             -1.0   \n",
       "239                 -1.0                 -1.0             -1.0   \n",
       "\n",
       "     activation_sigmoid  activation_hard_sigmoid  activation_exponential  \\\n",
       "139                -1.0                     -1.0                    -1.0   \n",
       "55                 -1.0                     -1.0                    -1.0   \n",
       "125                -1.0                     -1.0                    -1.0   \n",
       "309                -1.0                     -1.0                    -1.0   \n",
       "216                -1.0                     -1.0                    -1.0   \n",
       "129                -1.0                     -1.0                    -1.0   \n",
       "49                 -1.0                     -1.0                    -1.0   \n",
       "83                 -1.0                     -1.0                    -1.0   \n",
       "25                 -1.0                     -1.0                    -1.0   \n",
       "239                -1.0                     -1.0                    -1.0   \n",
       "\n",
       "     input_size  output_size  stride_size  avg_ms_actual  avg_ms_pred  \n",
       "139      221952        46240          1.0          0.002     0.420535  \n",
       "55        78400        78400         -1.0          0.005     0.263402  \n",
       "125       55488        55488         -1.0          0.003     0.286609  \n",
       "309       12288        12288         -1.0          1.287     0.749305  \n",
       "216      221952        55488          1.0          0.002     0.336043  \n",
       "129       55488        55488         -1.0          0.708     0.992539  \n",
       "49       117600       117600         -1.0          1.290     1.376630  \n",
       "83        78400        78400         -1.0          1.925     0.824567  \n",
       "25        58800        58800         -1.0          0.450     0.522446  \n",
       "239       55488        55488         -1.0          0.671     0.992539  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# AVG MS stacked\n",
    "cnn_ms_stacked_1, X_test, y_test = stacked_regression_model(cleaned, '[avg ms]')\n",
    "\n",
    "y_pred = cnn_ms_stacked_1.predict(X_test)\n",
    "\n",
    "print(\"MSE:\", mean_squared_error(y_test, y_pred))\n",
    "cnn_ms_stacked_1_mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "pd.concat([X_test, pd.DataFrame({'avg_ms_actual': y_test, 'avg_ms_pred': y_pred})], axis=1).sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brian/anaconda/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/brian/anaconda/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/brian/anaconda/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/brian/anaconda/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/brian/anaconda/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/brian/anaconda/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 1076248.8717503173\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>units</th>\n",
       "      <th>filters</th>\n",
       "      <th>kernel_size</th>\n",
       "      <th>activation_linear</th>\n",
       "      <th>activation_relu</th>\n",
       "      <th>activation_softmax</th>\n",
       "      <th>activation_nan</th>\n",
       "      <th>activation_selu</th>\n",
       "      <th>activation_elu</th>\n",
       "      <th>activation_softplus</th>\n",
       "      <th>activation_softsign</th>\n",
       "      <th>activation_tanh</th>\n",
       "      <th>activation_sigmoid</th>\n",
       "      <th>activation_hard_sigmoid</th>\n",
       "      <th>activation_exponential</th>\n",
       "      <th>input_size</th>\n",
       "      <th>output_size</th>\n",
       "      <th>stride_size</th>\n",
       "      <th>mem_kb_actual</th>\n",
       "      <th>mem_kb_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>78400</td>\n",
       "      <td>117600</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>20.702398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>221952</td>\n",
       "      <td>46240</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-2.656129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>55488</td>\n",
       "      <td>55488</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>221.952</td>\n",
       "      <td>276.701087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>39200</td>\n",
       "      <td>39200</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>156.800</td>\n",
       "      <td>213.228637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>117600</td>\n",
       "      <td>117600</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>100.991929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>24576</td>\n",
       "      <td>24576</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>98.304</td>\n",
       "      <td>166.092819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>117600</td>\n",
       "      <td>117600</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>28.740704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>221952</td>\n",
       "      <td>221952</td>\n",
       "      <td>1.0</td>\n",
       "      <td>887.808</td>\n",
       "      <td>784.072508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>352800</td>\n",
       "      <td>352800</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1411.200</td>\n",
       "      <td>1207.010633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1605632</td>\n",
       "      <td>401408</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1605.632</td>\n",
       "      <td>1485.698043</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     units  filters  kernel_size  activation_linear  activation_relu  \\\n",
       "68    -1.0     96.0          9.0                  1                0   \n",
       "171   -1.0    160.0          1.0                  1                0   \n",
       "214   -1.0     -1.0         -1.0                  0                1   \n",
       "39    -1.0     -1.0         -1.0                  0                1   \n",
       "80    -1.0     -1.0         -1.0                  0                0   \n",
       "303   -1.0     -1.0         -1.0                  0                1   \n",
       "76    -1.0     96.0          9.0                  1                0   \n",
       "183   -1.0     -1.0         -1.0                  0                0   \n",
       "73    -1.0     -1.0         -1.0                  0                0   \n",
       "6     -1.0     -1.0         -1.0                  0                0   \n",
       "\n",
       "     activation_softmax  activation_nan  activation_selu  activation_elu  \\\n",
       "68                    0               0             -1.0            -1.0   \n",
       "171                   0               0             -1.0            -1.0   \n",
       "214                   0               0             -1.0            -1.0   \n",
       "39                    0               0             -1.0            -1.0   \n",
       "80                    0               1             -1.0            -1.0   \n",
       "303                   0               0             -1.0            -1.0   \n",
       "76                    0               0             -1.0            -1.0   \n",
       "183                   0               1             -1.0            -1.0   \n",
       "73                    0               1             -1.0            -1.0   \n",
       "6                     0               1             -1.0            -1.0   \n",
       "\n",
       "     activation_softplus  activation_softsign  activation_tanh  \\\n",
       "68                  -1.0                 -1.0             -1.0   \n",
       "171                 -1.0                 -1.0             -1.0   \n",
       "214                 -1.0                 -1.0             -1.0   \n",
       "39                  -1.0                 -1.0             -1.0   \n",
       "80                  -1.0                 -1.0             -1.0   \n",
       "303                 -1.0                 -1.0             -1.0   \n",
       "76                  -1.0                 -1.0             -1.0   \n",
       "183                 -1.0                 -1.0             -1.0   \n",
       "73                  -1.0                 -1.0             -1.0   \n",
       "6                   -1.0                 -1.0             -1.0   \n",
       "\n",
       "     activation_sigmoid  activation_hard_sigmoid  activation_exponential  \\\n",
       "68                 -1.0                     -1.0                    -1.0   \n",
       "171                -1.0                     -1.0                    -1.0   \n",
       "214                -1.0                     -1.0                    -1.0   \n",
       "39                 -1.0                     -1.0                    -1.0   \n",
       "80                 -1.0                     -1.0                    -1.0   \n",
       "303                -1.0                     -1.0                    -1.0   \n",
       "76                 -1.0                     -1.0                    -1.0   \n",
       "183                -1.0                     -1.0                    -1.0   \n",
       "73                 -1.0                     -1.0                    -1.0   \n",
       "6                  -1.0                     -1.0                    -1.0   \n",
       "\n",
       "     input_size  output_size  stride_size  mem_kb_actual  mem_kb_pred  \n",
       "68        78400       117600          1.0          0.000    20.702398  \n",
       "171      221952        46240          1.0          0.000    -2.656129  \n",
       "214       55488        55488         -1.0        221.952   276.701087  \n",
       "39        39200        39200         -1.0        156.800   213.228637  \n",
       "80       117600       117600         -1.0          0.000   100.991929  \n",
       "303       24576        24576         -1.0         98.304   166.092819  \n",
       "76       117600       117600          1.0          0.000    28.740704  \n",
       "183      221952       221952          1.0        887.808   784.072508  \n",
       "73       352800       352800          1.0       1411.200  1207.010633  \n",
       "6       1605632       401408          4.0       1605.632  1485.698043  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# AVG MEM stacked\n",
    "cnn_mem_stacked_1, X_test, y_test = stacked_regression_model(cleaned, '[mem KB]')\n",
    "\n",
    "y_pred = cnn_mem_stacked_1.predict(X_test)\n",
    "\n",
    "print(\"MSE:\", mean_squared_error(y_test, y_pred))\n",
    "cnn_mem_stacked_1_mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "pd.concat([X_test, pd.DataFrame({'mem_kb_actual': y_test, 'mem_kb_pred': y_pred})], axis=1).sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brian/anaconda/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 79.61104081858598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brian/anaconda/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/brian/anaconda/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/brian/anaconda/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/brian/anaconda/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/brian/anaconda/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>units</th>\n",
       "      <th>filters</th>\n",
       "      <th>kernel_size</th>\n",
       "      <th>activation_linear</th>\n",
       "      <th>activation_relu</th>\n",
       "      <th>activation_softmax</th>\n",
       "      <th>activation_nan</th>\n",
       "      <th>activation_selu</th>\n",
       "      <th>activation_elu</th>\n",
       "      <th>activation_softplus</th>\n",
       "      <th>activation_softsign</th>\n",
       "      <th>activation_tanh</th>\n",
       "      <th>activation_sigmoid</th>\n",
       "      <th>activation_hard_sigmoid</th>\n",
       "      <th>activation_exponential</th>\n",
       "      <th>input_size</th>\n",
       "      <th>output_size</th>\n",
       "      <th>stride_size</th>\n",
       "      <th>avg_ms_actual</th>\n",
       "      <th>avg_ms_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>426320</td>\n",
       "      <td>967872</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.002</td>\n",
       "      <td>-7.434774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>24576</td>\n",
       "      <td>24576</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.008</td>\n",
       "      <td>-8.968249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>221952</td>\n",
       "      <td>55488</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.002</td>\n",
       "      <td>-9.039889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>55488</td>\n",
       "      <td>55488</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.073</td>\n",
       "      <td>-7.682186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>55488</td>\n",
       "      <td>55488</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.003</td>\n",
       "      <td>-8.534105</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     units  filters  kernel_size  activation_linear  activation_relu  \\\n",
       "14    -1.0    192.0          9.0                  1                0   \n",
       "298   -1.0     -1.0         -1.0                  0                0   \n",
       "155   -1.0    192.0          1.0                  1                0   \n",
       "192   -1.0     -1.0         -1.0                  0                1   \n",
       "217   -1.0    192.0          7.0                  1                0   \n",
       "\n",
       "     activation_softmax  activation_nan  activation_selu  activation_elu  \\\n",
       "14                    0               0             -1.0            -1.0   \n",
       "298                   0               1             -1.0            -1.0   \n",
       "155                   0               0             -1.0            -1.0   \n",
       "192                   0               0             -1.0            -1.0   \n",
       "217                   0               0             -1.0            -1.0   \n",
       "\n",
       "     activation_softplus  activation_softsign  activation_tanh  \\\n",
       "14                  -1.0                 -1.0             -1.0   \n",
       "298                 -1.0                 -1.0             -1.0   \n",
       "155                 -1.0                 -1.0             -1.0   \n",
       "192                 -1.0                 -1.0             -1.0   \n",
       "217                 -1.0                 -1.0             -1.0   \n",
       "\n",
       "     activation_sigmoid  activation_hard_sigmoid  activation_exponential  \\\n",
       "14                 -1.0                     -1.0                    -1.0   \n",
       "298                -1.0                     -1.0                    -1.0   \n",
       "155                -1.0                     -1.0                    -1.0   \n",
       "192                -1.0                     -1.0                    -1.0   \n",
       "217                -1.0                     -1.0                    -1.0   \n",
       "\n",
       "     input_size  output_size  stride_size  avg_ms_actual  avg_ms_pred  \n",
       "14       426320       967872          1.0          0.002    -7.434774  \n",
       "298       24576        24576         -1.0          0.008    -8.968249  \n",
       "155      221952        55488          1.0          0.002    -9.039889  \n",
       "192       55488        55488         -1.0          1.073    -7.682186  \n",
       "217       55488        55488          1.0          0.003    -8.534105  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lstm stacked avg ms\n",
    "cnn_ms_stacked_2, X_test, y_test = stacked_regression_model_2(cleaned, '[avg ms]')\n",
    "\n",
    "y_pred = cnn_ms_stacked_2.predict(X_test)\n",
    "\n",
    "print(\"MSE:\", mean_squared_error(y_test, y_pred))\n",
    "cnn_ms_stacked_2_mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "pd.concat([X_test, pd.DataFrame({'avg_ms_actual': y_test, 'avg_ms_pred': y_pred})], axis=1).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brian/anaconda/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 1.0917266885366172e+19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brian/anaconda/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/brian/anaconda/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/brian/anaconda/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/brian/anaconda/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/brian/anaconda/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>units</th>\n",
       "      <th>filters</th>\n",
       "      <th>kernel_size</th>\n",
       "      <th>activation_linear</th>\n",
       "      <th>activation_relu</th>\n",
       "      <th>activation_softmax</th>\n",
       "      <th>activation_nan</th>\n",
       "      <th>activation_selu</th>\n",
       "      <th>activation_elu</th>\n",
       "      <th>activation_softplus</th>\n",
       "      <th>activation_softsign</th>\n",
       "      <th>activation_tanh</th>\n",
       "      <th>activation_sigmoid</th>\n",
       "      <th>activation_hard_sigmoid</th>\n",
       "      <th>activation_exponential</th>\n",
       "      <th>input_size</th>\n",
       "      <th>output_size</th>\n",
       "      <th>stride_size</th>\n",
       "      <th>mem_kb_actual</th>\n",
       "      <th>mem_kb_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>55488</td>\n",
       "      <td>55488</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-3.304109e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>117600</td>\n",
       "      <td>117600</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>470.400</td>\n",
       "      <td>-3.304109e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>12288</td>\n",
       "      <td>12288</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-3.304109e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>512.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>100352</td>\n",
       "      <td>100352</td>\n",
       "      <td>1.0</td>\n",
       "      <td>401.408</td>\n",
       "      <td>-3.304106e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>58800</td>\n",
       "      <td>58800</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-3.304109e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     units  filters  kernel_size  activation_linear  activation_relu  \\\n",
       "222   -1.0     -1.0         -1.0                  0                0   \n",
       "84    -1.0     -1.0         -1.0                  0                1   \n",
       "274   -1.0     -1.0         -1.0                  0                0   \n",
       "16    -1.0    512.0          9.0                  0                1   \n",
       "23    -1.0     -1.0         -1.0                  0                0   \n",
       "\n",
       "     activation_softmax  activation_nan  activation_selu  activation_elu  \\\n",
       "222                   0               1             -1.0            -1.0   \n",
       "84                    0               0             -1.0            -1.0   \n",
       "274                   0               1             -1.0            -1.0   \n",
       "16                    0               0             -1.0            -1.0   \n",
       "23                    0               1             -1.0            -1.0   \n",
       "\n",
       "     activation_softplus  activation_softsign  activation_tanh  \\\n",
       "222                 -1.0                 -1.0             -1.0   \n",
       "84                  -1.0                 -1.0             -1.0   \n",
       "274                 -1.0                 -1.0             -1.0   \n",
       "16                  -1.0                 -1.0             -1.0   \n",
       "23                  -1.0                 -1.0             -1.0   \n",
       "\n",
       "     activation_sigmoid  activation_hard_sigmoid  activation_exponential  \\\n",
       "222                -1.0                     -1.0                    -1.0   \n",
       "84                 -1.0                     -1.0                    -1.0   \n",
       "274                -1.0                     -1.0                    -1.0   \n",
       "16                 -1.0                     -1.0                    -1.0   \n",
       "23                 -1.0                     -1.0                    -1.0   \n",
       "\n",
       "     input_size  output_size  stride_size  mem_kb_actual   mem_kb_pred  \n",
       "222       55488        55488         -1.0          0.000 -3.304109e+09  \n",
       "84       117600       117600         -1.0        470.400 -3.304109e+09  \n",
       "274       12288        12288         -1.0          0.000 -3.304109e+09  \n",
       "16       100352       100352          1.0        401.408 -3.304106e+09  \n",
       "23        58800        58800         -1.0          0.000 -3.304109e+09  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lstm stacked mem\n",
    "cnn_mem_stacked_2, X_test, y_test = stacked_regression_model_2(cleaned, '[mem KB]')\n",
    "\n",
    "y_pred = cnn_mem_stacked_2.predict(X_test)\n",
    "\n",
    "print(\"MSE:\", mean_squared_error(y_test, y_pred))\n",
    "cnn_mem_stacked_2_mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "pd.concat([X_test, pd.DataFrame({'mem_kb_actual': y_test, 'mem_kb_pred': y_pred})], axis=1).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/brian/anaconda/lib/python3.6/site-packages/tensorflow/python/keras/initializers.py:119: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /Users/brian/anaconda/lib/python3.6/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Retrieving saved model and benchmark results.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>[node type]</th>\n",
       "      <th>[start]</th>\n",
       "      <th>[first]</th>\n",
       "      <th>[avg ms]</th>\n",
       "      <th>[%]</th>\n",
       "      <th>[cdf%]</th>\n",
       "      <th>[mem KB]</th>\n",
       "      <th>[times called]</th>\n",
       "      <th>[Name]</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Enter</td>\n",
       "      <td>171.058</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.002%</td>\n",
       "      <td>9.435%</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1</td>\n",
       "      <td>lstm5/while/TensorArrayReadV3/Enter_1</td>\n",
       "      <td>lstm5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>Const</td>\n",
       "      <td>-24.271</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.001%</td>\n",
       "      <td>75.558%</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1</td>\n",
       "      <td>lstm2/kernel</td>\n",
       "      <td>lstm2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>Switch</td>\n",
       "      <td>-0.856</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.341%</td>\n",
       "      <td>88.465%</td>\n",
       "      <td>0.000</td>\n",
       "      <td>251</td>\n",
       "      <td>lstm1/while/Switch_2</td>\n",
       "      <td>lstm1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>Enter</td>\n",
       "      <td>-24.129</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.001%</td>\n",
       "      <td>75.611%</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1</td>\n",
       "      <td>lstm3/while/Enter_1</td>\n",
       "      <td>lstm3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>460</th>\n",
       "      <td>Range</td>\n",
       "      <td>-23.890</td>\n",
       "      <td>0.045</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.005%</td>\n",
       "      <td>84.005%</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1</td>\n",
       "      <td>lstm1/TensorArrayUnstack/range</td>\n",
       "      <td>lstm1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>Const</td>\n",
       "      <td>190.609</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.229%</td>\n",
       "      <td>15.452%</td>\n",
       "      <td>0.000</td>\n",
       "      <td>250</td>\n",
       "      <td>ConstantFolding/lstm5/while/split_1-folded-1</td>\n",
       "      <td>ConstantFolding</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>Enter</td>\n",
       "      <td>120.857</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.003%</td>\n",
       "      <td>34.794%</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1</td>\n",
       "      <td>lstm4/while/TensorArrayReadV3/Enter</td>\n",
       "      <td>lstm4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>Mul</td>\n",
       "      <td>46.095</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.221%</td>\n",
       "      <td>62.502%</td>\n",
       "      <td>0.000</td>\n",
       "      <td>250</td>\n",
       "      <td>lstm2/while/Mul</td>\n",
       "      <td>lstm2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>Const</td>\n",
       "      <td>-24.330</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.001%</td>\n",
       "      <td>75.544%</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1</td>\n",
       "      <td>lstm5/bias</td>\n",
       "      <td>lstm5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>Less</td>\n",
       "      <td>190.664</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.338%</td>\n",
       "      <td>17.811%</td>\n",
       "      <td>0.001</td>\n",
       "      <td>251</td>\n",
       "      <td>lstm5/while/Less_1</td>\n",
       "      <td>lstm5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465</th>\n",
       "      <td>Identity</td>\n",
       "      <td>-5.152</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.242%</td>\n",
       "      <td>85.160%</td>\n",
       "      <td>0.000</td>\n",
       "      <td>250</td>\n",
       "      <td>lstm1/while/Identity</td>\n",
       "      <td>lstm1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>Const</td>\n",
       "      <td>41.708</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.233%</td>\n",
       "      <td>74.002%</td>\n",
       "      <td>0.000</td>\n",
       "      <td>250</td>\n",
       "      <td>lstm2/while/strided_slice_1</td>\n",
       "      <td>lstm2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>NextIteration</td>\n",
       "      <td>91.052</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.420%</td>\n",
       "      <td>52.040%</td>\n",
       "      <td>0.000</td>\n",
       "      <td>250</td>\n",
       "      <td>lstm3/while/NextIteration</td>\n",
       "      <td>lstm3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>Const</td>\n",
       "      <td>-24.249</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.001%</td>\n",
       "      <td>75.563%</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1</td>\n",
       "      <td>lstm5/strided_slice_7/stack</td>\n",
       "      <td>lstm5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>Merge</td>\n",
       "      <td>144.830</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.437%</td>\n",
       "      <td>34.792%</td>\n",
       "      <td>0.004</td>\n",
       "      <td>251</td>\n",
       "      <td>lstm4/while/Merge_3</td>\n",
       "      <td>lstm4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  [node type]  [start]  [first]  [avg ms]       [%]    [cdf%]  \\\n",
       "39                      Enter  171.058    0.006     0.004    0.002%    9.435%   \n",
       "380                     Const  -24.271    0.002     0.003    0.001%   75.558%   \n",
       "485                    Switch   -0.856    0.008     0.003    0.341%   88.465%   \n",
       "417                     Enter  -24.129    0.003     0.003    0.001%   75.611%   \n",
       "460                     Range  -23.890    0.045     0.013    0.005%   84.005%   \n",
       "63                      Const  190.609    0.003     0.002    0.229%   15.452%   \n",
       "151                     Enter  120.857    0.023     0.006    0.003%   34.794%   \n",
       "288                       Mul   46.095    0.006     0.002    0.221%   62.502%   \n",
       "362                     Const  -24.330    0.003     0.002    0.001%   75.544%   \n",
       "72                       Less  190.664    0.008     0.003    0.338%   17.811%   \n",
       "465                  Identity   -5.152    0.006     0.002    0.242%   85.160%   \n",
       "340                     Const   41.708    0.005     0.002    0.233%   74.002%   \n",
       "238             NextIteration   91.052    0.006     0.004    0.420%   52.040%   \n",
       "387                     Const  -24.249    0.002     0.002    0.001%   75.563%   \n",
       "150                     Merge  144.830    0.025     0.004    0.437%   34.792%   \n",
       "\n",
       "     [mem KB]  [times called]                                        [Name]  \\\n",
       "39      0.000               1         lstm5/while/TensorArrayReadV3/Enter_1   \n",
       "380     0.000               1                                  lstm2/kernel   \n",
       "485     0.000             251                          lstm1/while/Switch_2   \n",
       "417     0.000               1                           lstm3/while/Enter_1   \n",
       "460     1.000               1                lstm1/TensorArrayUnstack/range   \n",
       "63      0.000             250  ConstantFolding/lstm5/while/split_1-folded-1   \n",
       "151     0.000               1           lstm4/while/TensorArrayReadV3/Enter   \n",
       "288     0.000             250                               lstm2/while/Mul   \n",
       "362     0.000               1                                    lstm5/bias   \n",
       "72      0.001             251                            lstm5/while/Less_1   \n",
       "465     0.000             250                          lstm1/while/Identity   \n",
       "340     0.000             250                   lstm2/while/strided_slice_1   \n",
       "238     0.000             250                     lstm3/while/NextIteration   \n",
       "387     0.000               1                   lstm5/strided_slice_7/stack   \n",
       "150     0.004             251                           lstm4/while/Merge_3   \n",
       "\n",
       "                name  \n",
       "39             lstm5  \n",
       "380            lstm2  \n",
       "485            lstm1  \n",
       "417            lstm3  \n",
       "460            lstm1  \n",
       "63   ConstantFolding  \n",
       "151            lstm4  \n",
       "288            lstm2  \n",
       "362            lstm5  \n",
       "72             lstm5  \n",
       "465            lstm1  \n",
       "340            lstm2  \n",
       "238            lstm3  \n",
       "387            lstm5  \n",
       "150            lstm4  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lstm.summary()\n",
    "\n",
    "tf.keras.backend.clear_session() # IMPORTANT for layer names to match up.\n",
    "\n",
    "lstm = create_lstm()\n",
    "\n",
    "# tf.keras.backend.set_learning_phase(0)\n",
    "lstm_benchmark = benchmark_model(lstm)\n",
    "lstm_benchmark.sample(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lstm_features = get_layer_features(lstm)\n",
    "lstm_df = join_benchmark(lstm_features, lstm_benchmark)\n",
    "cleaned_lstm = clean(lstm_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.003043146131333064\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>units</th>\n",
       "      <th>filters</th>\n",
       "      <th>kernel_size</th>\n",
       "      <th>activation_relu</th>\n",
       "      <th>activation_sigmoid</th>\n",
       "      <th>activation_tanh</th>\n",
       "      <th>activation_nan</th>\n",
       "      <th>activation_selu</th>\n",
       "      <th>activation_elu</th>\n",
       "      <th>activation_softmax</th>\n",
       "      <th>activation_softplus</th>\n",
       "      <th>activation_softsign</th>\n",
       "      <th>activation_hard_sigmoid</th>\n",
       "      <th>activation_exponential</th>\n",
       "      <th>activation_linear</th>\n",
       "      <th>input_size</th>\n",
       "      <th>output_size</th>\n",
       "      <th>stride_size</th>\n",
       "      <th>avg_ms_actual</th>\n",
       "      <th>avg_ms_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>48.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>32000</td>\n",
       "      <td>48</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.941</td>\n",
       "      <td>0.900587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>16000</td>\n",
       "      <td>16000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.166</td>\n",
       "      <td>0.242828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>64.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>8000</td>\n",
       "      <td>16000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.940</td>\n",
       "      <td>0.900079</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   units  filters  kernel_size  activation_relu  activation_sigmoid  \\\n",
       "7   48.0     -1.0         -1.0                0                   0   \n",
       "1   -1.0     32.0          3.0                1                   0   \n",
       "5   64.0     -1.0         -1.0                0                   0   \n",
       "\n",
       "   activation_tanh  activation_nan  activation_selu  activation_elu  \\\n",
       "7                1               0             -1.0            -1.0   \n",
       "1                0               0             -1.0            -1.0   \n",
       "5                1               0             -1.0            -1.0   \n",
       "\n",
       "   activation_softmax  activation_softplus  activation_softsign  \\\n",
       "7                -1.0                 -1.0                 -1.0   \n",
       "1                -1.0                 -1.0                 -1.0   \n",
       "5                -1.0                 -1.0                 -1.0   \n",
       "\n",
       "   activation_hard_sigmoid  activation_exponential  activation_linear  \\\n",
       "7                     -1.0                    -1.0               -1.0   \n",
       "1                     -1.0                    -1.0               -1.0   \n",
       "5                     -1.0                    -1.0               -1.0   \n",
       "\n",
       "   input_size  output_size  stride_size  avg_ms_actual  avg_ms_pred  \n",
       "7       32000           48         -1.0          0.941     0.900587  \n",
       "1       16000        16000          1.0          0.166     0.242828  \n",
       "5        8000        16000         -1.0          0.940     0.900079  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf, X_test, y_test = rf_regression_model(cleaned_lstm, '[avg ms]')\n",
    "\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "print(\"MSE:\", mean_squared_error(y_test, y_pred))\n",
    "\n",
    "pd.concat([X_test, pd.DataFrame({'avg_ms_actual': y_test, 'avg_ms_pred': y_pred})], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 363.04756968992393\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>units</th>\n",
       "      <th>filters</th>\n",
       "      <th>kernel_size</th>\n",
       "      <th>activation_relu</th>\n",
       "      <th>activation_sigmoid</th>\n",
       "      <th>activation_tanh</th>\n",
       "      <th>activation_nan</th>\n",
       "      <th>activation_selu</th>\n",
       "      <th>activation_elu</th>\n",
       "      <th>activation_softmax</th>\n",
       "      <th>activation_softplus</th>\n",
       "      <th>activation_softsign</th>\n",
       "      <th>activation_hard_sigmoid</th>\n",
       "      <th>activation_exponential</th>\n",
       "      <th>activation_linear</th>\n",
       "      <th>input_size</th>\n",
       "      <th>output_size</th>\n",
       "      <th>stride_size</th>\n",
       "      <th>mem_kb_actual</th>\n",
       "      <th>mem_kb_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>48.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>32000</td>\n",
       "      <td>48</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>25.184864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>16000</td>\n",
       "      <td>16000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>31.712296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>64.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>8000</td>\n",
       "      <td>16000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>32.448108</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   units  filters  kernel_size  activation_relu  activation_sigmoid  \\\n",
       "7   48.0     -1.0         -1.0                0                   0   \n",
       "1   -1.0     32.0          3.0                1                   0   \n",
       "5   64.0     -1.0         -1.0                0                   0   \n",
       "\n",
       "   activation_tanh  activation_nan  activation_selu  activation_elu  \\\n",
       "7                1               0             -1.0            -1.0   \n",
       "1                0               0             -1.0            -1.0   \n",
       "5                1               0             -1.0            -1.0   \n",
       "\n",
       "   activation_softmax  activation_softplus  activation_softsign  \\\n",
       "7                -1.0                 -1.0                 -1.0   \n",
       "1                -1.0                 -1.0                 -1.0   \n",
       "5                -1.0                 -1.0                 -1.0   \n",
       "\n",
       "   activation_hard_sigmoid  activation_exponential  activation_linear  \\\n",
       "7                     -1.0                    -1.0               -1.0   \n",
       "1                     -1.0                    -1.0               -1.0   \n",
       "5                     -1.0                    -1.0               -1.0   \n",
       "\n",
       "   input_size  output_size  stride_size  mem_kb_actual  mem_kb_pred  \n",
       "7       32000           48         -1.0           32.0    25.184864  \n",
       "1       16000        16000          1.0           64.0    31.712296  \n",
       "5        8000        16000         -1.0           32.0    32.448108  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf, X_test, y_test = rf_regression_model(cleaned_lstm, '[mem KB]')\n",
    "\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "print(\"MSE:\", mean_squared_error(y_test, y_pred))\n",
    "\n",
    "pd.concat([X_test, pd.DataFrame({'mem_kb_actual': y_test, 'mem_kb_pred': y_pred})], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brian/anaconda/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.32148484991487053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brian/anaconda/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/brian/anaconda/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/brian/anaconda/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/brian/anaconda/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/brian/anaconda/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>units</th>\n",
       "      <th>filters</th>\n",
       "      <th>kernel_size</th>\n",
       "      <th>activation_relu</th>\n",
       "      <th>activation_sigmoid</th>\n",
       "      <th>activation_tanh</th>\n",
       "      <th>activation_nan</th>\n",
       "      <th>activation_selu</th>\n",
       "      <th>activation_elu</th>\n",
       "      <th>activation_softmax</th>\n",
       "      <th>activation_softplus</th>\n",
       "      <th>activation_softsign</th>\n",
       "      <th>activation_hard_sigmoid</th>\n",
       "      <th>activation_exponential</th>\n",
       "      <th>activation_linear</th>\n",
       "      <th>input_size</th>\n",
       "      <th>output_size</th>\n",
       "      <th>stride_size</th>\n",
       "      <th>avg_ms_actual</th>\n",
       "      <th>avg_ms_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>16000</td>\n",
       "      <td>16000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.166</td>\n",
       "      <td>-0.343861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.850315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2500</td>\n",
       "      <td>8000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.941</td>\n",
       "      <td>0.947790</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   units  filters  kernel_size  activation_relu  activation_sigmoid  \\\n",
       "1   -1.0     32.0          3.0                1                   0   \n",
       "8    1.0     -1.0         -1.0                0                   1   \n",
       "4   32.0     -1.0         -1.0                0                   0   \n",
       "\n",
       "   activation_tanh  activation_nan  activation_selu  activation_elu  \\\n",
       "1                0               0             -1.0            -1.0   \n",
       "8                0               0             -1.0            -1.0   \n",
       "4                1               0             -1.0            -1.0   \n",
       "\n",
       "   activation_softmax  activation_softplus  activation_softsign  \\\n",
       "1                -1.0                 -1.0                 -1.0   \n",
       "8                -1.0                 -1.0                 -1.0   \n",
       "4                -1.0                 -1.0                 -1.0   \n",
       "\n",
       "   activation_hard_sigmoid  activation_exponential  activation_linear  \\\n",
       "1                     -1.0                    -1.0               -1.0   \n",
       "8                     -1.0                    -1.0               -1.0   \n",
       "4                     -1.0                    -1.0               -1.0   \n",
       "\n",
       "   input_size  output_size  stride_size  avg_ms_actual  avg_ms_pred  \n",
       "1       16000        16000          1.0          0.166    -0.343861  \n",
       "8          48            1         -1.0          0.011     0.850315  \n",
       "4        2500         8000         -1.0          0.941     0.947790  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lstm stacked avg ms\n",
    "rf, X_test, y_test = stacked_regression_model(cleaned_lstm, '[avg ms]')\n",
    "\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "print(\"MSE:\", mean_squared_error(y_test, y_pred))\n",
    "\n",
    "pd.concat([X_test, pd.DataFrame({'avg_ms_actual': y_test, 'avg_ms_pred': y_pred})], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brian/anaconda/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 1780.7031965625222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brian/anaconda/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/brian/anaconda/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/brian/anaconda/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/brian/anaconda/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>units</th>\n",
       "      <th>filters</th>\n",
       "      <th>kernel_size</th>\n",
       "      <th>activation_relu</th>\n",
       "      <th>activation_sigmoid</th>\n",
       "      <th>activation_tanh</th>\n",
       "      <th>activation_nan</th>\n",
       "      <th>activation_selu</th>\n",
       "      <th>activation_elu</th>\n",
       "      <th>activation_softmax</th>\n",
       "      <th>activation_softplus</th>\n",
       "      <th>activation_softsign</th>\n",
       "      <th>activation_hard_sigmoid</th>\n",
       "      <th>activation_exponential</th>\n",
       "      <th>activation_linear</th>\n",
       "      <th>input_size</th>\n",
       "      <th>output_size</th>\n",
       "      <th>stride_size</th>\n",
       "      <th>mem_kb_actual</th>\n",
       "      <th>mem_kb_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>48.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>32000</td>\n",
       "      <td>48</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>35.150173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>128.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>16000</td>\n",
       "      <td>32000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>104.931036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>8000</td>\n",
       "      <td>2500</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>28.359949</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   units  filters  kernel_size  activation_relu  activation_sigmoid  \\\n",
       "7   48.0     -1.0         -1.0                0                   0   \n",
       "6  128.0     -1.0         -1.0                0                   0   \n",
       "3   10.0     -1.0         -1.0                0                   0   \n",
       "\n",
       "   activation_tanh  activation_nan  activation_selu  activation_elu  \\\n",
       "7                1               0             -1.0            -1.0   \n",
       "6                1               0             -1.0            -1.0   \n",
       "3                1               0             -1.0            -1.0   \n",
       "\n",
       "   activation_softmax  activation_softplus  activation_softsign  \\\n",
       "7                -1.0                 -1.0                 -1.0   \n",
       "6                -1.0                 -1.0                 -1.0   \n",
       "3                -1.0                 -1.0                 -1.0   \n",
       "\n",
       "   activation_hard_sigmoid  activation_exponential  activation_linear  \\\n",
       "7                     -1.0                    -1.0               -1.0   \n",
       "6                     -1.0                    -1.0               -1.0   \n",
       "3                     -1.0                    -1.0               -1.0   \n",
       "\n",
       "   input_size  output_size  stride_size  mem_kb_actual  mem_kb_pred  \n",
       "7       32000           48         -1.0           32.0    35.150173  \n",
       "6       16000        32000         -1.0           32.0   104.931036  \n",
       "3        8000         2500         -1.0           32.0    28.359949  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lstm stacked mem\n",
    "rf, X_test, y_test = stacked_regression_model(cleaned_lstm, '[mem KB]')\n",
    "\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "print(\"MSE:\", mean_squared_error(y_test, y_pred))\n",
    "\n",
    "pd.concat([X_test, pd.DataFrame({'mem_kb_actual': y_test, 'mem_kb_pred': y_pred})], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brian/anaconda/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 1.6067859381992454e+16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brian/anaconda/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/brian/anaconda/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/brian/anaconda/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/brian/anaconda/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/brian/anaconda/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>units</th>\n",
       "      <th>filters</th>\n",
       "      <th>kernel_size</th>\n",
       "      <th>activation_relu</th>\n",
       "      <th>activation_sigmoid</th>\n",
       "      <th>activation_tanh</th>\n",
       "      <th>activation_nan</th>\n",
       "      <th>activation_selu</th>\n",
       "      <th>activation_elu</th>\n",
       "      <th>activation_softmax</th>\n",
       "      <th>activation_softplus</th>\n",
       "      <th>activation_softsign</th>\n",
       "      <th>activation_hard_sigmoid</th>\n",
       "      <th>activation_exponential</th>\n",
       "      <th>activation_linear</th>\n",
       "      <th>input_size</th>\n",
       "      <th>output_size</th>\n",
       "      <th>stride_size</th>\n",
       "      <th>avg_ms_actual</th>\n",
       "      <th>avg_ms_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>64.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>8000</td>\n",
       "      <td>16000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.940</td>\n",
       "      <td>-1.267589e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>8000</td>\n",
       "      <td>2500</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.952</td>\n",
       "      <td>-1.267531e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2500</td>\n",
       "      <td>8000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.941</td>\n",
       "      <td>-1.267652e+08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   units  filters  kernel_size  activation_relu  activation_sigmoid  \\\n",
       "5   64.0     -1.0         -1.0                0                   0   \n",
       "3   10.0     -1.0         -1.0                0                   0   \n",
       "4   32.0     -1.0         -1.0                0                   0   \n",
       "\n",
       "   activation_tanh  activation_nan  activation_selu  activation_elu  \\\n",
       "5                1               0             -1.0            -1.0   \n",
       "3                1               0             -1.0            -1.0   \n",
       "4                1               0             -1.0            -1.0   \n",
       "\n",
       "   activation_softmax  activation_softplus  activation_softsign  \\\n",
       "5                -1.0                 -1.0                 -1.0   \n",
       "3                -1.0                 -1.0                 -1.0   \n",
       "4                -1.0                 -1.0                 -1.0   \n",
       "\n",
       "   activation_hard_sigmoid  activation_exponential  activation_linear  \\\n",
       "5                     -1.0                    -1.0               -1.0   \n",
       "3                     -1.0                    -1.0               -1.0   \n",
       "4                     -1.0                    -1.0               -1.0   \n",
       "\n",
       "   input_size  output_size  stride_size  avg_ms_actual   avg_ms_pred  \n",
       "5        8000        16000         -1.0          0.940 -1.267589e+08  \n",
       "3        8000         2500         -1.0          0.952 -1.267531e+08  \n",
       "4        2500         8000         -1.0          0.941 -1.267652e+08  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lstm stacked avg ms\n",
    "rf, X_test, y_test = stacked_regression_model_2(cleaned_lstm, '[avg ms]')\n",
    "\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "print(\"MSE:\", mean_squared_error(y_test, y_pred))\n",
    "\n",
    "pd.concat([X_test, pd.DataFrame({'avg_ms_actual': y_test, 'avg_ms_pred': y_pred})], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brian/anaconda/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/brian/anaconda/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/brian/anaconda/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/brian/anaconda/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/brian/anaconda/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/brian/anaconda/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 23843351824817.754\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>units</th>\n",
       "      <th>filters</th>\n",
       "      <th>kernel_size</th>\n",
       "      <th>activation_relu</th>\n",
       "      <th>activation_sigmoid</th>\n",
       "      <th>activation_tanh</th>\n",
       "      <th>activation_nan</th>\n",
       "      <th>activation_selu</th>\n",
       "      <th>activation_elu</th>\n",
       "      <th>activation_softmax</th>\n",
       "      <th>activation_softplus</th>\n",
       "      <th>activation_softsign</th>\n",
       "      <th>activation_hard_sigmoid</th>\n",
       "      <th>activation_exponential</th>\n",
       "      <th>activation_linear</th>\n",
       "      <th>input_size</th>\n",
       "      <th>output_size</th>\n",
       "      <th>stride_size</th>\n",
       "      <th>mem_kb_actual</th>\n",
       "      <th>mem_kb_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2500</td>\n",
       "      <td>8000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>4.903031e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>16000</td>\n",
       "      <td>16000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>4.843128e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>64.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>8000</td>\n",
       "      <td>16000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>4.902622e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   units  filters  kernel_size  activation_relu  activation_sigmoid  \\\n",
       "4   32.0     -1.0         -1.0                0                   0   \n",
       "1   -1.0     32.0          3.0                1                   0   \n",
       "5   64.0     -1.0         -1.0                0                   0   \n",
       "\n",
       "   activation_tanh  activation_nan  activation_selu  activation_elu  \\\n",
       "4                1               0             -1.0            -1.0   \n",
       "1                0               0             -1.0            -1.0   \n",
       "5                1               0             -1.0            -1.0   \n",
       "\n",
       "   activation_softmax  activation_softplus  activation_softsign  \\\n",
       "4                -1.0                 -1.0                 -1.0   \n",
       "1                -1.0                 -1.0                 -1.0   \n",
       "5                -1.0                 -1.0                 -1.0   \n",
       "\n",
       "   activation_hard_sigmoid  activation_exponential  activation_linear  \\\n",
       "4                     -1.0                    -1.0               -1.0   \n",
       "1                     -1.0                    -1.0               -1.0   \n",
       "5                     -1.0                    -1.0               -1.0   \n",
       "\n",
       "   input_size  output_size  stride_size  mem_kb_actual   mem_kb_pred  \n",
       "4        2500         8000         -1.0           32.0  4.903031e+06  \n",
       "1       16000        16000          1.0           64.0  4.843128e+06  \n",
       "5        8000        16000         -1.0           32.0  4.902622e+06  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lstm stacked mem\n",
    "rf, X_test, y_test = stacked_regression_model_2(cleaned_lstm, '[mem KB]')\n",
    "\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "print(\"MSE:\", mean_squared_error(y_test, y_pred))\n",
    "\n",
    "pd.concat([X_test, pd.DataFrame({'mem_kb_actual': y_test, 'mem_kb_pred': y_pred})], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving saved model and benchmark results.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>[node type]</th>\n",
       "      <th>[start]</th>\n",
       "      <th>[first]</th>\n",
       "      <th>[avg ms]</th>\n",
       "      <th>[%]</th>\n",
       "      <th>[cdf%]</th>\n",
       "      <th>[mem KB]</th>\n",
       "      <th>[times called]</th>\n",
       "      <th>[Name]</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Const</td>\n",
       "      <td>-0.108</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.377%</td>\n",
       "      <td>2.587%</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1</td>\n",
       "      <td>lstm1/strided_slice/stack</td>\n",
       "      <td>lstm1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Const</td>\n",
       "      <td>0.052</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.556%</td>\n",
       "      <td>35.641%</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1</td>\n",
       "      <td>ConstantFolding/lstm1/while/split-folded-0</td>\n",
       "      <td>ConstantFolding</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>Enter</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.757%</td>\n",
       "      <td>67.111%</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1</td>\n",
       "      <td>lstm1/while/TensorArrayReadV3/Enter_1</td>\n",
       "      <td>lstm1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Enter</td>\n",
       "      <td>-0.083</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.415%</td>\n",
       "      <td>6.624%</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1</td>\n",
       "      <td>lstm1/while/Enter</td>\n",
       "      <td>lstm1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>MatMul</td>\n",
       "      <td>0.041</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.012</td>\n",
       "      <td>2.926%</td>\n",
       "      <td>81.040%</td>\n",
       "      <td>1.024</td>\n",
       "      <td>1</td>\n",
       "      <td>lstm1/while/MatMul_3</td>\n",
       "      <td>lstm1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 [node type]  [start]  [first]  [avg ms]       [%]    [cdf%]  \\\n",
       "5                      Const   -0.108    0.002     0.002    0.377%    2.587%   \n",
       "47                     Const    0.052    0.003     0.002    0.556%   35.641%   \n",
       "59                     Enter    0.007    0.009     0.003    0.757%   67.111%   \n",
       "14                     Enter   -0.083    0.002     0.002    0.415%    6.624%   \n",
       "66                    MatMul    0.041    0.016     0.012    2.926%   81.040%   \n",
       "\n",
       "    [mem KB]  [times called]                                      [Name]  \\\n",
       "5      0.000               1                   lstm1/strided_slice/stack   \n",
       "47     0.000               1  ConstantFolding/lstm1/while/split-folded-0   \n",
       "59     0.000               1       lstm1/while/TensorArrayReadV3/Enter_1   \n",
       "14     0.000               1                           lstm1/while/Enter   \n",
       "66     1.024               1                        lstm1/while/MatMul_3   \n",
       "\n",
       "               name  \n",
       "5             lstm1  \n",
       "47  ConstantFolding  \n",
       "59            lstm1  \n",
       "14            lstm1  \n",
       "66            lstm1  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lstm.summary()\n",
    "\n",
    "tf.keras.backend.clear_session() # IMPORTANT for layer names to match up.\n",
    "\n",
    "enc, dec = create_seq2seq()\n",
    "\n",
    "# tf.keras.backend.set_learning_phase(0)\n",
    "enc_benchmark = benchmark_model(enc, '../tensorflow/bazel-bin/tensorflow/tools/benchmark/benchmark_model --graph=encoder.pbtxt --input_layer=\"input_1:0\" --input_layer_shape=\"1,1,71\" --output_layer=\"lstm1/while/Exit_2:0\"')\n",
    "enc_benchmark.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving saved model and benchmark results.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>[node type]</th>\n",
       "      <th>[start]</th>\n",
       "      <th>[first]</th>\n",
       "      <th>[avg ms]</th>\n",
       "      <th>[%]</th>\n",
       "      <th>[cdf%]</th>\n",
       "      <th>[mem KB]</th>\n",
       "      <th>[times called]</th>\n",
       "      <th>[Name]</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>Minimum</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.612%</td>\n",
       "      <td>82.161%</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>lstm2_1/while/clip_by_value_1/Minimum</td>\n",
       "      <td>lstm2_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Const</td>\n",
       "      <td>-0.121</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.555%</td>\n",
       "      <td>0.943%</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>lstm2/kernel</td>\n",
       "      <td>lstm2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Const</td>\n",
       "      <td>-0.101</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.247%</td>\n",
       "      <td>2.685%</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>lstm2_1/TensorArrayUnstack/strided_slice/stack_1</td>\n",
       "      <td>lstm2_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>Prod</td>\n",
       "      <td>0.271</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.358%</td>\n",
       "      <td>98.355%</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>dense1_1/Tensordot/Prod_1</td>\n",
       "      <td>dense1_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Const</td>\n",
       "      <td>0.044</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.411%</td>\n",
       "      <td>27.194%</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>lstm2_1/while/strided_slice_1</td>\n",
       "      <td>lstm2_1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  [node type]  [start]  [first]  [avg ms]       [%]    [cdf%]  \\\n",
       "91                    Minimum    0.130    0.010     0.004    0.612%   82.161%   \n",
       "1                       Const   -0.121    0.009     0.004    0.555%    0.943%   \n",
       "8                       Const   -0.101    0.002     0.002    0.247%    2.685%   \n",
       "118                      Prod    0.271    0.002     0.002    0.358%   98.355%   \n",
       "49                      Const    0.044    0.003     0.003    0.411%   27.194%   \n",
       "\n",
       "     [mem KB]  [times called]  \\\n",
       "91        0.0               1   \n",
       "1         0.0               1   \n",
       "8         0.0               1   \n",
       "118       0.0               1   \n",
       "49        0.0               1   \n",
       "\n",
       "                                               [Name]      name  \n",
       "91              lstm2_1/while/clip_by_value_1/Minimum   lstm2_1  \n",
       "1                                        lstm2/kernel     lstm2  \n",
       "8    lstm2_1/TensorArrayUnstack/strided_slice/stack_1   lstm2_1  \n",
       "118                         dense1_1/Tensordot/Prod_1  dense1_1  \n",
       "49                      lstm2_1/while/strided_slice_1   lstm2_1  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dec_benchmark = benchmark_model(dec, '../tensorflow/bazel-bin/tensorflow/tools/benchmark/benchmark_model --graph=decoder.pbtxt --input_layer=\"input_2:0,input_3:0,input_4:0\" --input_layer_shape=\"1,1,93:1,256:1,256\" --input_layer_type=float,float,float --output_layer=\"dense1_1/truediv:0\"')\n",
    "dec_benchmark.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seq2seq_benchmark = pd.concat([enc_benchmark, dec_benchmark])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "enc_features = get_layer_features(enc)\n",
    "dec_features = get_layer_features(dec)\n",
    "seq2seq_features = pd.concat([enc_features, dec_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seq2seq_df = join_benchmark(seq2seq_features, seq2seq_benchmark)\n",
    "cleaned_seq2seq = clean(seq2seq_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brian/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:1: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>[avg ms]</th>\n",
       "      <th>[mem KB]</th>\n",
       "      <th>activation_elu</th>\n",
       "      <th>activation_exponential</th>\n",
       "      <th>activation_hard_sigmoid</th>\n",
       "      <th>activation_linear</th>\n",
       "      <th>activation_nan</th>\n",
       "      <th>activation_relu</th>\n",
       "      <th>activation_selu</th>\n",
       "      <th>activation_sigmoid</th>\n",
       "      <th>...</th>\n",
       "      <th>filters</th>\n",
       "      <th>input_shape</th>\n",
       "      <th>input_size</th>\n",
       "      <th>kernel_size</th>\n",
       "      <th>name</th>\n",
       "      <th>output_shape</th>\n",
       "      <th>output_size</th>\n",
       "      <th>stride_size</th>\n",
       "      <th>strides</th>\n",
       "      <th>units</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.166</td>\n",
       "      <td>64.000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>32.0</td>\n",
       "      <td>(None, 500, 32)</td>\n",
       "      <td>16000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>conv1d</td>\n",
       "      <td>(None, 500, 32)</td>\n",
       "      <td>16000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>(1,)</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.011</td>\n",
       "      <td>0.004</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>(None, 48)</td>\n",
       "      <td>48</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>dense</td>\n",
       "      <td>(None, 1)</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.033</td>\n",
       "      <td>64.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>(None, 500)</td>\n",
       "      <td>500</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>embedding</td>\n",
       "      <td>(None, 500, 32)</td>\n",
       "      <td>16000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.039</td>\n",
       "      <td>32.000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>(None, 500, 32)</td>\n",
       "      <td>16000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>max_pooling1d</td>\n",
       "      <td>(None, 250, 32)</td>\n",
       "      <td>8000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>(2,)</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.941</td>\n",
       "      <td>32.000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>(None, 250, 10)</td>\n",
       "      <td>2500</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>lstm2</td>\n",
       "      <td>(None, 250, 32)</td>\n",
       "      <td>8000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.965</td>\n",
       "      <td>32.000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>(None, 250, 64)</td>\n",
       "      <td>16000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>lstm4</td>\n",
       "      <td>(None, 250, 128)</td>\n",
       "      <td>32000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>128.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.952</td>\n",
       "      <td>32.000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>(None, 250, 32)</td>\n",
       "      <td>8000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>lstm1</td>\n",
       "      <td>(None, 250, 10)</td>\n",
       "      <td>2500</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.940</td>\n",
       "      <td>32.000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>(None, 250, 32)</td>\n",
       "      <td>8000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>lstm3</td>\n",
       "      <td>(None, 250, 64)</td>\n",
       "      <td>16000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>64.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.941</td>\n",
       "      <td>32.000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>(None, 250, 128)</td>\n",
       "      <td>32000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>lstm5</td>\n",
       "      <td>(None, 48)</td>\n",
       "      <td>48</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>48.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.382</td>\n",
       "      <td>1.024</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>(None, None, 71)</td>\n",
       "      <td>71</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>lstm1</td>\n",
       "      <td>[(None, 256), (None, 256), (None, 256)]</td>\n",
       "      <td>768</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>256.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   [avg ms]  [mem KB]  activation_elu  activation_exponential  \\\n",
       "1     0.166    64.000            -1.0                    -1.0   \n",
       "8     0.011     0.004            -1.0                    -1.0   \n",
       "0     0.033    64.000             0.0                     0.0   \n",
       "2     0.039    32.000            -1.0                    -1.0   \n",
       "4     0.941    32.000            -1.0                    -1.0   \n",
       "6     0.965    32.000            -1.0                    -1.0   \n",
       "3     0.952    32.000            -1.0                    -1.0   \n",
       "5     0.940    32.000            -1.0                    -1.0   \n",
       "7     0.941    32.000            -1.0                    -1.0   \n",
       "1     0.382     1.024            -1.0                    -1.0   \n",
       "\n",
       "   activation_hard_sigmoid  activation_linear  activation_nan  \\\n",
       "1                     -1.0               -1.0               0   \n",
       "8                     -1.0               -1.0               0   \n",
       "0                      0.0                0.0               1   \n",
       "2                     -1.0               -1.0               1   \n",
       "4                     -1.0               -1.0               0   \n",
       "6                     -1.0               -1.0               0   \n",
       "3                     -1.0               -1.0               0   \n",
       "5                     -1.0               -1.0               0   \n",
       "7                     -1.0               -1.0               0   \n",
       "1                     -1.0               -1.0               0   \n",
       "\n",
       "   activation_relu  activation_selu  activation_sigmoid  ...  filters  \\\n",
       "1              1.0             -1.0                 0.0  ...     32.0   \n",
       "8              0.0             -1.0                 1.0  ...     -1.0   \n",
       "0              0.0              0.0                 0.0  ...     -1.0   \n",
       "2              0.0             -1.0                 0.0  ...     -1.0   \n",
       "4              0.0             -1.0                 0.0  ...     -1.0   \n",
       "6              0.0             -1.0                 0.0  ...     -1.0   \n",
       "3              0.0             -1.0                 0.0  ...     -1.0   \n",
       "5              0.0             -1.0                 0.0  ...     -1.0   \n",
       "7              0.0             -1.0                 0.0  ...     -1.0   \n",
       "1             -1.0             -1.0                -1.0  ...     -1.0   \n",
       "\n",
       "        input_shape  input_size  kernel_size           name  \\\n",
       "1   (None, 500, 32)       16000          3.0         conv1d   \n",
       "8        (None, 48)          48         -1.0          dense   \n",
       "0       (None, 500)         500         -1.0      embedding   \n",
       "2   (None, 500, 32)       16000         -1.0  max_pooling1d   \n",
       "4   (None, 250, 10)        2500         -1.0          lstm2   \n",
       "6   (None, 250, 64)       16000         -1.0          lstm4   \n",
       "3   (None, 250, 32)        8000         -1.0          lstm1   \n",
       "5   (None, 250, 32)        8000         -1.0          lstm3   \n",
       "7  (None, 250, 128)       32000         -1.0          lstm5   \n",
       "1  (None, None, 71)          71         -1.0          lstm1   \n",
       "\n",
       "                              output_shape  output_size  stride_size strides  \\\n",
       "1                          (None, 500, 32)        16000          1.0    (1,)   \n",
       "8                                (None, 1)            1         -1.0      -1   \n",
       "0                          (None, 500, 32)        16000         -1.0      -1   \n",
       "2                          (None, 250, 32)         8000          2.0    (2,)   \n",
       "4                          (None, 250, 32)         8000         -1.0      -1   \n",
       "6                         (None, 250, 128)        32000         -1.0      -1   \n",
       "3                          (None, 250, 10)         2500         -1.0      -1   \n",
       "5                          (None, 250, 64)        16000         -1.0      -1   \n",
       "7                               (None, 48)           48         -1.0      -1   \n",
       "1  [(None, 256), (None, 256), (None, 256)]          768         -1.0      -1   \n",
       "\n",
       "   units  \n",
       "1   -1.0  \n",
       "8    1.0  \n",
       "0   -1.0  \n",
       "2   -1.0  \n",
       "4   32.0  \n",
       "6  128.0  \n",
       "3   10.0  \n",
       "5   64.0  \n",
       "7   48.0  \n",
       "1  256.0  \n",
       "\n",
       "[10 rows x 24 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_rnn = pd.concat([cleaned_lstm, cleaned_seq2seq]).fillna(0)\n",
    "cleaned_rnn.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.2941177649690035\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>activation_elu</th>\n",
       "      <th>activation_exponential</th>\n",
       "      <th>activation_hard_sigmoid</th>\n",
       "      <th>activation_linear</th>\n",
       "      <th>activation_nan</th>\n",
       "      <th>activation_relu</th>\n",
       "      <th>activation_selu</th>\n",
       "      <th>activation_sigmoid</th>\n",
       "      <th>activation_softmax</th>\n",
       "      <th>activation_softplus</th>\n",
       "      <th>activation_softsign</th>\n",
       "      <th>activation_tanh</th>\n",
       "      <th>filters</th>\n",
       "      <th>input_size</th>\n",
       "      <th>kernel_size</th>\n",
       "      <th>output_size</th>\n",
       "      <th>stride_size</th>\n",
       "      <th>units</th>\n",
       "      <th>avg_ms_actual</th>\n",
       "      <th>avg_ms_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>8000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>16000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.940</td>\n",
       "      <td>0.919003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>500</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>16000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.256547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>71</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>768</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>256.0</td>\n",
       "      <td>0.382</td>\n",
       "      <td>0.921677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>605</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>768</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>256.0</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.921677</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   activation_elu  activation_exponential  activation_hard_sigmoid  \\\n",
       "5            -1.0                    -1.0                     -1.0   \n",
       "0             0.0                     0.0                      0.0   \n",
       "1            -1.0                    -1.0                     -1.0   \n",
       "3            -1.0                    -1.0                     -1.0   \n",
       "\n",
       "   activation_linear  activation_nan  activation_relu  activation_selu  \\\n",
       "5               -1.0               0              0.0             -1.0   \n",
       "0                0.0               1              0.0              0.0   \n",
       "1               -1.0               0             -1.0             -1.0   \n",
       "3               -1.0               0             -1.0             -1.0   \n",
       "\n",
       "   activation_sigmoid  activation_softmax  activation_softplus  \\\n",
       "5                 0.0                -1.0                 -1.0   \n",
       "0                 0.0                 0.0                  0.0   \n",
       "1                -1.0                -1.0                 -1.0   \n",
       "3                -1.0                -1.0                 -1.0   \n",
       "\n",
       "   activation_softsign  activation_tanh  filters  input_size  kernel_size  \\\n",
       "5                 -1.0                1     -1.0        8000         -1.0   \n",
       "0                  0.0                0     -1.0         500         -1.0   \n",
       "1                 -1.0                1     -1.0          71         -1.0   \n",
       "3                 -1.0                1     -1.0         605         -1.0   \n",
       "\n",
       "   output_size  stride_size  units  avg_ms_actual  avg_ms_pred  \n",
       "5        16000         -1.0   64.0          0.940     0.919003  \n",
       "0        16000         -1.0   -1.0          0.033     0.256547  \n",
       "1          768         -1.0  256.0          0.382     0.921677  \n",
       "3          768         -1.0  256.0          0.008     0.921677  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn_ms_rf, X_test, y_test = rf_regression_model(cleaned_rnn, '[avg ms]')\n",
    "\n",
    "y_pred = rnn_ms_rf.predict(X_test)\n",
    "\n",
    "print(\"MSE:\", mean_squared_error(y_test, y_pred))\n",
    "rnn_ms_rf_mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "pd.concat([X_test, pd.DataFrame({'avg_ms_actual': y_test, 'avg_ms_pred': y_pred})], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 585.0930507439566\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>activation_elu</th>\n",
       "      <th>activation_exponential</th>\n",
       "      <th>activation_hard_sigmoid</th>\n",
       "      <th>activation_linear</th>\n",
       "      <th>activation_nan</th>\n",
       "      <th>activation_relu</th>\n",
       "      <th>activation_selu</th>\n",
       "      <th>activation_sigmoid</th>\n",
       "      <th>activation_softmax</th>\n",
       "      <th>activation_softplus</th>\n",
       "      <th>activation_softsign</th>\n",
       "      <th>activation_tanh</th>\n",
       "      <th>filters</th>\n",
       "      <th>input_size</th>\n",
       "      <th>kernel_size</th>\n",
       "      <th>output_size</th>\n",
       "      <th>stride_size</th>\n",
       "      <th>units</th>\n",
       "      <th>mem_kb_actual</th>\n",
       "      <th>mem_kb_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>8000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>16000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>32.000</td>\n",
       "      <td>32.992120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>500</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>16000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>64.000</td>\n",
       "      <td>27.936956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>71</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>768</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>256.0</td>\n",
       "      <td>1.024</td>\n",
       "      <td>23.297088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>605</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>768</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>256.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>23.297088</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   activation_elu  activation_exponential  activation_hard_sigmoid  \\\n",
       "5            -1.0                    -1.0                     -1.0   \n",
       "0             0.0                     0.0                      0.0   \n",
       "1            -1.0                    -1.0                     -1.0   \n",
       "3            -1.0                    -1.0                     -1.0   \n",
       "\n",
       "   activation_linear  activation_nan  activation_relu  activation_selu  \\\n",
       "5               -1.0               0              0.0             -1.0   \n",
       "0                0.0               1              0.0              0.0   \n",
       "1               -1.0               0             -1.0             -1.0   \n",
       "3               -1.0               0             -1.0             -1.0   \n",
       "\n",
       "   activation_sigmoid  activation_softmax  activation_softplus  \\\n",
       "5                 0.0                -1.0                 -1.0   \n",
       "0                 0.0                 0.0                  0.0   \n",
       "1                -1.0                -1.0                 -1.0   \n",
       "3                -1.0                -1.0                 -1.0   \n",
       "\n",
       "   activation_softsign  activation_tanh  filters  input_size  kernel_size  \\\n",
       "5                 -1.0                1     -1.0        8000         -1.0   \n",
       "0                  0.0                0     -1.0         500         -1.0   \n",
       "1                 -1.0                1     -1.0          71         -1.0   \n",
       "3                 -1.0                1     -1.0         605         -1.0   \n",
       "\n",
       "   output_size  stride_size  units  mem_kb_actual  mem_kb_pred  \n",
       "5        16000         -1.0   64.0         32.000    32.992120  \n",
       "0        16000         -1.0   -1.0         64.000    27.936956  \n",
       "1          768         -1.0  256.0          1.024    23.297088  \n",
       "3          768         -1.0  256.0          0.000    23.297088  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn_mem_rf, X_test, y_test = rf_regression_model(cleaned_rnn, '[mem KB]')\n",
    "\n",
    "y_pred = rnn_mem_rf.predict(X_test)\n",
    "\n",
    "print(\"MSE:\", mean_squared_error(y_test, y_pred))\n",
    "rnn_mem_rf_mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "pd.concat([X_test, pd.DataFrame({'mem_kb_actual': y_test, 'mem_kb_pred': y_pred})], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brian/anaconda/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.3017690844111648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brian/anaconda/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/brian/anaconda/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/brian/anaconda/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/brian/anaconda/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/brian/anaconda/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>activation_elu</th>\n",
       "      <th>activation_exponential</th>\n",
       "      <th>activation_hard_sigmoid</th>\n",
       "      <th>activation_linear</th>\n",
       "      <th>activation_nan</th>\n",
       "      <th>activation_relu</th>\n",
       "      <th>activation_selu</th>\n",
       "      <th>activation_sigmoid</th>\n",
       "      <th>activation_softmax</th>\n",
       "      <th>activation_softplus</th>\n",
       "      <th>activation_softsign</th>\n",
       "      <th>activation_tanh</th>\n",
       "      <th>filters</th>\n",
       "      <th>input_size</th>\n",
       "      <th>kernel_size</th>\n",
       "      <th>output_size</th>\n",
       "      <th>stride_size</th>\n",
       "      <th>units</th>\n",
       "      <th>avg_ms_actual</th>\n",
       "      <th>avg_ms_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>16000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>32000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>0.965</td>\n",
       "      <td>0.237778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>32000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>48</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0.941</td>\n",
       "      <td>0.394734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>8000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>16000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.940</td>\n",
       "      <td>0.324446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>71</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>768</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>256.0</td>\n",
       "      <td>0.382</td>\n",
       "      <td>0.412191</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   activation_elu  activation_exponential  activation_hard_sigmoid  \\\n",
       "6            -1.0                    -1.0                     -1.0   \n",
       "7            -1.0                    -1.0                     -1.0   \n",
       "5            -1.0                    -1.0                     -1.0   \n",
       "1            -1.0                    -1.0                     -1.0   \n",
       "\n",
       "   activation_linear  activation_nan  activation_relu  activation_selu  \\\n",
       "6               -1.0               0              0.0             -1.0   \n",
       "7               -1.0               0              0.0             -1.0   \n",
       "5               -1.0               0              0.0             -1.0   \n",
       "1               -1.0               0             -1.0             -1.0   \n",
       "\n",
       "   activation_sigmoid  activation_softmax  activation_softplus  \\\n",
       "6                 0.0                -1.0                 -1.0   \n",
       "7                 0.0                -1.0                 -1.0   \n",
       "5                 0.0                -1.0                 -1.0   \n",
       "1                -1.0                -1.0                 -1.0   \n",
       "\n",
       "   activation_softsign  activation_tanh  filters  input_size  kernel_size  \\\n",
       "6                 -1.0                1     -1.0       16000         -1.0   \n",
       "7                 -1.0                1     -1.0       32000         -1.0   \n",
       "5                 -1.0                1     -1.0        8000         -1.0   \n",
       "1                 -1.0                1     -1.0          71         -1.0   \n",
       "\n",
       "   output_size  stride_size  units  avg_ms_actual  avg_ms_pred  \n",
       "6        32000         -1.0  128.0          0.965     0.237778  \n",
       "7           48         -1.0   48.0          0.941     0.394734  \n",
       "5        16000         -1.0   64.0          0.940     0.324446  \n",
       "1          768         -1.0  256.0          0.382     0.412191  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn_ms_stacked_1, X_test, y_test = stacked_regression_model(cleaned_rnn, '[avg ms]')\n",
    "\n",
    "y_pred = rnn_ms_stacked_1.predict(X_test)\n",
    "\n",
    "print(\"MSE:\", mean_squared_error(y_test, y_pred))\n",
    "rnn_ms_stacked_1_mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "pd.concat([X_test, pd.DataFrame({'avg_ms_actual': y_test, 'avg_ms_pred': y_pred})], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brian/anaconda/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 610.3908272774386\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brian/anaconda/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/brian/anaconda/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/brian/anaconda/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/brian/anaconda/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/brian/anaconda/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>activation_elu</th>\n",
       "      <th>activation_exponential</th>\n",
       "      <th>activation_hard_sigmoid</th>\n",
       "      <th>activation_linear</th>\n",
       "      <th>activation_nan</th>\n",
       "      <th>activation_relu</th>\n",
       "      <th>activation_selu</th>\n",
       "      <th>activation_sigmoid</th>\n",
       "      <th>activation_softmax</th>\n",
       "      <th>activation_softplus</th>\n",
       "      <th>activation_softsign</th>\n",
       "      <th>activation_tanh</th>\n",
       "      <th>filters</th>\n",
       "      <th>input_size</th>\n",
       "      <th>kernel_size</th>\n",
       "      <th>output_size</th>\n",
       "      <th>stride_size</th>\n",
       "      <th>units</th>\n",
       "      <th>mem_kb_actual</th>\n",
       "      <th>mem_kb_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>16000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>16000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>64.000</td>\n",
       "      <td>36.045711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>32000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>48</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>32.000</td>\n",
       "      <td>27.091656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>71</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>768</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>256.0</td>\n",
       "      <td>1.024</td>\n",
       "      <td>7.303139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>500</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>16000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>64.000</td>\n",
       "      <td>24.042503</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   activation_elu  activation_exponential  activation_hard_sigmoid  \\\n",
       "1            -1.0                    -1.0                     -1.0   \n",
       "7            -1.0                    -1.0                     -1.0   \n",
       "1            -1.0                    -1.0                     -1.0   \n",
       "0             0.0                     0.0                      0.0   \n",
       "\n",
       "   activation_linear  activation_nan  activation_relu  activation_selu  \\\n",
       "1               -1.0               0              1.0             -1.0   \n",
       "7               -1.0               0              0.0             -1.0   \n",
       "1               -1.0               0             -1.0             -1.0   \n",
       "0                0.0               1              0.0              0.0   \n",
       "\n",
       "   activation_sigmoid  activation_softmax  activation_softplus  \\\n",
       "1                 0.0                -1.0                 -1.0   \n",
       "7                 0.0                -1.0                 -1.0   \n",
       "1                -1.0                -1.0                 -1.0   \n",
       "0                 0.0                 0.0                  0.0   \n",
       "\n",
       "   activation_softsign  activation_tanh  filters  input_size  kernel_size  \\\n",
       "1                 -1.0                0     32.0       16000          3.0   \n",
       "7                 -1.0                1     -1.0       32000         -1.0   \n",
       "1                 -1.0                1     -1.0          71         -1.0   \n",
       "0                  0.0                0     -1.0         500         -1.0   \n",
       "\n",
       "   output_size  stride_size  units  mem_kb_actual  mem_kb_pred  \n",
       "1        16000          1.0   -1.0         64.000    36.045711  \n",
       "7           48         -1.0   48.0         32.000    27.091656  \n",
       "1          768         -1.0  256.0          1.024     7.303139  \n",
       "0        16000         -1.0   -1.0         64.000    24.042503  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn_mem_stacked_1, X_test, y_test = stacked_regression_model(cleaned_rnn, '[mem KB]')\n",
    "\n",
    "y_pred = rnn_mem_stacked_1.predict(X_test)\n",
    "\n",
    "print(\"MSE:\", mean_squared_error(y_test, y_pred))\n",
    "rnn_mem_stacked_1_mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "pd.concat([X_test, pd.DataFrame({'mem_kb_actual': y_test, 'mem_kb_pred': y_pred})], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brian/anaconda/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.2947922495872289\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brian/anaconda/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/brian/anaconda/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/brian/anaconda/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/brian/anaconda/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/brian/anaconda/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>activation_elu</th>\n",
       "      <th>activation_exponential</th>\n",
       "      <th>activation_hard_sigmoid</th>\n",
       "      <th>activation_linear</th>\n",
       "      <th>activation_nan</th>\n",
       "      <th>activation_relu</th>\n",
       "      <th>activation_selu</th>\n",
       "      <th>activation_sigmoid</th>\n",
       "      <th>activation_softmax</th>\n",
       "      <th>activation_softplus</th>\n",
       "      <th>activation_softsign</th>\n",
       "      <th>activation_tanh</th>\n",
       "      <th>filters</th>\n",
       "      <th>input_size</th>\n",
       "      <th>kernel_size</th>\n",
       "      <th>output_size</th>\n",
       "      <th>stride_size</th>\n",
       "      <th>units</th>\n",
       "      <th>avg_ms_actual</th>\n",
       "      <th>avg_ms_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2500</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>8000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.941</td>\n",
       "      <td>0.598679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>605</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>768</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>256.0</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.631385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>16000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>8000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.610192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>48</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.600166</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   activation_elu  activation_exponential  activation_hard_sigmoid  \\\n",
       "4            -1.0                    -1.0                     -1.0   \n",
       "3            -1.0                    -1.0                     -1.0   \n",
       "2            -1.0                    -1.0                     -1.0   \n",
       "8            -1.0                    -1.0                     -1.0   \n",
       "\n",
       "   activation_linear  activation_nan  activation_relu  activation_selu  \\\n",
       "4               -1.0               0              0.0             -1.0   \n",
       "3               -1.0               0             -1.0             -1.0   \n",
       "2               -1.0               1              0.0             -1.0   \n",
       "8               -1.0               0              0.0             -1.0   \n",
       "\n",
       "   activation_sigmoid  activation_softmax  activation_softplus  \\\n",
       "4                 0.0                -1.0                 -1.0   \n",
       "3                -1.0                -1.0                 -1.0   \n",
       "2                 0.0                -1.0                 -1.0   \n",
       "8                 1.0                -1.0                 -1.0   \n",
       "\n",
       "   activation_softsign  activation_tanh  filters  input_size  kernel_size  \\\n",
       "4                 -1.0                1     -1.0        2500         -1.0   \n",
       "3                 -1.0                1     -1.0         605         -1.0   \n",
       "2                 -1.0                0     -1.0       16000         -1.0   \n",
       "8                 -1.0                0     -1.0          48         -1.0   \n",
       "\n",
       "   output_size  stride_size  units  avg_ms_actual  avg_ms_pred  \n",
       "4         8000         -1.0   32.0          0.941     0.598679  \n",
       "3          768         -1.0  256.0          0.008     0.631385  \n",
       "2         8000          2.0   -1.0          0.039     0.610192  \n",
       "8            1         -1.0    1.0          0.011     0.600166  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn_ms_stacked_2, X_test, y_test = stacked_regression_model_2(cleaned_rnn, '[avg ms]')\n",
    "\n",
    "y_pred = rnn_ms_stacked_2.predict(X_test)\n",
    "\n",
    "print(\"MSE:\", mean_squared_error(y_test, y_pred))\n",
    "rnn_ms_stacked_2_mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "pd.concat([X_test, pd.DataFrame({'avg_ms_actual': y_test, 'avg_ms_pred': y_pred})], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brian/anaconda/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 631.1786728780157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brian/anaconda/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/brian/anaconda/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/brian/anaconda/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/brian/anaconda/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/brian/anaconda/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>activation_elu</th>\n",
       "      <th>activation_exponential</th>\n",
       "      <th>activation_hard_sigmoid</th>\n",
       "      <th>activation_linear</th>\n",
       "      <th>activation_nan</th>\n",
       "      <th>activation_relu</th>\n",
       "      <th>activation_selu</th>\n",
       "      <th>activation_sigmoid</th>\n",
       "      <th>activation_softmax</th>\n",
       "      <th>activation_softplus</th>\n",
       "      <th>activation_softsign</th>\n",
       "      <th>activation_tanh</th>\n",
       "      <th>filters</th>\n",
       "      <th>input_size</th>\n",
       "      <th>kernel_size</th>\n",
       "      <th>output_size</th>\n",
       "      <th>stride_size</th>\n",
       "      <th>units</th>\n",
       "      <th>mem_kb_actual</th>\n",
       "      <th>mem_kb_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>500</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>16000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>64.000</td>\n",
       "      <td>41.050608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>8000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>16000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>32.000</td>\n",
       "      <td>50.459367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>16000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>32000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>32.000</td>\n",
       "      <td>67.846760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>48</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.004</td>\n",
       "      <td>19.299120</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   activation_elu  activation_exponential  activation_hard_sigmoid  \\\n",
       "0             0.0                     0.0                      0.0   \n",
       "5            -1.0                    -1.0                     -1.0   \n",
       "6            -1.0                    -1.0                     -1.0   \n",
       "8            -1.0                    -1.0                     -1.0   \n",
       "\n",
       "   activation_linear  activation_nan  activation_relu  activation_selu  \\\n",
       "0                0.0               1              0.0              0.0   \n",
       "5               -1.0               0              0.0             -1.0   \n",
       "6               -1.0               0              0.0             -1.0   \n",
       "8               -1.0               0              0.0             -1.0   \n",
       "\n",
       "   activation_sigmoid  activation_softmax  activation_softplus  \\\n",
       "0                 0.0                 0.0                  0.0   \n",
       "5                 0.0                -1.0                 -1.0   \n",
       "6                 0.0                -1.0                 -1.0   \n",
       "8                 1.0                -1.0                 -1.0   \n",
       "\n",
       "   activation_softsign  activation_tanh  filters  input_size  kernel_size  \\\n",
       "0                  0.0                0     -1.0         500         -1.0   \n",
       "5                 -1.0                1     -1.0        8000         -1.0   \n",
       "6                 -1.0                1     -1.0       16000         -1.0   \n",
       "8                 -1.0                0     -1.0          48         -1.0   \n",
       "\n",
       "   output_size  stride_size  units  mem_kb_actual  mem_kb_pred  \n",
       "0        16000         -1.0   -1.0         64.000    41.050608  \n",
       "5        16000         -1.0   64.0         32.000    50.459367  \n",
       "6        32000         -1.0  128.0         32.000    67.846760  \n",
       "8            1         -1.0    1.0          0.004    19.299120  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn_mem_stacked_2, X_test, y_test = stacked_regression_model(cleaned_rnn, '[mem KB]')\n",
    "\n",
    "y_pred = rnn_mem_stacked_2.predict(X_test)\n",
    "\n",
    "print(\"MSE:\", mean_squared_error(y_test, y_pred))\n",
    "rnn_mem_stacked_2_mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "pd.concat([X_test, pd.DataFrame({'mem_kb_actual': y_test, 'mem_kb_pred': y_pred})], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAe8AAAFlCAYAAADComBzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3XlclOXi///3sCUIiSbZKcOUwg1N\n7biAW0i5o6K5FpraoqmZJskxt8xccss10z52Svt0NGzRTmWZpmZKUrlmWXpcSANK/CCggMz1+8Of\n843DkqaD5+K8no+Hj4dz3zP3fc3AzGuum1kcxhgjAABgDY/rPQAAAHBliDcAAJYh3gAAWIZ4AwBg\nGeINAIBliDcAAJYh3vhTkpOTVbNmTT300EOF1sXHx6tmzZo6ffq0JGn37t2KjY1VdHS0OnfurEce\neUQ//vij6/w1a9ZUdHS0unbtWuBfcnLyFY1p0qRJatOmjebNm1dgeWJiourXr19g2/fdd5+GDBmi\n9PT0P3Ht3W/+/Pl677333L6fgwcP6r777lP37t2LvL03b96s2NhYde3aVZ06ddJTTz2lU6dOSbp4\nu9aqVUvbt28vcJkpU6Zo4cKFki7+LrRv317Z2dkFztOwYcNif76HDx/WiBEjFB0drS5duuihhx5S\nUlLStbi6V2X8+PHav3//FZ3v2Wef1ZdffnlN9t+nTx917dpVHTt2VO3atV2/y08//bT27dunJ598\n8prsB5YwwJ9w4sQJU69ePRMREWGSk5Ndy7Oyssz9999vQkNDzW+//WZycnJMkyZNzP79+13nee+9\n90zr1q3NhQsXjDHGdd6rVbNmTXPq1KlCy3fu3Gk6depUYNmFCxfM0KFDzezZs696vzZbuHChGTdu\nXJHr1q1bZzp06GCOHj1qjDHG6XSapUuXmvvuu8/k5OSYnTt3mrCwMNO8efMCP7/nnnvOLFiwwBhj\nzNixY01YWFihfTRo0MCcOHGi0D4PHz5smjdvbrZu3epa9uWXX5p77rnHHDp06Kqv79WIjIw0e/fu\nvWbn+7NOnDhhGjRo4Lbtww5e1/vJA+zl6empDh06aP369RoyZIgk6ZNPPlFUVJRWrFghSTp37pzO\nnj1bYObVpUsX+fv7Kz8/X56enle0zx9//FFTpkzRmTNn5HA4NGjQIHXr1k39+vWTMUaPPvqoJk2a\npL/+9a8lbiczM1OnT59Wo0aNJElnz57VCy+8oEOHDikvL0/h4eF65pln5OXlpS1btmj27Nny8PBQ\n7dq19eWXX+p///d/9dVXXykhIUHnzp2Tv7+/Vq5cqbfffltvvfWWnE6nAgMDNWHCBIWEhCgpKUkz\nZsyQ0+mUJD3++ONq165dscvj4+N11113afDgwUpKStKLL76oc+fOydvbW0899ZRatWqld955R59+\n+qk8PDx07NgxlStXTjNnzlRISEih67t48WL985//lKenp6pXr64JEyZox44deuutt5Sfn6/z589r\nzpw5BS4zb948Pf/886pWrZokyeFw6LHHHtNf/vIX5ebmSpKqVaum+vXra9y4cVq6dGmRt3X//v31\n/vvva8OGDWrXrl2JP5fly5erR48eatmypWtZeHi45syZo3LlykmSNm7cqEWLFsnpdKp8+fL629/+\npvr162vhwoU6fvy4UlJSlJaWprp166pp06Z67733lJycrLi4OHXu3FkLFy7UsWPH9MsvvygtLU21\natXSCy+8IH9/f7Vp00bz589XvXr1JMl1euPGjUpNTdWYMWP04osvyhijWbNmKTc3V2lpaYqIiNC0\nadM0b968AuebPXu2HnzwQbVv377Ecf/8889KS0vTzz//rCpVqmjWrFm6+eabS7ytfi8xMVHPP/+8\nPvjgA8XHx6tcuXI6dOiQfvvtN7Vp00aBgYHavHmz0tLSNHXqVIWHhys3N1ezZ8/Wrl27lJ+frzp1\n6mj8+PHy9/e/7P3iOrrezx5gp0vP/vft22fat2/vWj5gwADzww8/FJhNr1ixwtSvX9+0adPGjBkz\nxrz99tsmOzvbdZnQ0FDTuXNn06VLF9e/J554otA+8/LyTFRUlNmwYYMxxphffvnFtGzZ0nzzzTeu\n7RQ1g9+5c6epV6+e6dKli+nYsaNp1qyZ6datm3nllVdMbm6uMcaY+Ph488YbbxhjLs7Kx4wZY5Yt\nW2ZOnz5tmjRpYg4ePGiMMeadd94xoaGh5sSJE2bt2rWmcePG5uzZs8YYYxITE02/fv1c123btm2u\n26Z///7mgw8+MMYYc/DgQTN58uQSl48dO9a8+uqr5vTp0yY8PNzs3r3bGGPMoUOHTJMmTczx48fN\n2rVrzT333OM62jBlyhTzzDPPFLr+CQkJpnfv3iYrK8sYY8yCBQvMoEGDXP9/7rnnCl3m9OnTJjQ0\ntMDPqajbtVOnTiYrK8u0bdvWrFy50hhTeOb96quvmm3btpkmTZqYkydPGmOKn3l37tzZfP7558Xu\n86effjIRERHm+PHjxpiLs/LmzZubs2fPmgULFpjIyEiTkZFhzp07Zxo3bmymT59ujDHm008/NW3b\ntnVd51atWpm0tDSTn59vRo8ebWbMmGGMKTxr/v3p3/9/1KhRZufOncYYYzIzM03Tpk3Nvn37Cp3v\noYceMh999NEfjjsqKsr1e/T444+b+fPnF3sbFDXz/v3RpbFjx5qePXua3Nxck5qaakJDQ12/23//\n+9/NwIEDjTEXj7rMmDHDOJ1OY4wxc+bMMZMmTSp2v/jPwswbVyUsLEyenp7av3+/brrpJmVlZSk0\nNLTAeQYOHKiePXtq165d2rVrl5YvX67ly5crISFBAQEBkqTXX39dlSpVKnFfR48eVU5Ojtq2bStJ\nqlKlitq2batt27apYcOGJV42ODhY77//viRp7dq1mjdvnjp06CBvb29J0ueff659+/YpISFBknT+\n/HlJUlJSkkJCQlSrVi1JUkxMjKZOnerabs2aNV0zlc8//1zHjh1Tnz59XOszMjJ05swZdejQQVOm\nTNGmTZsUERGh0aNHS1Kxyy/Zu3evgoODdffdd0uS7rrrLjVq1EhfffWVHA6H6tatq1tuuUWSVKdO\nHX366aeFrvvWrVvVvXt3+fn5Sbo4E166dKlr9lwUD4+LL4e5dESgJH5+fpo7d6769++vJk2aFHme\nFi1aKCYmRnFxcXrjjTeK3ZbD4Shxnzt37lSzZs10++23S7o4K69UqZLrb8wRERGu36mbb77ZNYMP\nDg7WmTNnXNtp3769KleuLEl64IEHNG3aNI0dO/YPr+slM2bM0NatW7V06VIdOXJEOTk5hf6ufyXj\nbtKkiev3qE6dOvq///u/yx5LUSIjI+Xt7a2goCD5+fkVeTt8/vnnOnv2rOtv8nl5ebrpppuuar8o\nPcQbV61Lly5at26dKlWqpK5duxZY9/XXX+vbb7/VI488osjISEVGRmr06NHq3Lmztm/frvbt21/2\nfvLz8+VwOAosM8bowoULVzTeHj16aM+ePRo5cqTWrFkjLy8vOZ1OzZ8/33XIOSMjQw6HQ7t27ZL5\nt4//vxQ2Sa4gShdD17VrV8XFxblOp6amqkKFCurTp48iIyO1fft2bdu2TYsWLdLHH39c7PLLuc7e\n3t6uQ8nSxfD9+1gvjeP323A6nX94m1WoUEF33HGH9uzZo4iIiALrRo4cqaFDhxZYVrduXQ0dOlRP\nP/206tevX+Q2R48erd69exd7eF2SGjRooN27dysyMrLA8kWLFik4OLjQdZEK/g74+PgUWOflVfRD\n3O//XON0Ogv8TH9/Gxb3BOehhx5SzZo11bJlS3Xo0EF79uwp8rb//T5KGvfl/ByvxOXcDk6nU+PG\njVPr1q0lSVlZWcrJybmq/aL08GpzXLWuXbvq448/1ocffqjOnTsXWFepUiW9/PLLBV4tnJaWpszM\nzEIz9D9So0YNeXl56ZNPPpEkpaSkaMOGDYXicjnGjBmjU6dO6c0335R0cWb497//XcYY5ebmaujQ\noVq1apUaNWqko0eP6vvvv5ckbdiwwRX2f9eiRQv985//VGpqqiTprbfe0oABAyRdfKXwwYMH1b17\ndz3//PPKyMhQWlpascsvadCggY4cOaK9e/dKuvg3/127dhU7wy1Ky5YttXbtWtfMcOXKlWrcuHGh\nB/h/N3z4cL3wwgs6duyYpItPJJYsWaLvv/9eNWrUKHT+wYMHq3Llylq3bl2R2/Px8dGcOXO0YsUK\n15GNorbx9ttv64svvnAt27p1q1auXKlatWopPDxcX3zxhU6cOCFJ2rFjh06dOuU6MnG5PvvsM509\ne1ZOp1Nr1qxxPVn4/Ww4MTGxwM/C09NTFy5cUEZGhvbt26cxY8aobdu2+uWXX3T8+HHXEYNL5/u9\nazXua6lFixZ68803lZubK6fTqQkTJmju3LnXbTy4Msy8cdWqVKmikJAQBQQEKDAwsMC66tWra/Hi\nxZo3b55++eUX3XDDDQoICNC0adMKBGDAgAEFZj/SxZnapVmBJHl7e2vJkiWaOnWqFi5cqPz8fA0b\nNkzNmjW74jHfeOONGjNmjKZPn65OnTrp2Wef1QsvvKDo6Gjl5eUpIiJCjzzyiLy9vTV37lyNHTtW\nHh4eCgsLk5eXl3x9fQtts0WLFnr00Uc1aNAgORwO+fv7a9GiRXI4HBozZoymTZuml156SQ6HQ8OH\nD1fVqlWLXX5JpUqVNH/+fD3//PM6f/68HA6Hpk+frurVq+vbb7+9rOv6wAMP6NSpU+rZs6ecTqeq\nVaum2bNn/+HloqOjZYzR6NGjdeHCBeXk5Khu3bp6/fXXiwy/w+HQzJkz1aVLl2K3WaNGDY0dO1bj\nx48vcn21atW0dOlSvfTSS5o5c6acTqfrCeClJ3uTJk3S8OHDlZ+fr3Llymnp0qWuQ+WXq3Llynr0\n0UeVnp6uxo0bu15wOWbMGE2ePFmrV69W3bp1VbduXddl7r//fsXFxWny5Ml67LHHFBMTIz8/P1Wp\nUkWNGjXSsWPHFB4eXuB8l9x5553XZNzX0hNPPKGZM2cqJiZG+fn5ql27tuLj46/beHBlHOZqj88A\nZVhmZqaWLFmiESNGyNfXVwcOHNDjjz+ubdu2FTn7xn++hQsXKj09XRMnTrzeQwH+NGbeQAn8/f3l\n7e2tBx54QF5eXvLy8nLNkgHgemHmDQCAZXjBGgAAliHeAABYhngDAGAZa16wlpZ29noPAX9SxYp+\nSk8v/tOnALgX90E7BQUV/1ZCZt5wOy+vK/vyEQDXFvfBsod4AwBgGeINAIBliDcAAJYh3gAAWIZ4\nAwBgGeINAIBliDcAAJYh3gAAWIZ4AwBgGeINAIBliDcAAJYh3gAAWMaabxUDUPYMmrHpeg8BuGZW\nxLcptX0x8wYAwDLEGwAAyxBvAAAsQ7wBALAM8QYAwDLEGwAAyxBvAAAsQ7wBALAM8QYAwDLEGwAA\nyxBvAAAsQ7wBALAM8QYAwDLEGwAAyxBvAAAsQ7wBALAM8QYAwDLEGwAAyxBvAAAsQ7wBALAM8QYA\nwDLEGwAAyxBvAAAsQ7wBALAM8QYAwDLEGwAAyxBvAAAsQ7wBALAM8QYAwDLEGwAAyxBvAAAsQ7wB\nALCMlzs2mpeXp3Hjxunnn39Wbm6uhg4dqqioKNf6TZs2afHixfLy8lKPHj3Uq1cvdwwDAIAyyS3x\nXrdunQIDAzVr1iylp6crJibGFe+8vDxNnz5dCQkJ8vX1Vd++fRUZGamgoCB3DAUAgDLHLYfN27dv\nr5EjR7pOe3p6uv5/+PBhBQcHq0KFCvLx8dE999yjpKQkdwwDAIAyyS0z7/Lly0uSMjMz9eSTT+qp\np55yrcvMzFRAQECB82ZmZrpjGAAAlEluibcknTp1SsOGDVO/fv0UHR3tWu7v76+srCzX6aysrAIx\nL07Fin7y8vL8w/PhP1NQ0B//jAHAZqX5OOeWeP/6668aNGiQJk6cqPDw8ALrQkJCdOzYMZ05c0Z+\nfn5KSkrS4MGD/3Cb6enZ7hgqSkFQUIDS0s5e72EAgFtd68e5kp4MuCXeS5cuVUZGhpYsWaIlS5ZI\nknr27Klz586pd+/eio+P1+DBg2WMUY8ePVSlShV3DAMAgDLJYYwx13sQl4OZm72YeaM4g2Zsut5D\nAK6ZFfFtrun2Spp58yEtAABYhngDAGAZ4g0AgGWINwAAliHeAABYhngDAGAZ4g0AgGWINwAAliHe\nAABYhngDAGAZ4g0AgGWINwAAliHeAABYhngDAGAZ4g0AgGWINwAAliHeAABYhngDAGAZ4g0AgGWI\nNwAAliHeAABYhngDAGAZ4g0AgGWINwAAliHeAABYhngDAGAZ4g0AgGWINwAAliHeAABYhngDAGAZ\n4g0AgGWINwAAliHeAABYhngDAGAZ4g0AgGWINwAAliHeAABYhngDAGAZ4g0AgGWINwAAliHeAABY\nhngDAGAZ4g0AgGWINwAAliHeAABYhngDAGAZ4g0AgGWINwAAliHeAABYhngDAGAZ4g0AgGWINwAA\nliHeAABYhngDAGAZ4g0AgGXcGu89e/YoNja20PLXXntNnTp1UmxsrGJjY3XkyBF3DgMAgDLFy10b\nXr58udatWydfX99C6w4cOKCZM2cqLCzMXbsHAKDMctvMOzg4WAsXLixy3YEDB7Rs2TL17dtXr7zy\niruGAABAmeS2mXe7du2UnJxc5LpOnTqpX79+8vf31/Dhw7V582ZFRkaWuL2KFf3k5eXpjqGiFAQF\nBVzvIQCAW5Xm45zb4l0cY4wGDBiggICLV7J169b67rvv/jDe6enZpTE8uEFQUIDS0s5e72EAgFtd\n68e5kp4MlPqrzTMzM9W5c2dlZWXJGKPExET+9g0AwBUotZn3+vXrlZ2drd69e2vUqFHq37+/fHx8\nFB4ertatW5fWMAAAsJ7DGGOu9yAuB4dd7cVhcxRn0IxN13sIwDWzIr7NNd3ef9RhcwAAcHWINwAA\nliHeAABYhngDAGAZ4g0AgGWINwAAliHeAABYhngDAGAZ4g0AgGWINwAAliHeAABYhngDAGAZ4g0A\ngGWINwAAliHeAABYhngDAGAZ4g0AgGWINwAAliHeAABYhngDAGAZ4g0AgGWINwAAlikx3ikpKcWu\n27FjxzUfDAAA+GMlxnvIkCGu/48YMaLAuhdffNE9IwIAACUqMd7GGNf/T5w4Uew6AABQekqMt8Ph\nKPL/RZ0GAAClgxesAQBgGa+SVqalpWnRokWF/n/pNAAAKH0lzrz79OlT5P+LOg0AAEpHiTPv4cOH\nl9Y4AADAZSpx5n3+/HnNnDlTe/fulSRNnz5dDRs21IMPPljie8ABAID7lBjvF154QefOndNtt92m\nLVu2aP369Xr33Xf14IMPasqUKaU1RgAA8DslHjbfvXu31q9fL0n67LPP1KFDB91xxx264447Crx4\nDQAAlJ4SZ94eHv9vdWJiosLDw12n8/Ly3DcqAABQrBJn3oGBgdq7d6+ysrKUmpqqiIgISRdDfsst\nt5TKAAEAQEElxnvcuHEaNWqUfvvtN02aNEl+fn5asmSJVq5cqVdeeaW0xggAAH6nxHgfPHhQjz32\nmOtzzN977z0FBQVpyJAhOnLkiOrXr18qgwQAAP9PifGOj4/XTTfdpPDwcHl7exda361bN7cNDAAA\nFK3EeL/77rv68MMPtX37dtWqVUsdO3ZUREREgReyAQCA0lVivGvXrq3atWvr6aef1r59+/Thhx9q\n7ty5CgsLU6dOndS0adPSGicAAPj/lRjv36tXr57q1aunpKQkzZ49W+vXr9e3337rzrEBAIAi/GG8\njTHatWuXPv74Y23dulW1a9dWbGysIiMjS2N8AADg35QY70mTJmnbtm2qU6eOOnTooLi4OPn6+pbW\n2AAAQBFKjPfq1asVGBio7777Tt99953mzp1bYP1nn33m1sEBAIDCSow3cQYA4D9PifG+7bbbSmsc\nAADgMvGGbQAALEO8AQCwDPEGAMAyxBsAAMsQbwAALEO8AQCwDPEGAMAyxBsAAMu4Nd579uxRbGxs\noeWbNm1Sjx491Lt3b61Zs8adQwAAoMy57K8EvVLLly/XunXrCn2RSV5enqZPn66EhAT5+vqqb9++\nioyMVFBQkLuGAgBAmeK2mXdwcLAWLlxYaPnhw4cVHBysChUqyMfHR/fcc4+SkpLcNQwAAMoct828\n27Vrp+Tk5ELLMzMzFRAQ4Dpdvnx5ZWZm/uH2Klb0k5eX5zUdI0pPUFDAH58JACxWmo9zbot3cfz9\n/ZWVleU6nZWVVSDmxUlPz3bnsOBGQUEBSks7e72HAQBuda0f50p6MlDqrzYPCQnRsWPHdObMGeXm\n5iopKUkNGzYs7WEAAGCtUpt5r1+/XtnZ2erdu7fi4+M1ePBgGWPUo0cPValSpbSGAQCA9RzGGHO9\nB3E5OOxqLw6boziDZmy63kMArpkV8W2u6fb+ow6bAwCAq0O8AQCwDPEGAMAyxBsAAMsQbwAALEO8\nAQCwDPEGAMAyxBsAAMsQbwAALEO8AQCwDPEGAMAyxBsAAMsQbwAALEO8AQCwDPEGAMAyxBsAAMsQ\nbwAALEO8AQCwDPEGAMAyxBsAAMsQbwAALEO8AQCwDPEGAMAyxBsAAMsQbwAALEO8AQCwDPEGAMAy\nxBsAAMsQbwAALEO8AQCwDPEGAMAyxBsAAMsQbwAALEO8AQCwDPEGAMAyxBsAAMsQbwAALEO8AQCw\nDPEGAMAyxBsAAMsQbwAALEO8AQCwDPEGAMAyxBsAAMsQbwAALEO8AQCwDPEGAMAyxBsAAMsQbwAA\nLEO8AQCwDPEGAMAyxBsAAMsQbwAALEO8AQCwjJe7Nux0OjV58mT98MMP8vHx0dSpU1WtWjXX+qlT\np+qbb75R+fLlJUlLlixRQECAu4YDAECZ4bZ4b9y4Ubm5uVq9erV2796tGTNm6OWXX3atP3DggF59\n9VVVqlTJXUMAAKBMctth86+//lotW7aUJDVo0ED79+93rXM6nTp27JgmTpyoPn36KCEhwV3DAACg\nzHHbzDszM1P+/v6u056enrpw4YK8vLyUnZ2thx56SAMHDlR+fr769++vsLAw1apVq9jtVazoJy8v\nT3cNF24WFMSfRACUbaX5OOe2ePv7+ysrK8t12ul0ysvr4u58fX3Vv39/+fr6SpKaNWum77//vsR4\np6dnu2uocLOgoAClpZ293sMAALe61o9zJT0ZcNth80aNGmnr1q2SpN27dys0NNS17ujRo+rXr5/y\n8/OVl5enb775RnXr1nXXUAAAKFPcNvO+//77tX37dvXp00fGGE2bNk2vvfaagoODFRUVpejoaPXq\n1Uve3t7q2rWr7rrrLncNBQCAMsVhjDHXexCXg8Ou9uKwOYozaMam6z0E4JpZEd/mmm7vuhw2BwAA\n7kG8AQCwDPEGAMAyxBsAAMsQbwAALEO8AQCwDPEGAMAyxBsAAMsQbwAALEO8AQCwDPEGAMAyxBsA\nAMsQbwAALOO2rwT9T8e3GaGsudbfaATgPxczbwAALEO8AQCwDPEGAMAyxBsAAMsQbwAALEO8AQCw\nDPEGAMAyxBsAAMsQbwAALEO8AQCwDPEGAMAyxBsAAMsQbwAALEO8AQCwDPEGAMAyxBsAAMsQbwAA\nLEO8AQCwDPEGAMAyxBsAAMsQbwAALEO8AQCwDPEGAMAyxBsAAMsQbwAALEO8AQCwDPEGAMAyxBsA\nAMsQbwAALEO8AQCwDPEGAMAyxBsAAMsQbwAALEO8AQCwDPEGAMAyxBsAAMsQbwAALEO8AQCwDPEG\nAMAyxBsAAMu4Ld5Op1MTJ05U7969FRsbq2PHjhVYv2bNGnXv3l29evXS5s2b3TUMAADKHC93bXjj\nxo3Kzc3V6tWrtXv3bs2YMUMvv/yyJCktLU0rV67U2rVrlZOTo379+ql58+by8fFx13AAACgz3Dbz\n/vrrr9WyZUtJUoMGDbR//37Xur1796phw4by8fFRQECAgoOD9f3337trKAAAlClum3lnZmbK39/f\nddrT01MXLlyQl5eXMjMzFRAQ4FpXvnx5ZWZmlri9oKCAEtdfqfVzul7T7QG4ctwPgT/HbTNvf39/\nZWVluU47nU55eXkVuS4rK6tAzAEAQPHcFu9GjRpp69atkqTdu3crNDTUta5+/fr6+uuvlZOTo7Nn\nz+rw4cMF1gMAgOI5jDHGHRt2Op2aPHmyDh06JGOMpk2bpq1btyo4OFhRUVFas2aNVq9eLWOMHn/8\ncbVr184dwwAAoMxxW7wBAIB78CEtAABYhngDAGAZt71VDNdXYmKinnrqKd15552SLr6iv2rVqpo9\ne/ZVfRjOqFGj1KdPHzVt2vSqx/jOO+9owYIFuv32213LHn74YUVFRV31tn9v165dCggIUK1ata7p\ndoGSLFu2TF9++aU8PDzkcDg0atQohYWF6YcfflBGRoYaN2582dtKTEzUP/7xD82bN++KxvDWW2/p\n119/1YgRIy7r/GlpaVq8eLEmT55c4H7TvHlzbd++vdjLxcfH68CBAwoMDJQxRmfOnNHAgQPVo0eP\nUruf/7ch3mVYs2bNCtzZn376aW3atEnt27e/jqMqqHPnzhozZoxb97F27Vp17NiReKPU/PTTT9q0\naZPeeustORwOHTx4UGPHjtW6dev0ySefqHLlylcU79ISFBSkyZMnS7ry+01cXJxatWolSTpz5ow6\nd+6s7t27Syqd+/l/G+L9XyI3N1epqamqUKGC8vPzNXHiRP3yyy9KT09Xq1at9NRTTyk+Pl4+Pj76\n+eeflZqaqhkzZqhu3bp688039fbbbysoKEi//fabJCkvL0/jxo3TiRMnlJ+fr4EDB6pjx46KjY1V\nzZo19eOPP8rPz09//etf9cUXXygjI0MrVqxQhQoV/nCsGRkZiouLU2ZmpvLz8zVy5EiFh4erc+fO\nuuOOO+Tj46PnnntOzz77rNLT0yVJ48ePV82aNRUfH6/jx48rJydHgwcPVnBwsLZt26YDBw7ozjvv\n1K233urW2xmQpEqVKunkyZNKSEhQq1atVLt2bSUkJCglJUXvvvuuvL29VbduXZ08eVJvvvmm63Lz\n589XYGCgpk6dqr179yovL0/A8SjDAAAKPklEQVQjRoxwfQ7GuXPnNHz4cHXt2lVdunTRnDlztGvX\nLhlj9PDDD6tDhw5KSkrStGnTVKFCBXl4eKhBgwYFxhYTE6NXX31VN954o5o2bapVq1apTp06iomJ\n0Zw5cxQfH6+JEycWuN/k5ubq6aef1smTJxUYGKgFCxbI29u72Ov/66+/ysfHRw6Hwz03MIh3WbZz\n507Fxsbqt99+k4eHh3r16qXw8HAlJyerQYMG6tmzp3JyclzxlqRbb71VU6ZMcb2VLy4uTm+88YbW\nr18vh8Pheia9evVqVaxYUbNmzVJmZqa6d++uZs2aSbr4Pv7x48dr8ODBKleunF577TWNHTtWu3bt\n0n333VdgjB988IH27NkjSapYsaIWLFigl19+WRERERowYIBSUlLUt29fbdy4UdnZ2XriiSdUp04d\nzZo1S82aNVO/fv109OhR/e1vf9Py5cuVmJiotWvXSpK2b9+usLAwtWzZUh07diTcKDWVKlXSyy+/\nrFWrVmnx4sUqV66cRo0apXbt2ikmJkaVK1dW/fr19eWXX2rZsmXy9fXVxIkT9cUXX8jX11fp6elK\nSEhQWlqaVq1apYiICGVnZ2vIkCHq37+/oqKitGXLFiUnJ+sf//iHcnJy1KtXLzVv3lzTp0/XnDlz\nVL16dU2aNKnQ2KKiorRt2zbdcsstqlq1qrZv3y4fHx/XE2NJhe432dnZGjVqlKpWrarY2FgdPHhQ\n9evXL7DdWbNmaenSpTp58qRCQkI0f/5817qi7ue4OsS7DLt02Dw9PV2DBg1S1apVJUmBgYHat2+f\ndu7cKX9/f+Xm5rouU7t2bUnSLbfcom+++UZHjhzRnXfe6bpTX7rDHj58WBEREZIufmJeSEiITpw4\nIUmqW7euJOnGG290/c39xhtvVE5OTqExFnU47fDhw4qOjpYkValSRf7+/jp9+rQkqXr16pKkQ4cO\naefOnfroo48kXZyt+/v7a8KECZowYYIyMzPVpUuXq7r9gD/r2LFj8vf31/Tp0yVJ+/bt02OPPVbo\ntSI33XSTxo4dq/Lly+vIkSNq0KCB/vWvf7lmy0FBQRo1apQSExP11VdfqWbNmq7766FDh3TgwAHF\nxsZKki5cuKCTJ08qJSXFdT9p1KiRjh8/XmCfbdu21dKlS/WXv/xFo0aN0sqVK2WMUdu2bYu9PhUq\nVHA9flSuXFnnzp0rdJ5Lh823bNmi2bNnKzg42LWOw+bXHq82/y9waYY8fvx4paam6p133lFAQIDm\nzJmjQYMG6fz587r0dv9/P8x1++2366efftL58+eVn5+vgwcPSpJCQkKUlJQk6eLn2B86dMh1575a\nv992SkqKMjIyFBgYKEny8Lj4K1ujRg09/PDDWrlypV566SVFR0crNTVVBw4c0OLFi7Vs2TLNmjVL\nFy5ckMPhEB9ngNL0ww8/aPLkya4nrNWrV1dAQIA8PT3lcDjkdDp19uxZLViwQPPmzdPUqVN1ww03\nyBijGjVqaN++fZKks2fPavDgwZKke++9V4sWLdJLL72klJQU1ahRQ02bNtXKlSv1+uuvq0OHDqpa\ntaqCgoJ0+PBhSXJt5/dCQ0OVnJysvXv3qnXr1srOztZnn33m+nv1Jb+/31zJ4e/WrVsrKipKEyZM\nuPIbDpeNmfd/iTvvvFOxsbGaOnWqRowYodGjR+vrr7+Wr6+vqlWrptTU1CIvV6lSJY0cOVJ9+vRR\npUqV5OvrK0nq1auXJkyYoL59+yonJ0fDhw/XTTfddE3G+vjjj2vcuHHasGGDzp8/rylTprg+F/+S\nIUOG6Nlnn9WaNWuUmZmp4cOHKygoSGlpaerWrZv8/Pw0aNAgeXl56e6779bs2bNVtWpVhYSEXJMx\nAiVp27atDh8+rJ49e8rPz0/GGD3zzDMKCAhQWFiYXnzxRYWEhKhRo0aKiYmRn5+fbrzxRqWmpqp7\n9+7asWOH+vbtq/z8fA0bNsy13cqVK2vEiBEaN26cXn31VX311Vfq16+fsrOzdd9998nf31+zZs1y\nzebLly9f5OtMGjdurOTkZHl4eKhx48b66aefVL58eddrSCQVuN9cqSeeeELdu3fX559//qduP/wx\nPmENAADLcNgcAADLEG8AACxDvAEAsAzxBgDAMsQbAADL8FYxwHLJyclq3769621wTqdTWVlZ6tat\nm5588snrPDoA7kC8gTLg5ptv1vvvv+86nZKSonbt2qlTp068tx0og4g3UAalpaXJGKPy5ctr2bJl\n+uijj5Sfn68WLVooLi5ODodDb7zxhlatWqWAgADVqFFDwcHBGjFihJo1a6awsDClpaUpISFBr732\nWqHLZ2VlafTo0fr1118lScOGDVNUVJRee+01vfvuu/Lw8FD9+vU1ZcoUOZ1OTZs2TTt27JDD4VCX\nLl302GOPKTExUbNmzZLT6dRdd92lmTNnXudbDbAH8QbKgNTUVHXt2lU5OTlKT09XvXr1tGjRIh06\ndEj79+9XQkKCHA6H4uLitG7dOtWsWVNvvvmm3nnnHXl7eys2Ntb1WdTp6el69NFH1bRpU23durXI\nyzudTt12221atmyZDh48qHXr1unee+/VK6+8om3btsnT01PPPvusUlJStHHjRp06dUrr1q1Tbm6u\nYmNjFRoaKl9fXx09elSbN292fWsWgMtDvIEy4NJhc6fTqRkzZujw4cNq3ry5Zs2apb1797q+De78\n+fO69dZbdfr0aUVGRsrf31+S1KlTJ2VkZLi2d/fdd0uSduzYUeTle/Tooblz5yolJUX33nuvhg0b\nJk9PTzVs2FAPPPCAoqKiNHDgQFWpUkWJiYmKiYmRp6enfH19FR0drR07dqhNmzauz/wGcGWIN1CG\neHh46JlnnlG3bt30P//zP8rPz9eAAQM0cOBASRe/fc3T01MJCQlyOp3FbqdcuXKSVOzly5cvr48+\n+kjbtm3T5s2btWLFCn344YdasmSJdu/era1bt+qRRx7R7NmzC+3HGKP8/PwC+wFwZXirGFDGeHl5\n6ZlnntGSJUtUp04dvf/++8rKytKFCxc0bNgwbdiwQeHh4dqyZYsyMzOVm5urTz75pMhvjmrWrFmR\nl1+1apUWLlyoDh06aNKkSTp9+rTOnDmjjh07KjQ0VCNHjlTz5s31ww8/qFmzZnrvvfeUn5+vc+fO\naf369YW+GhPAlWHmDZRBrVq1UsOGDZWUlKS2bduqV69eys/PV8uWLRUTEyOHw6H+/furd+/e8vPz\nU8WKFXXDDTcU2k6bNm30/fffF7r8pResRUdHy9PTU3FxcapUqZJ69+6tBx54QL6+vqpevbp69Ogh\nb29vHT16VF27dlVeXp6io6N1//33KzEx8TrcMkDZwLeKAf+F/vWvf2nLli16+OGHJUlDhw5Vz549\n1aZNm+s7MACXhZk38F/otttu0759+9S5c2c5HA61aNFCkZGR13tYAC4TM28AACzDC9YAALAM8QYA\nwDLEGwAAyxBvAAAsQ7wBALAM8QYAwDL/H084llH4C/ZxAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 576x396 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cnn_ms = [cnn_ms_rf_mse, cnn_ms_stacked_1_mse]#,cnn_ms_stacked_2_mse]\n",
    "plt.bar([i for i in range(len(cnn_ms))], cnn_ms, tick_label=[\n",
    "    'Random Forest',\n",
    "    'Stacked with RF',\n",
    "#     'Stacked with Polynomial',\n",
    "])\n",
    "plt.title('MSE of Regression of CNN Computation Time')\n",
    "plt.ylabel('MSE')\n",
    "\n",
    "plt.xlabel('Regressor')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfUAAAFlCAYAAADyLnFSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n1AEAsAShDgCAJQh1AAAs8f9WZNNXYl+w4QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 576x396 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rnn_ms = [rnn_ms_rf_mse, rnn_ms_stacked_1_mse]#, rnn_ms_stacked_2_mse]\n",
    "\n",
    "plt.bar([i for i in range(len(rnn_ms))], rnn_ms, tick_label=[\n",
    "    'Random Forest',\n",
    "    'Stacked with RF',\n",
    "#     'Stacked with Polynomial',\n",
    "])\n",
    "plt.title('MSE of Regression of RNN Computation Time')\n",
    "plt.ylabel('MSE')\n",
    "\n",
    "plt.xlabel('Regressor')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAggAAAFlCAYAAACOfhB6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<Figure size 576x396 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cnn_mem = [cnn_mem_rf_mse, cnn_mem_stacked_1_mse]\n",
    "plt.bar(range(len(cnn_mem)), cnn_mem, tick_label=[\"Random Forest\", \"Stacked with RF\"])\n",
    "\n",
    "plt.title('MSE of Regression of CNN Memory Usage')\n",
    "plt.ylabel('MSE')\n",
    "plt.xlabel('Regressor')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfIAAAFlCAYAAAAQ8morAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 576x396 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rnn_mem = [rnn_mem_rf_mse, rnn_mem_stacked_1_mse, rnn_mem_stacked_2_mse]\n",
    "\n",
    "plt.bar(range(len(rnn_mem)), rnn_mem, tick_label=[\n",
    "    \"Random Forest\",\n",
    "    \"Stacked with RF\",\n",
    "    \"Stacked with Polynomial\",\n",
    "])\n",
    "\n",
    "plt.title('MSE of Regression of RNN Memory Usage')\n",
    "plt.ylabel('MSE')\n",
    "plt.xlabel('Regressor')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_cnn_ms(model):\n",
    "    \n",
    "    layer_features = get_layer_features(model)\n",
    "    cleaned_features = clean(layer_features, inference=True)\n",
    "    \n",
    "    X = cleaned_features.drop(['name', 'input_shape', 'output_shape', 'strides'], axis=1)  # Features\n",
    "    \n",
    "    predicted = cnn_ms_rf.predict(X)\n",
    "    \n",
    "    return pd.DataFrame({'name': cleaned_features['name'], 'pred_ms': predicted})\n",
    "\n",
    "def predict_cnn_mem(model):\n",
    "    \n",
    "    layer_features = get_layer_features(model)\n",
    "    cleaned_features = clean(layer_features, inference=True)\n",
    "    \n",
    "    X = cleaned_features.drop(['name', 'input_shape', 'output_shape', 'strides'], axis=1)  # Features\n",
    "    \n",
    "    predicted = cnn_mem_rf.predict(X)\n",
    "    \n",
    "    return pd.DataFrame({'name': cleaned_features['name'], 'pred_mem': predicted})\n",
    "\n",
    "def predict_rnn_ms(model):\n",
    "    \n",
    "    layer_features = get_layer_features(model)\n",
    "    cleaned_features = clean(layer_features, inference=True)\n",
    "    \n",
    "    X = cleaned_features.drop(['name', 'input_shape', 'output_shape', 'strides'], axis=1)  # Features\n",
    "    \n",
    "    predicted = rnn_ms_rf.predict(X)\n",
    "    \n",
    "    return pd.DataFrame({'name': cleaned_features['name'], 'pred_ms': predicted})\n",
    "\n",
    "def predict_rnn_mem(model):\n",
    "    \n",
    "    layer_features = get_layer_features(model)\n",
    "    cleaned_features = clean(layer_features, inference=True)\n",
    "    \n",
    "    X = cleaned_features.drop(['name', 'input_shape', 'output_shape', 'strides'], axis=1)  # Features\n",
    "    \n",
    "    predicted = rnn_mem_rf.predict(X)\n",
    "    \n",
    "    return pd.DataFrame({'name': cleaned_features['name'], 'pred_mem': predicted})\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>pred_ms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>input_1</td>\n",
       "      <td>0.236354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>conv1_pad</td>\n",
       "      <td>0.236354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>conv1</td>\n",
       "      <td>0.742407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bn_conv1</td>\n",
       "      <td>1.356283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>activation</td>\n",
       "      <td>4.468461</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         name   pred_ms\n",
       "0     input_1  0.236354\n",
       "1   conv1_pad  0.236354\n",
       "2       conv1  0.742407\n",
       "3    bn_conv1  1.356283\n",
       "4  activation  4.468461"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "test_model = tf.keras.applications.resnet50.ResNet50(\n",
    "    include_top=True,\n",
    "    weights='imagenet')\n",
    "\n",
    "predict_cnn_ms(test_model).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>pred_mem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>input_1</td>\n",
       "      <td>458.366976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>conv1_pad</td>\n",
       "      <td>458.366976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>conv1</td>\n",
       "      <td>507.565568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bn_conv1</td>\n",
       "      <td>430.150784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>activation</td>\n",
       "      <td>2867.109824</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         name     pred_mem\n",
       "0     input_1   458.366976\n",
       "1   conv1_pad   458.366976\n",
       "2       conv1   507.565568\n",
       "3    bn_conv1   430.150784\n",
       "4  activation  2867.109824"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_cnn_mem(test_model).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving saved model and benchmark results.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>[node type]</th>\n",
       "      <th>[start]</th>\n",
       "      <th>[first]</th>\n",
       "      <th>[avg ms]</th>\n",
       "      <th>[%]</th>\n",
       "      <th>[cdf%]</th>\n",
       "      <th>[mem KB]</th>\n",
       "      <th>[times called]</th>\n",
       "      <th>[Name]</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NoOp</td>\n",
       "      <td>-6.821</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014%</td>\n",
       "      <td>0.014%</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>_SOURCE</td>\n",
       "      <td>_SOURCE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Const</td>\n",
       "      <td>-6.790</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005%</td>\n",
       "      <td>0.019%</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>bn2b_branch2c/gamma</td>\n",
       "      <td>bn2b_branch2c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Const</td>\n",
       "      <td>-6.783</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002%</td>\n",
       "      <td>0.022%</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>bn2c_branch2b/beta</td>\n",
       "      <td>bn2c_branch2b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Const</td>\n",
       "      <td>-6.779</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002%</td>\n",
       "      <td>0.024%</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>bn3a_branch2c/beta</td>\n",
       "      <td>bn3a_branch2c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Const</td>\n",
       "      <td>-6.776</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002%</td>\n",
       "      <td>0.026%</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>bn3b_branch2c/moving_mean</td>\n",
       "      <td>bn3b_branch2c</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                [node type]  [start]  [first]  [avg ms]       [%]    [cdf%]  \\\n",
       "0                      NoOp   -6.821    0.034     0.014    0.014%    0.014%   \n",
       "1                     Const   -6.790    0.017     0.005    0.005%    0.019%   \n",
       "2                     Const   -6.783    0.004     0.002    0.002%    0.022%   \n",
       "3                     Const   -6.779    0.004     0.002    0.002%    0.024%   \n",
       "4                     Const   -6.776    0.003     0.002    0.002%    0.026%   \n",
       "\n",
       "   [mem KB]  [times called]                     [Name]           name  \n",
       "0       0.0               1                    _SOURCE        _SOURCE  \n",
       "1       0.0               1        bn2b_branch2c/gamma  bn2b_branch2c  \n",
       "2       0.0               1         bn2c_branch2b/beta  bn2c_branch2b  \n",
       "3       0.0               1         bn3a_branch2c/beta  bn3a_branch2c  \n",
       "4       0.0               1  bn3b_branch2c/moving_mean  bn3b_branch2c  "
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet_benchmark = benchmark_model(test_model)\n",
    "resnet_benchmark.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180\n",
      "177\n"
     ]
    }
   ],
   "source": [
    "resnet_cpu = resnet_benchmark[['name', '[avg ms]']].groupby('name').sum().reset_index()\n",
    "resnet_mem = resnet_benchmark[['name', '[mem KB]']].groupby('name').max().reset_index()\n",
    "\n",
    "print(len(resnet_cpu))\n",
    "print(len(predict_cnn_ms(test_model)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>[avg ms]</th>\n",
       "      <th>pred_ms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>activation</td>\n",
       "      <td>0.142</td>\n",
       "      <td>4.468461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>activation_1</td>\n",
       "      <td>0.145</td>\n",
       "      <td>1.475160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>activation_10</td>\n",
       "      <td>0.098</td>\n",
       "      <td>1.424594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>activation_11</td>\n",
       "      <td>0.054</td>\n",
       "      <td>1.424594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>activation_12</td>\n",
       "      <td>0.101</td>\n",
       "      <td>1.247037</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            name  [avg ms]   pred_ms\n",
       "0     activation     0.142  4.468461\n",
       "1   activation_1     0.145  1.475160\n",
       "2  activation_10     0.098  1.424594\n",
       "3  activation_11     0.054  1.424594\n",
       "4  activation_12     0.101  1.247037"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet_cpu_df = resnet_cpu.merge(predict_cnn_ms(test_model), on='name')\n",
    "resnet_cpu_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>[mem KB]</th>\n",
       "      <th>pred_mem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>res4c_branch2c</td>\n",
       "      <td>802.816</td>\n",
       "      <td>817.317184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>res4d_branch2a</td>\n",
       "      <td>200.704</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>res4d_branch2b</td>\n",
       "      <td>200.704</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>res4d_branch2c</td>\n",
       "      <td>802.816</td>\n",
       "      <td>817.317184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>res4e_branch2a</td>\n",
       "      <td>200.704</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>res4e_branch2b</td>\n",
       "      <td>200.704</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>res4e_branch2c</td>\n",
       "      <td>802.816</td>\n",
       "      <td>817.317184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>res4f_branch2a</td>\n",
       "      <td>200.704</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>res4f_branch2b</td>\n",
       "      <td>200.704</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>res4f_branch2c</td>\n",
       "      <td>802.816</td>\n",
       "      <td>817.317184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>res5a_branch1</td>\n",
       "      <td>401.408</td>\n",
       "      <td>189.005568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>res5a_branch2a</td>\n",
       "      <td>100.352</td>\n",
       "      <td>75.153920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>res5a_branch2b</td>\n",
       "      <td>100.352</td>\n",
       "      <td>5.629712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>res5a_branch2c</td>\n",
       "      <td>401.408</td>\n",
       "      <td>88.751424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>res5b_branch2a</td>\n",
       "      <td>100.352</td>\n",
       "      <td>5.619744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>res5b_branch2b</td>\n",
       "      <td>100.352</td>\n",
       "      <td>5.629712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>res5b_branch2c</td>\n",
       "      <td>401.408</td>\n",
       "      <td>88.751424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>res5c_branch2a</td>\n",
       "      <td>100.352</td>\n",
       "      <td>5.619744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>res5c_branch2b</td>\n",
       "      <td>100.352</td>\n",
       "      <td>5.629712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>res5c_branch2c</td>\n",
       "      <td>401.408</td>\n",
       "      <td>88.751424</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               name  [mem KB]    pred_mem\n",
       "156  res4c_branch2c   802.816  817.317184\n",
       "157  res4d_branch2a   200.704    0.000000\n",
       "158  res4d_branch2b   200.704    0.000000\n",
       "159  res4d_branch2c   802.816  817.317184\n",
       "160  res4e_branch2a   200.704    0.000000\n",
       "161  res4e_branch2b   200.704    0.000000\n",
       "162  res4e_branch2c   802.816  817.317184\n",
       "163  res4f_branch2a   200.704    0.000000\n",
       "164  res4f_branch2b   200.704    0.000000\n",
       "165  res4f_branch2c   802.816  817.317184\n",
       "166   res5a_branch1   401.408  189.005568\n",
       "167  res5a_branch2a   100.352   75.153920\n",
       "168  res5a_branch2b   100.352    5.629712\n",
       "169  res5a_branch2c   401.408   88.751424\n",
       "170  res5b_branch2a   100.352    5.619744\n",
       "171  res5b_branch2b   100.352    5.629712\n",
       "172  res5b_branch2c   401.408   88.751424\n",
       "173  res5c_branch2a   100.352    5.619744\n",
       "174  res5c_branch2b   100.352    5.629712\n",
       "175  res5c_branch2c   401.408   88.751424"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet_mem_df = resnet_mem.merge(predict_cnn_mem(test_model), on='name')\n",
    "resnet_mem_df.tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.24975750164106\n",
      "892257.5725697743\n"
     ]
    }
   ],
   "source": [
    "print(mean_squared_error(resnet_cpu_df['pred_ms'], resnet_cpu_df['[avg ms]']))\n",
    "print(mean_squared_error(resnet_mem_df['pred_mem'], resnet_mem_df['[mem KB]']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/brian/anaconda/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /Users/brian/anaconda/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:97: calling Orthogonal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /Users/brian/anaconda/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.130042, 0.145918, 0.130042, 0.148489])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.compat.v1.keras.models import Sequential\n",
    "# from keras.layers import Dense, Dropout, Embedding, LSTM, Bidirectional\n",
    "\n",
    "max_features = 20000\n",
    "maxlen = 100\n",
    "batch_size = 32\n",
    "rnn_model = Sequential()\n",
    "rnn_model.add(layers.Embedding(max_features, 128, input_length=maxlen))\n",
    "rnn_model.add(layers.Bidirectional(layers.LSTM(64)))\n",
    "rnn_model.add(layers.Dropout(0.5))\n",
    "rnn_model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "# try using different optimizers and different optimizer configs\n",
    "rnn_model.compile('adam', 'binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "predict_rnn_ms(rnn_model)\n",
    "\n",
    "# get_layer_features(rnn_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predict_rnn_mem(rnn_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clean(get_layer_features(test_model), inference=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['nn_regressors/rnn_mem.joblib']"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from joblib import dump, load\n",
    "dump(cnn_ms_rf, 'nn_regressors/cnn_cpu.joblib') \n",
    "dump(cnn_mem_rf, 'nn_regressors/cnn_mem.joblib') \n",
    "\n",
    "dump(rnn_ms_rf, 'nn_regressors/rnn_cpu.joblib') \n",
    "dump(rnn_mem_rf, 'nn_regressors/rnn_mem.joblib') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
