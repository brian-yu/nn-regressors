{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import io\n",
    "import subprocess\n",
    "import os\n",
    "\n",
    "from tensorflow.compat.v1.keras import layers\n",
    "import tensorflow.compat.v1 as tf\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from tf_graph_util import convert_variables_to_constants\n",
    "from lstm import create_lstm\n",
    "\n",
    "from seq2seq import create_seq2seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "RANDOM_SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "def benchmark_model(model, cmd=None):\n",
    "    bench_path = f\"{model.name}_benchmark.txt\"\n",
    "    if not os.path.exists(f\"{model.name}.pbtxt\") and not os.path.exists(bench_path):\n",
    "        if not os.path.exists(f\"{model.name}.pbtxt\"):\n",
    "            print(\"Saving model...\")\n",
    "#             tf.keras.backend.clear_session()\n",
    "            sess = tf.keras.backend.get_session()\n",
    "    #         output_graph_def = tf.graph_util.convert_variables_to_constants(\n",
    "            output_graph_def = convert_variables_to_constants(\n",
    "                sess,\n",
    "                sess.graph.as_graph_def(),\n",
    "                [node.op.name for node in model.outputs])\n",
    "            tf.io.write_graph(output_graph_def, './', f'{model.name}.pbtxt')\n",
    "        else:\n",
    "            print(\"Retrieving saved model.\")\n",
    "    \n",
    "    \n",
    "        if not os.path.exists(bench_path):\n",
    "            if not cmd:\n",
    "                input_shape = f\"1,{','.join(str(dim) for dim in model.input.shape[1:])}\"\n",
    "                cmd = f'../tensorflow/bazel-bin/tensorflow/tools/benchmark/benchmark_model --graph={model.name}.pbtxt --input_layer=\"{model.input.name}\" --input_layer_shape=\"{input_shape}\" --output_layer=\"{model.output.name}\"'\n",
    "                print(cmd)\n",
    "            print(\"Running benchmark...\")\n",
    "            benchmark = subprocess.run([cmd], stderr=subprocess.PIPE, shell=True)\n",
    "            print(\"Done.\")\n",
    "\n",
    "            output = benchmark.stderr.decode('unicode_escape')\n",
    "            split_output = output[output.find('Run Order'):output.find('Top by Computation Time')].split('\\n')\n",
    "\n",
    "            with open(bench_path, 'w') as f:\n",
    "                f.write(\"\\n\".join(split_output[1:-2]))\n",
    "        else:\n",
    "            print(\"Retrieving saved benchmark results.\")\n",
    "    else:\n",
    "        print(\"Retrieving saved model and benchmark results.\")\n",
    "    \n",
    "    f = open(bench_path)\n",
    "    benchmark = pd.read_csv(f, sep=\"\\t\").rename(columns=lambda x: x.strip())\n",
    "    benchmark = benchmark.drop(benchmark.columns[0], axis=1)\n",
    "    benchmark['name'] = benchmark['[Name]'].apply(lambda x: x.split('/')[0])\n",
    "    return benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_layer_features(model):\n",
    "    layers = pd.DataFrame()\n",
    "    layers['name'] = pd.Series([layer.name for layer in model.layers])\n",
    "    \n",
    "#     input_dims = {layer.name: [dim.value for dim in layer.input.shape.dims] for layer in model.layers}\n",
    "    \n",
    "#     layers['input_shape'] = pd.Series([[dim.value for dim in layer.input.shape.dims] for layer in model.layers])\n",
    "#     layers['output_shape'] = pd.Series([[dim.value for dim in layer.output.shape.dims] for layer in model.layers])\n",
    "    layers['input_shape'] = pd.Series([layer.input_shape for layer in model.layers])\n",
    "    layers['output_shape'] = pd.Series([layer.output_shape for layer in model.layers])\n",
    "\n",
    "    features = ['units','filters','activation','strides','kernel_size']\n",
    "    for feature in features:\n",
    "        layers[feature] = pd.Series(\n",
    "            [layer.get_config()[feature] if feature in layer.get_config() else None for layer in model.layers])\n",
    "    return layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def join_benchmark(features, benchmark):\n",
    "    speed = benchmark[['name', '[avg ms]']].groupby('name').sum()\n",
    "    mem = benchmark[['name', '[mem KB]']].groupby('name').max()\n",
    "    \n",
    "    return features.join(speed, on='name').join(mem, on='name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def flatten_shape(shape):\n",
    "    if not shape:\n",
    "        return None\n",
    "    \n",
    "    # Return value if it is not iterable\n",
    "    try:\n",
    "        iter(shape)\n",
    "    except TypeError as e:\n",
    "        return shape\n",
    "    \n",
    "    def reduce(tup):\n",
    "        acc = 1\n",
    "        for val in tup:\n",
    "            if val:\n",
    "                acc *= val\n",
    "        return acc\n",
    "    \n",
    "    if isinstance(shape, list):\n",
    "        return sum(reduce(tup) for tup in shape)\n",
    "    \n",
    "    return reduce(shape)\n",
    "\n",
    "\n",
    "def clean(data, inference=False):\n",
    "    if inference:\n",
    "        cleaned = pd.get_dummies(data, columns=['activation'], dummy_na=True)\n",
    "    else:\n",
    "        cleaned = data.dropna(subset=['[avg ms]', '[mem KB]'])\n",
    "        if 'activation' in data.columns:\n",
    "            cleaned = pd.get_dummies(cleaned, columns=['activation'], dummy_na=True)\n",
    "    \n",
    "    for activation in ['selu', 'elu', 'softmax', 'softplus', 'softsign', 'relu', 'tanh', 'sigmoid', 'hard_sigmoid', 'exponential', 'linear']:\n",
    "        col = f\"activation_{activation}\"\n",
    "        if col not in cleaned.columns:\n",
    "            cleaned[col] = pd.Series(0)\n",
    "    \n",
    "\n",
    "    cleaned['input_size'] = cleaned['input_shape'].apply(flatten_shape)\n",
    "    cleaned['output_size'] = cleaned['output_shape'].apply(flatten_shape)\n",
    "    cleaned['stride_size'] = cleaned['strides'].apply(flatten_shape)\n",
    "    cleaned['kernel_size'] = cleaned['kernel_size'].apply(flatten_shape)\n",
    "\n",
    "    return cleaned.fillna(-1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rf_regression_model(data, column):\n",
    "    X = data.drop(['name', '[avg ms]', '[mem KB]', 'input_shape', 'output_shape', 'strides'], axis=1)  # Features\n",
    "    y = data[column]  # Labels\n",
    "\n",
    "    # Split dataset into training set and test set\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.3, random_state = RANDOM_SEED) # 70% training and 30% test\n",
    "\n",
    "    # Instantiate model with 1000 decision trees\n",
    "    rf = RandomForestRegressor(n_estimators = 1000, random_state = RANDOM_SEED)\n",
    "    # Train the model on training data\n",
    "    rf.fit(X_train, y_train);\n",
    "\n",
    "    return rf, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.svm import LinearSVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "\n",
    "def stacked_regression_model(data, column):\n",
    "\n",
    "    X = data.drop(['name', '[avg ms]', '[mem KB]', 'input_shape', 'output_shape', 'strides'], axis=1)  # Features\n",
    "    y = data[column]  # Labels\n",
    "\n",
    "    estimators = [\n",
    "        ('rf', RandomForestRegressor(n_estimators=1000, random_state=RANDOM_SEED)),\n",
    "        ('lr', RidgeCV()),\n",
    "        ('svr', LinearSVR(random_state=42)),\n",
    "        \n",
    "    ]\n",
    "    reg = StackingRegressor(\n",
    "        estimators=estimators,\n",
    "#         final_estimator=RandomForestRegressor(n_estimators=1000, random_state=RANDOM_SEED)\n",
    "    )\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "    \n",
    "    reg.fit(X_train, y_train).score(X_test, y_test)\n",
    "    \n",
    "    return reg, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "def stacked_regression_model_2(data, column):\n",
    "\n",
    "    X = data.drop(['name', '[avg ms]', '[mem KB]', 'input_shape', 'output_shape', 'strides'], axis=1)  # Features\n",
    "    y = data[column]  # Labels\n",
    "    \n",
    "    poly = Pipeline([\n",
    "        ('poly', PolynomialFeatures(degree=5)),\n",
    "        ('linear', LinearRegression(fit_intercept=False))\n",
    "    ])\n",
    "\n",
    "    estimators = [\n",
    "        ('poly', poly),\n",
    "        ('lr', RidgeCV()),\n",
    "        ('svr', LinearSVR(random_state=42)),\n",
    "        \n",
    "    ]\n",
    "    reg = StackingRegressor(\n",
    "        estimators=estimators,\n",
    "#         final_estimator=RandomForestRegressor(n_estimators=1000, random_state=RANDOM_SEED)\n",
    "    )\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "    \n",
    "    reg.fit(X_train, y_train).score(X_test, y_test)\n",
    "    \n",
    "    return reg, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/brian/anaconda/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session() # IMPORTANT for layer names to match up.\n",
    "model = tf.keras.applications.vgg16.VGG16(\n",
    "    include_top=True,\n",
    "    weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving saved model and benchmark results.\n"
     ]
    }
   ],
   "source": [
    "benchmark = benchmark_model(model)\n",
    "features = get_layer_features(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vgg_df = join_benchmark(features, benchmark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving saved model and benchmark results.\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session() # IMPORTANT for layer names to match up.\n",
    "tf.keras.backend.set_learning_phase(0)\n",
    "inception = tf.keras.applications.inception_v3.InceptionV3(\n",
    "    include_top=True, weights='imagenet')\n",
    "inception_benchmark = benchmark_model(inception)\n",
    "inception_features = get_layer_features(inception)\n",
    "inception_df = join_benchmark(inception_features, inception_benchmark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # lstm.summary()\n",
    "\n",
    "# tf.keras.backend.clear_session() # IMPORTANT for layer names to match up.\n",
    "\n",
    "# lstm = create_lstm()\n",
    "\n",
    "# # tf.keras.backend.set_learning_phase(0)\n",
    "# lstm_benchmark = benchmark_model(lstm)\n",
    "# lstm_features = get_layer_features(lstm)\n",
    "# lstm_df = join_benchmark(lstm_features, lstm_benchmark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>input_shape</th>\n",
       "      <th>output_shape</th>\n",
       "      <th>units</th>\n",
       "      <th>filters</th>\n",
       "      <th>activation</th>\n",
       "      <th>strides</th>\n",
       "      <th>kernel_size</th>\n",
       "      <th>[avg ms]</th>\n",
       "      <th>[mem KB]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>batch_normalization_28</td>\n",
       "      <td>(None, 35, 35, 96)</td>\n",
       "      <td>(None, 35, 35, 96)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>activation_35</td>\n",
       "      <td>(None, 17, 17, 128)</td>\n",
       "      <td>(None, 17, 17, 128)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.849</td>\n",
       "      <td>147.968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>conv2d_89</td>\n",
       "      <td>(None, 8, 8, 2048)</td>\n",
       "      <td>(None, 8, 8, 448)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>448.0</td>\n",
       "      <td>linear</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>activation_84</td>\n",
       "      <td>(None, 8, 8, 192)</td>\n",
       "      <td>(None, 8, 8, 192)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.719</td>\n",
       "      <td>49.152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>batch_normalization_45</td>\n",
       "      <td>(None, 17, 17, 160)</td>\n",
       "      <td>(None, 17, 17, 160)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>activation_61</td>\n",
       "      <td>(None, 17, 17, 192)</td>\n",
       "      <td>(None, 17, 17, 192)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1.203</td>\n",
       "      <td>221.952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>mixed10</td>\n",
       "      <td>[(None, 8, 8, 320), (None, 8, 8, 768), (None, ...</td>\n",
       "      <td>(None, 8, 8, 2048)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.159</td>\n",
       "      <td>524.288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>batch_normalization_15</td>\n",
       "      <td>(None, 35, 35, 64)</td>\n",
       "      <td>(None, 35, 35, 64)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>batch_normalization_84</td>\n",
       "      <td>(None, 8, 8, 192)</td>\n",
       "      <td>(None, 8, 8, 192)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>max_pooling2d_2</td>\n",
       "      <td>(None, 35, 35, 288)</td>\n",
       "      <td>(None, 17, 17, 288)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>None</td>\n",
       "      <td>0.340</td>\n",
       "      <td>332.928</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       name  \\\n",
       "91   batch_normalization_28   \n",
       "106           activation_35   \n",
       "280               conv2d_89   \n",
       "278           activation_84   \n",
       "137  batch_normalization_45   \n",
       "207           activation_61   \n",
       "310                 mixed10   \n",
       "42   batch_normalization_15   \n",
       "274  batch_normalization_84   \n",
       "99          max_pooling2d_2   \n",
       "\n",
       "                                           input_shape         output_shape  \\\n",
       "91                                  (None, 35, 35, 96)   (None, 35, 35, 96)   \n",
       "106                                (None, 17, 17, 128)  (None, 17, 17, 128)   \n",
       "280                                 (None, 8, 8, 2048)    (None, 8, 8, 448)   \n",
       "278                                  (None, 8, 8, 192)    (None, 8, 8, 192)   \n",
       "137                                (None, 17, 17, 160)  (None, 17, 17, 160)   \n",
       "207                                (None, 17, 17, 192)  (None, 17, 17, 192)   \n",
       "310  [(None, 8, 8, 320), (None, 8, 8, 768), (None, ...   (None, 8, 8, 2048)   \n",
       "42                                  (None, 35, 35, 64)   (None, 35, 35, 64)   \n",
       "274                                  (None, 8, 8, 192)    (None, 8, 8, 192)   \n",
       "99                                 (None, 35, 35, 288)  (None, 17, 17, 288)   \n",
       "\n",
       "     units  filters activation strides kernel_size  [avg ms]  [mem KB]  \n",
       "91     NaN      NaN       None    None        None     0.007     0.000  \n",
       "106    NaN      NaN       relu    None        None     0.849   147.968  \n",
       "280    NaN    448.0     linear  (1, 1)      (1, 1)     0.002     0.000  \n",
       "278    NaN      NaN       relu    None        None     0.719    49.152  \n",
       "137    NaN      NaN       None    None        None     0.005     0.000  \n",
       "207    NaN      NaN       relu    None        None     1.203   221.952  \n",
       "310    NaN      NaN       None    None        None     0.159   524.288  \n",
       "42     NaN      NaN       None    None        None     0.003     0.000  \n",
       "274    NaN      NaN       None    None        None     0.003     0.000  \n",
       "99     NaN      NaN       None  (2, 2)        None     0.340   332.928  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.concat([vgg_df, inception_df])\n",
    "data.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>input_shape</th>\n",
       "      <th>output_shape</th>\n",
       "      <th>units</th>\n",
       "      <th>filters</th>\n",
       "      <th>strides</th>\n",
       "      <th>kernel_size</th>\n",
       "      <th>[avg ms]</th>\n",
       "      <th>[mem KB]</th>\n",
       "      <th>activation_linear</th>\n",
       "      <th>...</th>\n",
       "      <th>activation_elu</th>\n",
       "      <th>activation_softplus</th>\n",
       "      <th>activation_softsign</th>\n",
       "      <th>activation_tanh</th>\n",
       "      <th>activation_sigmoid</th>\n",
       "      <th>activation_hard_sigmoid</th>\n",
       "      <th>activation_exponential</th>\n",
       "      <th>input_size</th>\n",
       "      <th>output_size</th>\n",
       "      <th>stride_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>block1_conv1</td>\n",
       "      <td>(None, 224, 224, 3)</td>\n",
       "      <td>(None, 224, 224, 64)</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.657</td>\n",
       "      <td>12845.056</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>150528</td>\n",
       "      <td>3211264</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>block1_conv2</td>\n",
       "      <td>(None, 224, 224, 64)</td>\n",
       "      <td>(None, 224, 224, 64)</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>9.0</td>\n",
       "      <td>18.123</td>\n",
       "      <td>12845.056</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>3211264</td>\n",
       "      <td>3211264</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>block1_pool</td>\n",
       "      <td>(None, 224, 224, 64)</td>\n",
       "      <td>(None, 112, 112, 64)</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>3.437</td>\n",
       "      <td>3211.264</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>3211264</td>\n",
       "      <td>802816</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>block2_conv1</td>\n",
       "      <td>(None, 112, 112, 64)</td>\n",
       "      <td>(None, 112, 112, 128)</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.181</td>\n",
       "      <td>6422.528</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>802816</td>\n",
       "      <td>1605632</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>block2_conv2</td>\n",
       "      <td>(None, 112, 112, 128)</td>\n",
       "      <td>(None, 112, 112, 128)</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>9.0</td>\n",
       "      <td>13.004</td>\n",
       "      <td>6422.528</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1605632</td>\n",
       "      <td>1605632</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           name            input_shape           output_shape  units  filters  \\\n",
       "1  block1_conv1    (None, 224, 224, 3)   (None, 224, 224, 64)   -1.0     64.0   \n",
       "2  block1_conv2   (None, 224, 224, 64)   (None, 224, 224, 64)   -1.0     64.0   \n",
       "3   block1_pool   (None, 224, 224, 64)   (None, 112, 112, 64)   -1.0     -1.0   \n",
       "4  block2_conv1   (None, 112, 112, 64)  (None, 112, 112, 128)   -1.0    128.0   \n",
       "5  block2_conv2  (None, 112, 112, 128)  (None, 112, 112, 128)   -1.0    128.0   \n",
       "\n",
       "  strides  kernel_size  [avg ms]   [mem KB]  activation_linear  ...  \\\n",
       "1  (1, 1)          9.0     2.657  12845.056                  0  ...   \n",
       "2  (1, 1)          9.0    18.123  12845.056                  0  ...   \n",
       "3  (2, 2)         -1.0     3.437   3211.264                  0  ...   \n",
       "4  (1, 1)          9.0     7.181   6422.528                  0  ...   \n",
       "5  (1, 1)          9.0    13.004   6422.528                  0  ...   \n",
       "\n",
       "   activation_elu  activation_softplus  activation_softsign  activation_tanh  \\\n",
       "1            -1.0                 -1.0                 -1.0             -1.0   \n",
       "2            -1.0                 -1.0                 -1.0             -1.0   \n",
       "3            -1.0                 -1.0                 -1.0             -1.0   \n",
       "4            -1.0                 -1.0                 -1.0             -1.0   \n",
       "5            -1.0                 -1.0                 -1.0             -1.0   \n",
       "\n",
       "   activation_sigmoid  activation_hard_sigmoid  activation_exponential  \\\n",
       "1                -1.0                     -1.0                    -1.0   \n",
       "2                -1.0                     -1.0                    -1.0   \n",
       "3                -1.0                     -1.0                    -1.0   \n",
       "4                -1.0                     -1.0                    -1.0   \n",
       "5                -1.0                     -1.0                    -1.0   \n",
       "\n",
       "   input_size  output_size  stride_size  \n",
       "1      150528      3211264          1.0  \n",
       "2     3211264      3211264          1.0  \n",
       "3     3211264       802816          4.0  \n",
       "4      802816      1605632          1.0  \n",
       "5     1605632      1605632          1.0  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned = clean(data)\n",
    "\n",
    "cleaned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 17.10178814125108\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>units</th>\n",
       "      <th>filters</th>\n",
       "      <th>kernel_size</th>\n",
       "      <th>activation_linear</th>\n",
       "      <th>activation_relu</th>\n",
       "      <th>activation_softmax</th>\n",
       "      <th>activation_nan</th>\n",
       "      <th>activation_selu</th>\n",
       "      <th>activation_elu</th>\n",
       "      <th>activation_softplus</th>\n",
       "      <th>activation_softsign</th>\n",
       "      <th>activation_tanh</th>\n",
       "      <th>activation_sigmoid</th>\n",
       "      <th>activation_hard_sigmoid</th>\n",
       "      <th>activation_exponential</th>\n",
       "      <th>input_size</th>\n",
       "      <th>output_size</th>\n",
       "      <th>stride_size</th>\n",
       "      <th>avg_ms_actual</th>\n",
       "      <th>avg_ms_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>221952</td>\n",
       "      <td>221952</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.182</td>\n",
       "      <td>0.237503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>78400</td>\n",
       "      <td>78400</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.683</td>\n",
       "      <td>0.920930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>221952</td>\n",
       "      <td>55488</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>36992</td>\n",
       "      <td>36992</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.992</td>\n",
       "      <td>0.882680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>221952</td>\n",
       "      <td>221952</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.272</td>\n",
       "      <td>0.237503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>55488</td>\n",
       "      <td>55488</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.005435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>55488</td>\n",
       "      <td>55488</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.005435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>55488</td>\n",
       "      <td>55488</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.005435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>55488</td>\n",
       "      <td>55488</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.654</td>\n",
       "      <td>0.911988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>55488</td>\n",
       "      <td>55488</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.546</td>\n",
       "      <td>0.911988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>78400</td>\n",
       "      <td>78400</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.003876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>235200</td>\n",
       "      <td>78400</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>36992</td>\n",
       "      <td>36992</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.868</td>\n",
       "      <td>0.882680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>24576</td>\n",
       "      <td>24576</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.089</td>\n",
       "      <td>0.924709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>117600</td>\n",
       "      <td>117600</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.043</td>\n",
       "      <td>1.366511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>55488</td>\n",
       "      <td>55488</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.999</td>\n",
       "      <td>0.911988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>352800</td>\n",
       "      <td>78400</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.014869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>55488</td>\n",
       "      <td>55488</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.002422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>55488</td>\n",
       "      <td>55488</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>81920</td>\n",
       "      <td>12288</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.003071</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     units  filters  kernel_size  activation_linear  activation_relu  \\\n",
       "228   -1.0     -1.0         -1.0                  0                0   \n",
       "89    -1.0     -1.0         -1.0                  0                1   \n",
       "197   -1.0    192.0          1.0                  1                0   \n",
       "111   -1.0     -1.0         -1.0                  0                1   \n",
       "164   -1.0     -1.0         -1.0                  0                0   \n",
       "158   -1.0     -1.0         -1.0                  0                0   \n",
       "190   -1.0     -1.0         -1.0                  0                0   \n",
       "212   -1.0     -1.0         -1.0                  0                0   \n",
       "214   -1.0     -1.0         -1.0                  0                1   \n",
       "162   -1.0     -1.0         -1.0                  0                1   \n",
       "78    -1.0     -1.0         -1.0                  0                0   \n",
       "18    -1.0     64.0          1.0                  1                0   \n",
       "117   -1.0     -1.0         -1.0                  0                1   \n",
       "256   -1.0     -1.0         -1.0                  0                1   \n",
       "84    -1.0     -1.0         -1.0                  0                1   \n",
       "208   -1.0     -1.0         -1.0                  0                1   \n",
       "64    -1.0     64.0          1.0                  1                0   \n",
       "210   -1.0    192.0          7.0                  1                0   \n",
       "191   -1.0     -1.0         -1.0                  0                0   \n",
       "268   -1.0    192.0          1.0                  1                0   \n",
       "\n",
       "     activation_softmax  activation_nan  activation_selu  activation_elu  \\\n",
       "228                   0               1             -1.0            -1.0   \n",
       "89                    0               0             -1.0            -1.0   \n",
       "197                   0               0             -1.0            -1.0   \n",
       "111                   0               0             -1.0            -1.0   \n",
       "164                   0               1             -1.0            -1.0   \n",
       "158                   0               1             -1.0            -1.0   \n",
       "190                   0               1             -1.0            -1.0   \n",
       "212                   0               1             -1.0            -1.0   \n",
       "214                   0               0             -1.0            -1.0   \n",
       "162                   0               0             -1.0            -1.0   \n",
       "78                    0               1             -1.0            -1.0   \n",
       "18                    0               0             -1.0            -1.0   \n",
       "117                   0               0             -1.0            -1.0   \n",
       "256                   0               0             -1.0            -1.0   \n",
       "84                    0               0             -1.0            -1.0   \n",
       "208                   0               0             -1.0            -1.0   \n",
       "64                    0               0             -1.0            -1.0   \n",
       "210                   0               0             -1.0            -1.0   \n",
       "191                   0               1             -1.0            -1.0   \n",
       "268                   0               0             -1.0            -1.0   \n",
       "\n",
       "     activation_softplus  activation_softsign  activation_tanh  \\\n",
       "228                 -1.0                 -1.0             -1.0   \n",
       "89                  -1.0                 -1.0             -1.0   \n",
       "197                 -1.0                 -1.0             -1.0   \n",
       "111                 -1.0                 -1.0             -1.0   \n",
       "164                 -1.0                 -1.0             -1.0   \n",
       "158                 -1.0                 -1.0             -1.0   \n",
       "190                 -1.0                 -1.0             -1.0   \n",
       "212                 -1.0                 -1.0             -1.0   \n",
       "214                 -1.0                 -1.0             -1.0   \n",
       "162                 -1.0                 -1.0             -1.0   \n",
       "78                  -1.0                 -1.0             -1.0   \n",
       "18                  -1.0                 -1.0             -1.0   \n",
       "117                 -1.0                 -1.0             -1.0   \n",
       "256                 -1.0                 -1.0             -1.0   \n",
       "84                  -1.0                 -1.0             -1.0   \n",
       "208                 -1.0                 -1.0             -1.0   \n",
       "64                  -1.0                 -1.0             -1.0   \n",
       "210                 -1.0                 -1.0             -1.0   \n",
       "191                 -1.0                 -1.0             -1.0   \n",
       "268                 -1.0                 -1.0             -1.0   \n",
       "\n",
       "     activation_sigmoid  activation_hard_sigmoid  activation_exponential  \\\n",
       "228                -1.0                     -1.0                    -1.0   \n",
       "89                 -1.0                     -1.0                    -1.0   \n",
       "197                -1.0                     -1.0                    -1.0   \n",
       "111                -1.0                     -1.0                    -1.0   \n",
       "164                -1.0                     -1.0                    -1.0   \n",
       "158                -1.0                     -1.0                    -1.0   \n",
       "190                -1.0                     -1.0                    -1.0   \n",
       "212                -1.0                     -1.0                    -1.0   \n",
       "214                -1.0                     -1.0                    -1.0   \n",
       "162                -1.0                     -1.0                    -1.0   \n",
       "78                 -1.0                     -1.0                    -1.0   \n",
       "18                 -1.0                     -1.0                    -1.0   \n",
       "117                -1.0                     -1.0                    -1.0   \n",
       "256                -1.0                     -1.0                    -1.0   \n",
       "84                 -1.0                     -1.0                    -1.0   \n",
       "208                -1.0                     -1.0                    -1.0   \n",
       "64                 -1.0                     -1.0                    -1.0   \n",
       "210                -1.0                     -1.0                    -1.0   \n",
       "191                -1.0                     -1.0                    -1.0   \n",
       "268                -1.0                     -1.0                    -1.0   \n",
       "\n",
       "     input_size  output_size  stride_size  avg_ms_actual  avg_ms_pred  \n",
       "228      221952       221952         -1.0          0.182     0.237503  \n",
       "89        78400        78400         -1.0          0.683     0.920930  \n",
       "197      221952        55488          1.0          0.002     0.002323  \n",
       "111       36992        36992         -1.0          0.992     0.882680  \n",
       "164      221952       221952         -1.0          0.272     0.237503  \n",
       "158       55488        55488         -1.0          0.006     0.005435  \n",
       "190       55488        55488         -1.0          0.007     0.005435  \n",
       "212       55488        55488         -1.0          0.006     0.005435  \n",
       "214       55488        55488         -1.0          0.654     0.911988  \n",
       "162       55488        55488         -1.0          0.546     0.911988  \n",
       "78        78400        78400         -1.0          0.005     0.003876  \n",
       "18       235200        78400          1.0          0.002     0.002029  \n",
       "117       36992        36992         -1.0          0.868     0.882680  \n",
       "256       24576        24576         -1.0          1.089     0.924709  \n",
       "84       117600       117600         -1.0          1.043     1.366511  \n",
       "208       55488        55488         -1.0          0.999     0.911988  \n",
       "64       352800        78400          1.0          0.002     0.014869  \n",
       "210       55488        55488          1.0          0.003     0.002422  \n",
       "191       55488        55488         -1.0          0.005     0.005435  \n",
       "268       81920        12288          1.0          0.002     0.003071  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "X = cleaned.drop(['name', '[avg ms]', '[mem KB]', 'input_shape', 'output_shape', 'strides'], axis=1)  # Features\n",
    "y = cleaned['[avg ms]']  # Labels\n",
    "\n",
    "# Split dataset into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3) # 70% training and 30% test\n",
    "\n",
    "# Instantiate model with 1000 decision trees\n",
    "rf = RandomForestRegressor(n_estimators = 1000, random_state = 42)\n",
    "# Train the model on training data\n",
    "rf.fit(X_train, y_train);\n",
    "\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "print(\"MSE:\", mean_squared_error(y_test, y_pred))\n",
    "\n",
    "pd.concat([X_test, pd.DataFrame({'avg_ms_actual': y_test, 'avg_ms_pred': y_pred})], axis=1).sample(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 317183.27335722075\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>units</th>\n",
       "      <th>filters</th>\n",
       "      <th>kernel_size</th>\n",
       "      <th>activation_linear</th>\n",
       "      <th>activation_relu</th>\n",
       "      <th>activation_softmax</th>\n",
       "      <th>activation_nan</th>\n",
       "      <th>activation_selu</th>\n",
       "      <th>activation_elu</th>\n",
       "      <th>activation_softplus</th>\n",
       "      <th>activation_softsign</th>\n",
       "      <th>activation_tanh</th>\n",
       "      <th>activation_sigmoid</th>\n",
       "      <th>activation_hard_sigmoid</th>\n",
       "      <th>activation_exponential</th>\n",
       "      <th>input_size</th>\n",
       "      <th>output_size</th>\n",
       "      <th>stride_size</th>\n",
       "      <th>mem_KB_actual</th>\n",
       "      <th>mem_KB_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>36992</td>\n",
       "      <td>36992</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>147.968</td>\n",
       "      <td>147.710592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>384.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>24576</td>\n",
       "      <td>24576</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>55488</td>\n",
       "      <td>55488</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>78400</td>\n",
       "      <td>117600</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>14.896512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>55488</td>\n",
       "      <td>55488</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>58800</td>\n",
       "      <td>58800</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>235.200</td>\n",
       "      <td>230.245248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>55488</td>\n",
       "      <td>12288</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>46.583680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>55488</td>\n",
       "      <td>55488</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>46240</td>\n",
       "      <td>46240</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>117600</td>\n",
       "      <td>117600</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2.772352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>58800</td>\n",
       "      <td>58800</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>55488</td>\n",
       "      <td>55488</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>55488</td>\n",
       "      <td>55488</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>352800</td>\n",
       "      <td>78400</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2.330496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>55488</td>\n",
       "      <td>55488</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>117600</td>\n",
       "      <td>117600</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2.359296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>221952</td>\n",
       "      <td>221952</td>\n",
       "      <td>1.0</td>\n",
       "      <td>887.808</td>\n",
       "      <td>899.217408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>221952</td>\n",
       "      <td>36992</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>81920</td>\n",
       "      <td>12288</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.008192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>58800</td>\n",
       "      <td>58800</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     units  filters  kernel_size  activation_linear  activation_relu  \\\n",
       "111   -1.0     -1.0         -1.0                  0                1   \n",
       "291   -1.0    384.0          3.0                  1                0   \n",
       "222   -1.0     -1.0         -1.0                  0                0   \n",
       "68    -1.0     96.0          9.0                  1                0   \n",
       "218   -1.0    192.0          7.0                  1                0   \n",
       "25    -1.0     -1.0         -1.0                  0                1   \n",
       "242   -1.0    192.0          9.0                  1                0   \n",
       "209   -1.0    192.0          7.0                  1                0   \n",
       "178   -1.0    160.0          7.0                  1                0   \n",
       "76    -1.0     96.0          9.0                  1                0   \n",
       "46    -1.0     -1.0         -1.0                  0                0   \n",
       "238   -1.0     -1.0         -1.0                  0                0   \n",
       "230   -1.0     -1.0         -1.0                  0                0   \n",
       "87    -1.0     64.0          1.0                  1                0   \n",
       "200   -1.0    192.0          7.0                  1                0   \n",
       "80    -1.0     -1.0         -1.0                  0                0   \n",
       "119   -1.0     -1.0         -1.0                  0                0   \n",
       "107   -1.0    128.0          1.0                  1                0   \n",
       "268   -1.0    192.0          1.0                  1                0   \n",
       "69    -1.0     -1.0         -1.0                  0                0   \n",
       "\n",
       "     activation_softmax  activation_nan  activation_selu  activation_elu  \\\n",
       "111                   0               0             -1.0            -1.0   \n",
       "291                   0               0             -1.0            -1.0   \n",
       "222                   0               1             -1.0            -1.0   \n",
       "68                    0               0             -1.0            -1.0   \n",
       "218                   0               0             -1.0            -1.0   \n",
       "25                    0               0             -1.0            -1.0   \n",
       "242                   0               0             -1.0            -1.0   \n",
       "209                   0               0             -1.0            -1.0   \n",
       "178                   0               0             -1.0            -1.0   \n",
       "76                    0               0             -1.0            -1.0   \n",
       "46                    0               1             -1.0            -1.0   \n",
       "238                   0               1             -1.0            -1.0   \n",
       "230                   0               1             -1.0            -1.0   \n",
       "87                    0               0             -1.0            -1.0   \n",
       "200                   0               0             -1.0            -1.0   \n",
       "80                    0               1             -1.0            -1.0   \n",
       "119                   0               1             -1.0            -1.0   \n",
       "107                   0               0             -1.0            -1.0   \n",
       "268                   0               0             -1.0            -1.0   \n",
       "69                    0               1             -1.0            -1.0   \n",
       "\n",
       "     activation_softplus  activation_softsign  activation_tanh  \\\n",
       "111                 -1.0                 -1.0             -1.0   \n",
       "291                 -1.0                 -1.0             -1.0   \n",
       "222                 -1.0                 -1.0             -1.0   \n",
       "68                  -1.0                 -1.0             -1.0   \n",
       "218                 -1.0                 -1.0             -1.0   \n",
       "25                  -1.0                 -1.0             -1.0   \n",
       "242                 -1.0                 -1.0             -1.0   \n",
       "209                 -1.0                 -1.0             -1.0   \n",
       "178                 -1.0                 -1.0             -1.0   \n",
       "76                  -1.0                 -1.0             -1.0   \n",
       "46                  -1.0                 -1.0             -1.0   \n",
       "238                 -1.0                 -1.0             -1.0   \n",
       "230                 -1.0                 -1.0             -1.0   \n",
       "87                  -1.0                 -1.0             -1.0   \n",
       "200                 -1.0                 -1.0             -1.0   \n",
       "80                  -1.0                 -1.0             -1.0   \n",
       "119                 -1.0                 -1.0             -1.0   \n",
       "107                 -1.0                 -1.0             -1.0   \n",
       "268                 -1.0                 -1.0             -1.0   \n",
       "69                  -1.0                 -1.0             -1.0   \n",
       "\n",
       "     activation_sigmoid  activation_hard_sigmoid  activation_exponential  \\\n",
       "111                -1.0                     -1.0                    -1.0   \n",
       "291                -1.0                     -1.0                    -1.0   \n",
       "222                -1.0                     -1.0                    -1.0   \n",
       "68                 -1.0                     -1.0                    -1.0   \n",
       "218                -1.0                     -1.0                    -1.0   \n",
       "25                 -1.0                     -1.0                    -1.0   \n",
       "242                -1.0                     -1.0                    -1.0   \n",
       "209                -1.0                     -1.0                    -1.0   \n",
       "178                -1.0                     -1.0                    -1.0   \n",
       "76                 -1.0                     -1.0                    -1.0   \n",
       "46                 -1.0                     -1.0                    -1.0   \n",
       "238                -1.0                     -1.0                    -1.0   \n",
       "230                -1.0                     -1.0                    -1.0   \n",
       "87                 -1.0                     -1.0                    -1.0   \n",
       "200                -1.0                     -1.0                    -1.0   \n",
       "80                 -1.0                     -1.0                    -1.0   \n",
       "119                -1.0                     -1.0                    -1.0   \n",
       "107                -1.0                     -1.0                    -1.0   \n",
       "268                -1.0                     -1.0                    -1.0   \n",
       "69                 -1.0                     -1.0                    -1.0   \n",
       "\n",
       "     input_size  output_size  stride_size  mem_KB_actual  mem_KB_pred  \n",
       "111       36992        36992         -1.0        147.968   147.710592  \n",
       "291       24576        24576          1.0          0.000     0.000000  \n",
       "222       55488        55488         -1.0          0.000     0.000000  \n",
       "68        78400       117600          1.0          0.000    14.896512  \n",
       "218       55488        55488          1.0          0.000     0.000000  \n",
       "25        58800        58800         -1.0        235.200   230.245248  \n",
       "242       55488        12288          4.0          0.000    46.583680  \n",
       "209       55488        55488          1.0          0.000     0.000000  \n",
       "178       46240        46240          1.0          0.000     0.000000  \n",
       "76       117600       117600          1.0          0.000     2.772352  \n",
       "46        58800        58800         -1.0          0.000     0.000000  \n",
       "238       55488        55488         -1.0          0.000     0.000000  \n",
       "230       55488        55488         -1.0          0.000     0.000000  \n",
       "87       352800        78400          1.0          0.000     2.330496  \n",
       "200       55488        55488          1.0          0.000     0.000000  \n",
       "80       117600       117600         -1.0          0.000     2.359296  \n",
       "119      221952       221952          1.0        887.808   899.217408  \n",
       "107      221952        36992          1.0          0.000     0.000000  \n",
       "268       81920        12288          1.0          0.000     0.008192  \n",
       "69        58800        58800         -1.0          0.000     0.000000  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "X = cleaned.drop(['name', '[avg ms]', '[mem KB]', 'input_shape', 'output_shape', 'strides'], axis=1)  # Features\n",
    "y = cleaned['[mem KB]']  # Labels\n",
    "\n",
    "# Split dataset into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3) # 70% training and 30% test\n",
    "\n",
    "# Instantiate model with 1000 decision trees\n",
    "rf = RandomForestRegressor(n_estimators = 1000, random_state = 42)\n",
    "# Train the model on training data\n",
    "rf.fit(X_train, y_train);\n",
    "\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "print(\"MSE:\", mean_squared_error(y_test, y_pred))\n",
    "\n",
    "pd.concat([X_test, pd.DataFrame({'mem_KB_actual': y_test, 'mem_KB_pred': y_pred})], axis=1).sample(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.3499471311167615\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>units</th>\n",
       "      <th>filters</th>\n",
       "      <th>kernel_size</th>\n",
       "      <th>activation_linear</th>\n",
       "      <th>activation_relu</th>\n",
       "      <th>activation_softmax</th>\n",
       "      <th>activation_nan</th>\n",
       "      <th>activation_selu</th>\n",
       "      <th>activation_elu</th>\n",
       "      <th>activation_softplus</th>\n",
       "      <th>activation_softsign</th>\n",
       "      <th>activation_tanh</th>\n",
       "      <th>activation_sigmoid</th>\n",
       "      <th>activation_hard_sigmoid</th>\n",
       "      <th>activation_exponential</th>\n",
       "      <th>input_size</th>\n",
       "      <th>output_size</th>\n",
       "      <th>stride_size</th>\n",
       "      <th>avg_ms_actual</th>\n",
       "      <th>avg_ms_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>78400</td>\n",
       "      <td>78400</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>221952</td>\n",
       "      <td>55488</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>512.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>100352</td>\n",
       "      <td>100352</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.547</td>\n",
       "      <td>5.884671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>12288</td>\n",
       "      <td>12288</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.287</td>\n",
       "      <td>0.836314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>28672</td>\n",
       "      <td>28672</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.006932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>131072</td>\n",
       "      <td>131072</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.762</td>\n",
       "      <td>0.479530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>78400</td>\n",
       "      <td>78400</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.004020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>58800</td>\n",
       "      <td>78400</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.004720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>256.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>401408</td>\n",
       "      <td>802816</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.049</td>\n",
       "      <td>6.026361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>39200</td>\n",
       "      <td>39200</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.434</td>\n",
       "      <td>0.799501</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     units  filters  kernel_size  activation_linear  activation_relu  \\\n",
       "56    -1.0     -1.0         -1.0                  0                0   \n",
       "155   -1.0    192.0          1.0                  1                0   \n",
       "17    -1.0    512.0          9.0                  0                1   \n",
       "309   -1.0     -1.0         -1.0                  0                1   \n",
       "250   -1.0     -1.0         -1.0                  0                0   \n",
       "293   -1.0     -1.0         -1.0                  0                0   \n",
       "42    -1.0     -1.0         -1.0                  0                0   \n",
       "52    -1.0     64.0         25.0                  1                0   \n",
       "7     -1.0    256.0          9.0                  0                1   \n",
       "39    -1.0     -1.0         -1.0                  0                1   \n",
       "\n",
       "     activation_softmax  activation_nan  activation_selu  activation_elu  \\\n",
       "56                    0               1             -1.0            -1.0   \n",
       "155                   0               0             -1.0            -1.0   \n",
       "17                    0               0             -1.0            -1.0   \n",
       "309                   0               0             -1.0            -1.0   \n",
       "250                   0               1             -1.0            -1.0   \n",
       "293                   0               1             -1.0            -1.0   \n",
       "42                    0               1             -1.0            -1.0   \n",
       "52                    0               0             -1.0            -1.0   \n",
       "7                     0               0             -1.0            -1.0   \n",
       "39                    0               0             -1.0            -1.0   \n",
       "\n",
       "     activation_softplus  activation_softsign  activation_tanh  \\\n",
       "56                  -1.0                 -1.0             -1.0   \n",
       "155                 -1.0                 -1.0             -1.0   \n",
       "17                  -1.0                 -1.0             -1.0   \n",
       "309                 -1.0                 -1.0             -1.0   \n",
       "250                 -1.0                 -1.0             -1.0   \n",
       "293                 -1.0                 -1.0             -1.0   \n",
       "42                  -1.0                 -1.0             -1.0   \n",
       "52                  -1.0                 -1.0             -1.0   \n",
       "7                   -1.0                 -1.0             -1.0   \n",
       "39                  -1.0                 -1.0             -1.0   \n",
       "\n",
       "     activation_sigmoid  activation_hard_sigmoid  activation_exponential  \\\n",
       "56                 -1.0                     -1.0                    -1.0   \n",
       "155                -1.0                     -1.0                    -1.0   \n",
       "17                 -1.0                     -1.0                    -1.0   \n",
       "309                -1.0                     -1.0                    -1.0   \n",
       "250                -1.0                     -1.0                    -1.0   \n",
       "293                -1.0                     -1.0                    -1.0   \n",
       "42                 -1.0                     -1.0                    -1.0   \n",
       "52                 -1.0                     -1.0                    -1.0   \n",
       "7                  -1.0                     -1.0                    -1.0   \n",
       "39                 -1.0                     -1.0                    -1.0   \n",
       "\n",
       "     input_size  output_size  stride_size  avg_ms_actual  avg_ms_pred  \n",
       "56        78400        78400         -1.0          0.004     0.004020  \n",
       "155      221952        55488          1.0          0.002     0.002239  \n",
       "17       100352       100352          1.0          4.547     5.884671  \n",
       "309       12288        12288         -1.0          1.287     0.836314  \n",
       "250       28672        28672         -1.0          0.005     0.006932  \n",
       "293      131072       131072          1.0          0.762     0.479530  \n",
       "42        78400        78400         -1.0          0.003     0.004020  \n",
       "52        58800        78400          1.0          0.002     0.004720  \n",
       "7        401408       802816          1.0          7.049     6.026361  \n",
       "39        39200        39200         -1.0          0.434     0.799501  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# AVG MS RF\n",
    "cnn_ms_rf, X_test, y_test = rf_regression_model(cleaned, '[avg ms]')\n",
    "cnn_train_data = cleaned\n",
    "\n",
    "y_pred = cnn_ms_rf.predict(X_test)\n",
    "\n",
    "print(\"MSE:\", mean_squared_error(y_test, y_pred))\n",
    "\n",
    "cnn_ms_rf_mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "pd.concat([X_test, pd.DataFrame({'avg_ms_actual': y_test, 'avg_ms_pred': y_pred})], axis=1).sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 70984.64512575942\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>units</th>\n",
       "      <th>filters</th>\n",
       "      <th>kernel_size</th>\n",
       "      <th>activation_linear</th>\n",
       "      <th>activation_relu</th>\n",
       "      <th>activation_softmax</th>\n",
       "      <th>activation_nan</th>\n",
       "      <th>activation_selu</th>\n",
       "      <th>activation_elu</th>\n",
       "      <th>activation_softplus</th>\n",
       "      <th>activation_softsign</th>\n",
       "      <th>activation_tanh</th>\n",
       "      <th>activation_sigmoid</th>\n",
       "      <th>activation_hard_sigmoid</th>\n",
       "      <th>activation_exponential</th>\n",
       "      <th>input_size</th>\n",
       "      <th>output_size</th>\n",
       "      <th>stride_size</th>\n",
       "      <th>mem_kb_actual</th>\n",
       "      <th>mem_kb_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>221952</td>\n",
       "      <td>55488</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>268203</td>\n",
       "      <td>710432</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>400.351360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>221952</td>\n",
       "      <td>221952</td>\n",
       "      <td>1.0</td>\n",
       "      <td>887.808</td>\n",
       "      <td>888.982528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>117600</td>\n",
       "      <td>117600</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>470.400</td>\n",
       "      <td>463.789312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>100352</td>\n",
       "      <td>25088</td>\n",
       "      <td>4.0</td>\n",
       "      <td>100.352</td>\n",
       "      <td>117.181696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1382976</td>\n",
       "      <td>341056</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1364.224</td>\n",
       "      <td>1497.272128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>221952</td>\n",
       "      <td>55488</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>235200</td>\n",
       "      <td>58800</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>55488</td>\n",
       "      <td>55488</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>24576</td>\n",
       "      <td>24576</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>98.304</td>\n",
       "      <td>98.304000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     units  filters  kernel_size  activation_linear  activation_relu  \\\n",
       "229   -1.0    192.0          1.0                  1                0   \n",
       "1     -1.0     32.0          9.0                  1                0   \n",
       "151   -1.0     -1.0         -1.0                  0                0   \n",
       "92    -1.0     -1.0         -1.0                  0                1   \n",
       "18    -1.0     -1.0         -1.0                  0                0   \n",
       "10    -1.0     -1.0         -1.0                  0                0   \n",
       "123   -1.0    192.0          1.0                  1                0   \n",
       "21    -1.0     48.0          1.0                  1                0   \n",
       "232   -1.0    192.0          7.0                  1                0   \n",
       "288   -1.0     -1.0         -1.0                  0                1   \n",
       "\n",
       "     activation_softmax  activation_nan  activation_selu  activation_elu  \\\n",
       "229                   0               0             -1.0            -1.0   \n",
       "1                     0               0             -1.0            -1.0   \n",
       "151                   0               1             -1.0            -1.0   \n",
       "92                    0               0             -1.0            -1.0   \n",
       "18                    0               1             -1.0            -1.0   \n",
       "10                    0               1             -1.0            -1.0   \n",
       "123                   0               0             -1.0            -1.0   \n",
       "21                    0               0             -1.0            -1.0   \n",
       "232                   0               0             -1.0            -1.0   \n",
       "288                   0               0             -1.0            -1.0   \n",
       "\n",
       "     activation_softplus  activation_softsign  activation_tanh  \\\n",
       "229                 -1.0                 -1.0             -1.0   \n",
       "1                   -1.0                 -1.0             -1.0   \n",
       "151                 -1.0                 -1.0             -1.0   \n",
       "92                  -1.0                 -1.0             -1.0   \n",
       "18                  -1.0                 -1.0             -1.0   \n",
       "10                  -1.0                 -1.0             -1.0   \n",
       "123                 -1.0                 -1.0             -1.0   \n",
       "21                  -1.0                 -1.0             -1.0   \n",
       "232                 -1.0                 -1.0             -1.0   \n",
       "288                 -1.0                 -1.0             -1.0   \n",
       "\n",
       "     activation_sigmoid  activation_hard_sigmoid  activation_exponential  \\\n",
       "229                -1.0                     -1.0                    -1.0   \n",
       "1                  -1.0                     -1.0                    -1.0   \n",
       "151                -1.0                     -1.0                    -1.0   \n",
       "92                 -1.0                     -1.0                    -1.0   \n",
       "18                 -1.0                     -1.0                    -1.0   \n",
       "10                 -1.0                     -1.0                    -1.0   \n",
       "123                -1.0                     -1.0                    -1.0   \n",
       "21                 -1.0                     -1.0                    -1.0   \n",
       "232                -1.0                     -1.0                    -1.0   \n",
       "288                -1.0                     -1.0                    -1.0   \n",
       "\n",
       "     input_size  output_size  stride_size  mem_kb_actual  mem_kb_pred  \n",
       "229      221952        55488          1.0          0.000     0.000000  \n",
       "1        268203       710432          4.0          0.000   400.351360  \n",
       "151      221952       221952          1.0        887.808   888.982528  \n",
       "92       117600       117600         -1.0        470.400   463.789312  \n",
       "18       100352        25088          4.0        100.352   117.181696  \n",
       "10      1382976       341056          4.0       1364.224  1497.272128  \n",
       "123      221952        55488          1.0          0.000     0.000000  \n",
       "21       235200        58800          1.0          0.000     0.000000  \n",
       "232       55488        55488          1.0          0.000     0.000000  \n",
       "288       24576        24576         -1.0         98.304    98.304000  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MEM KB RF\n",
    "cnn_mem_rf, X_test, y_test = rf_regression_model(cleaned, '[mem KB]')\n",
    "\n",
    "y_pred = cnn_mem_rf.predict(X_test)\n",
    "\n",
    "print(\"MSE:\", mean_squared_error(y_test, y_pred))\n",
    "cnn_mem_rf_mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "pd.concat([X_test, pd.DataFrame({'mem_kb_actual': y_test, 'mem_kb_pred': y_pred})], axis=1).sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brian/anaconda/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 2.2940391907913917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brian/anaconda/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/brian/anaconda/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/brian/anaconda/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/brian/anaconda/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/brian/anaconda/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>units</th>\n",
       "      <th>filters</th>\n",
       "      <th>kernel_size</th>\n",
       "      <th>activation_linear</th>\n",
       "      <th>activation_relu</th>\n",
       "      <th>activation_softmax</th>\n",
       "      <th>activation_nan</th>\n",
       "      <th>activation_selu</th>\n",
       "      <th>activation_elu</th>\n",
       "      <th>activation_softplus</th>\n",
       "      <th>activation_softsign</th>\n",
       "      <th>activation_tanh</th>\n",
       "      <th>activation_sigmoid</th>\n",
       "      <th>activation_hard_sigmoid</th>\n",
       "      <th>activation_exponential</th>\n",
       "      <th>input_size</th>\n",
       "      <th>output_size</th>\n",
       "      <th>stride_size</th>\n",
       "      <th>avg_ms_actual</th>\n",
       "      <th>avg_ms_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>221952</td>\n",
       "      <td>46240</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.420535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>78400</td>\n",
       "      <td>78400</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.263402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>55488</td>\n",
       "      <td>55488</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.286609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>12288</td>\n",
       "      <td>12288</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.287</td>\n",
       "      <td>0.749305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>221952</td>\n",
       "      <td>55488</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.336043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>55488</td>\n",
       "      <td>55488</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.708</td>\n",
       "      <td>0.992539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>117600</td>\n",
       "      <td>117600</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.290</td>\n",
       "      <td>1.376630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>78400</td>\n",
       "      <td>78400</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.925</td>\n",
       "      <td>0.824567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>58800</td>\n",
       "      <td>58800</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.450</td>\n",
       "      <td>0.522446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>55488</td>\n",
       "      <td>55488</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.671</td>\n",
       "      <td>0.992539</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     units  filters  kernel_size  activation_linear  activation_relu  \\\n",
       "139   -1.0    160.0          1.0                  1                0   \n",
       "55    -1.0     -1.0         -1.0                  0                0   \n",
       "125   -1.0     -1.0         -1.0                  0                0   \n",
       "309   -1.0     -1.0         -1.0                  0                1   \n",
       "216   -1.0    192.0          1.0                  1                0   \n",
       "129   -1.0     -1.0         -1.0                  0                1   \n",
       "49    -1.0     -1.0         -1.0                  0                1   \n",
       "83    -1.0     -1.0         -1.0                  0                1   \n",
       "25    -1.0     -1.0         -1.0                  0                1   \n",
       "239   -1.0     -1.0         -1.0                  0                1   \n",
       "\n",
       "     activation_softmax  activation_nan  activation_selu  activation_elu  \\\n",
       "139                   0               0             -1.0            -1.0   \n",
       "55                    0               1             -1.0            -1.0   \n",
       "125                   0               1             -1.0            -1.0   \n",
       "309                   0               0             -1.0            -1.0   \n",
       "216                   0               0             -1.0            -1.0   \n",
       "129                   0               0             -1.0            -1.0   \n",
       "49                    0               0             -1.0            -1.0   \n",
       "83                    0               0             -1.0            -1.0   \n",
       "25                    0               0             -1.0            -1.0   \n",
       "239                   0               0             -1.0            -1.0   \n",
       "\n",
       "     activation_softplus  activation_softsign  activation_tanh  \\\n",
       "139                 -1.0                 -1.0             -1.0   \n",
       "55                  -1.0                 -1.0             -1.0   \n",
       "125                 -1.0                 -1.0             -1.0   \n",
       "309                 -1.0                 -1.0             -1.0   \n",
       "216                 -1.0                 -1.0             -1.0   \n",
       "129                 -1.0                 -1.0             -1.0   \n",
       "49                  -1.0                 -1.0             -1.0   \n",
       "83                  -1.0                 -1.0             -1.0   \n",
       "25                  -1.0                 -1.0             -1.0   \n",
       "239                 -1.0                 -1.0             -1.0   \n",
       "\n",
       "     activation_sigmoid  activation_hard_sigmoid  activation_exponential  \\\n",
       "139                -1.0                     -1.0                    -1.0   \n",
       "55                 -1.0                     -1.0                    -1.0   \n",
       "125                -1.0                     -1.0                    -1.0   \n",
       "309                -1.0                     -1.0                    -1.0   \n",
       "216                -1.0                     -1.0                    -1.0   \n",
       "129                -1.0                     -1.0                    -1.0   \n",
       "49                 -1.0                     -1.0                    -1.0   \n",
       "83                 -1.0                     -1.0                    -1.0   \n",
       "25                 -1.0                     -1.0                    -1.0   \n",
       "239                -1.0                     -1.0                    -1.0   \n",
       "\n",
       "     input_size  output_size  stride_size  avg_ms_actual  avg_ms_pred  \n",
       "139      221952        46240          1.0          0.002     0.420535  \n",
       "55        78400        78400         -1.0          0.005     0.263402  \n",
       "125       55488        55488         -1.0          0.003     0.286609  \n",
       "309       12288        12288         -1.0          1.287     0.749305  \n",
       "216      221952        55488          1.0          0.002     0.336043  \n",
       "129       55488        55488         -1.0          0.708     0.992539  \n",
       "49       117600       117600         -1.0          1.290     1.376630  \n",
       "83        78400        78400         -1.0          1.925     0.824567  \n",
       "25        58800        58800         -1.0          0.450     0.522446  \n",
       "239       55488        55488         -1.0          0.671     0.992539  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# AVG MS stacked\n",
    "cnn_ms_stacked_1, X_test, y_test = stacked_regression_model(cleaned, '[avg ms]')\n",
    "\n",
    "y_pred = cnn_ms_stacked_1.predict(X_test)\n",
    "\n",
    "print(\"MSE:\", mean_squared_error(y_test, y_pred))\n",
    "cnn_ms_stacked_1_mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "pd.concat([X_test, pd.DataFrame({'avg_ms_actual': y_test, 'avg_ms_pred': y_pred})], axis=1).sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brian/anaconda/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/brian/anaconda/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/brian/anaconda/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/brian/anaconda/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/brian/anaconda/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/brian/anaconda/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 1076248.8717503173\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>units</th>\n",
       "      <th>filters</th>\n",
       "      <th>kernel_size</th>\n",
       "      <th>activation_linear</th>\n",
       "      <th>activation_relu</th>\n",
       "      <th>activation_softmax</th>\n",
       "      <th>activation_nan</th>\n",
       "      <th>activation_selu</th>\n",
       "      <th>activation_elu</th>\n",
       "      <th>activation_softplus</th>\n",
       "      <th>activation_softsign</th>\n",
       "      <th>activation_tanh</th>\n",
       "      <th>activation_sigmoid</th>\n",
       "      <th>activation_hard_sigmoid</th>\n",
       "      <th>activation_exponential</th>\n",
       "      <th>input_size</th>\n",
       "      <th>output_size</th>\n",
       "      <th>stride_size</th>\n",
       "      <th>mem_kb_actual</th>\n",
       "      <th>mem_kb_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>78400</td>\n",
       "      <td>117600</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>20.702398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>221952</td>\n",
       "      <td>46240</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-2.656129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>55488</td>\n",
       "      <td>55488</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>221.952</td>\n",
       "      <td>276.701087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>39200</td>\n",
       "      <td>39200</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>156.800</td>\n",
       "      <td>213.228637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>117600</td>\n",
       "      <td>117600</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>100.991929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>24576</td>\n",
       "      <td>24576</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>98.304</td>\n",
       "      <td>166.092819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>117600</td>\n",
       "      <td>117600</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>28.740704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>221952</td>\n",
       "      <td>221952</td>\n",
       "      <td>1.0</td>\n",
       "      <td>887.808</td>\n",
       "      <td>784.072508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>352800</td>\n",
       "      <td>352800</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1411.200</td>\n",
       "      <td>1207.010633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1605632</td>\n",
       "      <td>401408</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1605.632</td>\n",
       "      <td>1485.698043</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     units  filters  kernel_size  activation_linear  activation_relu  \\\n",
       "68    -1.0     96.0          9.0                  1                0   \n",
       "171   -1.0    160.0          1.0                  1                0   \n",
       "214   -1.0     -1.0         -1.0                  0                1   \n",
       "39    -1.0     -1.0         -1.0                  0                1   \n",
       "80    -1.0     -1.0         -1.0                  0                0   \n",
       "303   -1.0     -1.0         -1.0                  0                1   \n",
       "76    -1.0     96.0          9.0                  1                0   \n",
       "183   -1.0     -1.0         -1.0                  0                0   \n",
       "73    -1.0     -1.0         -1.0                  0                0   \n",
       "6     -1.0     -1.0         -1.0                  0                0   \n",
       "\n",
       "     activation_softmax  activation_nan  activation_selu  activation_elu  \\\n",
       "68                    0               0             -1.0            -1.0   \n",
       "171                   0               0             -1.0            -1.0   \n",
       "214                   0               0             -1.0            -1.0   \n",
       "39                    0               0             -1.0            -1.0   \n",
       "80                    0               1             -1.0            -1.0   \n",
       "303                   0               0             -1.0            -1.0   \n",
       "76                    0               0             -1.0            -1.0   \n",
       "183                   0               1             -1.0            -1.0   \n",
       "73                    0               1             -1.0            -1.0   \n",
       "6                     0               1             -1.0            -1.0   \n",
       "\n",
       "     activation_softplus  activation_softsign  activation_tanh  \\\n",
       "68                  -1.0                 -1.0             -1.0   \n",
       "171                 -1.0                 -1.0             -1.0   \n",
       "214                 -1.0                 -1.0             -1.0   \n",
       "39                  -1.0                 -1.0             -1.0   \n",
       "80                  -1.0                 -1.0             -1.0   \n",
       "303                 -1.0                 -1.0             -1.0   \n",
       "76                  -1.0                 -1.0             -1.0   \n",
       "183                 -1.0                 -1.0             -1.0   \n",
       "73                  -1.0                 -1.0             -1.0   \n",
       "6                   -1.0                 -1.0             -1.0   \n",
       "\n",
       "     activation_sigmoid  activation_hard_sigmoid  activation_exponential  \\\n",
       "68                 -1.0                     -1.0                    -1.0   \n",
       "171                -1.0                     -1.0                    -1.0   \n",
       "214                -1.0                     -1.0                    -1.0   \n",
       "39                 -1.0                     -1.0                    -1.0   \n",
       "80                 -1.0                     -1.0                    -1.0   \n",
       "303                -1.0                     -1.0                    -1.0   \n",
       "76                 -1.0                     -1.0                    -1.0   \n",
       "183                -1.0                     -1.0                    -1.0   \n",
       "73                 -1.0                     -1.0                    -1.0   \n",
       "6                  -1.0                     -1.0                    -1.0   \n",
       "\n",
       "     input_size  output_size  stride_size  mem_kb_actual  mem_kb_pred  \n",
       "68        78400       117600          1.0          0.000    20.702398  \n",
       "171      221952        46240          1.0          0.000    -2.656129  \n",
       "214       55488        55488         -1.0        221.952   276.701087  \n",
       "39        39200        39200         -1.0        156.800   213.228637  \n",
       "80       117600       117600         -1.0          0.000   100.991929  \n",
       "303       24576        24576         -1.0         98.304   166.092819  \n",
       "76       117600       117600          1.0          0.000    28.740704  \n",
       "183      221952       221952          1.0        887.808   784.072508  \n",
       "73       352800       352800          1.0       1411.200  1207.010633  \n",
       "6       1605632       401408          4.0       1605.632  1485.698043  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# AVG MEM stacked\n",
    "cnn_mem_stacked_1, X_test, y_test = stacked_regression_model(cleaned, '[mem KB]')\n",
    "\n",
    "y_pred = cnn_mem_stacked_1.predict(X_test)\n",
    "\n",
    "print(\"MSE:\", mean_squared_error(y_test, y_pred))\n",
    "cnn_mem_stacked_1_mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "pd.concat([X_test, pd.DataFrame({'mem_kb_actual': y_test, 'mem_kb_pred': y_pred})], axis=1).sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brian/anaconda/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 79.61104081858598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brian/anaconda/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/brian/anaconda/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/brian/anaconda/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/brian/anaconda/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/brian/anaconda/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>units</th>\n",
       "      <th>filters</th>\n",
       "      <th>kernel_size</th>\n",
       "      <th>activation_linear</th>\n",
       "      <th>activation_relu</th>\n",
       "      <th>activation_softmax</th>\n",
       "      <th>activation_nan</th>\n",
       "      <th>activation_selu</th>\n",
       "      <th>activation_elu</th>\n",
       "      <th>activation_softplus</th>\n",
       "      <th>activation_softsign</th>\n",
       "      <th>activation_tanh</th>\n",
       "      <th>activation_sigmoid</th>\n",
       "      <th>activation_hard_sigmoid</th>\n",
       "      <th>activation_exponential</th>\n",
       "      <th>input_size</th>\n",
       "      <th>output_size</th>\n",
       "      <th>stride_size</th>\n",
       "      <th>avg_ms_actual</th>\n",
       "      <th>avg_ms_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>426320</td>\n",
       "      <td>967872</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.002</td>\n",
       "      <td>-7.434774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>24576</td>\n",
       "      <td>24576</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.008</td>\n",
       "      <td>-8.968249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>221952</td>\n",
       "      <td>55488</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.002</td>\n",
       "      <td>-9.039889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>55488</td>\n",
       "      <td>55488</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.073</td>\n",
       "      <td>-7.682186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>55488</td>\n",
       "      <td>55488</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.003</td>\n",
       "      <td>-8.534105</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     units  filters  kernel_size  activation_linear  activation_relu  \\\n",
       "14    -1.0    192.0          9.0                  1                0   \n",
       "298   -1.0     -1.0         -1.0                  0                0   \n",
       "155   -1.0    192.0          1.0                  1                0   \n",
       "192   -1.0     -1.0         -1.0                  0                1   \n",
       "217   -1.0    192.0          7.0                  1                0   \n",
       "\n",
       "     activation_softmax  activation_nan  activation_selu  activation_elu  \\\n",
       "14                    0               0             -1.0            -1.0   \n",
       "298                   0               1             -1.0            -1.0   \n",
       "155                   0               0             -1.0            -1.0   \n",
       "192                   0               0             -1.0            -1.0   \n",
       "217                   0               0             -1.0            -1.0   \n",
       "\n",
       "     activation_softplus  activation_softsign  activation_tanh  \\\n",
       "14                  -1.0                 -1.0             -1.0   \n",
       "298                 -1.0                 -1.0             -1.0   \n",
       "155                 -1.0                 -1.0             -1.0   \n",
       "192                 -1.0                 -1.0             -1.0   \n",
       "217                 -1.0                 -1.0             -1.0   \n",
       "\n",
       "     activation_sigmoid  activation_hard_sigmoid  activation_exponential  \\\n",
       "14                 -1.0                     -1.0                    -1.0   \n",
       "298                -1.0                     -1.0                    -1.0   \n",
       "155                -1.0                     -1.0                    -1.0   \n",
       "192                -1.0                     -1.0                    -1.0   \n",
       "217                -1.0                     -1.0                    -1.0   \n",
       "\n",
       "     input_size  output_size  stride_size  avg_ms_actual  avg_ms_pred  \n",
       "14       426320       967872          1.0          0.002    -7.434774  \n",
       "298       24576        24576         -1.0          0.008    -8.968249  \n",
       "155      221952        55488          1.0          0.002    -9.039889  \n",
       "192       55488        55488         -1.0          1.073    -7.682186  \n",
       "217       55488        55488          1.0          0.003    -8.534105  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lstm stacked avg ms\n",
    "cnn_ms_stacked_2, X_test, y_test = stacked_regression_model_2(cleaned, '[avg ms]')\n",
    "\n",
    "y_pred = cnn_ms_stacked_2.predict(X_test)\n",
    "\n",
    "print(\"MSE:\", mean_squared_error(y_test, y_pred))\n",
    "cnn_ms_stacked_2_mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "pd.concat([X_test, pd.DataFrame({'avg_ms_actual': y_test, 'avg_ms_pred': y_pred})], axis=1).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brian/anaconda/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 1.0917266885366172e+19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brian/anaconda/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/brian/anaconda/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/brian/anaconda/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/brian/anaconda/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/brian/anaconda/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>units</th>\n",
       "      <th>filters</th>\n",
       "      <th>kernel_size</th>\n",
       "      <th>activation_linear</th>\n",
       "      <th>activation_relu</th>\n",
       "      <th>activation_softmax</th>\n",
       "      <th>activation_nan</th>\n",
       "      <th>activation_selu</th>\n",
       "      <th>activation_elu</th>\n",
       "      <th>activation_softplus</th>\n",
       "      <th>activation_softsign</th>\n",
       "      <th>activation_tanh</th>\n",
       "      <th>activation_sigmoid</th>\n",
       "      <th>activation_hard_sigmoid</th>\n",
       "      <th>activation_exponential</th>\n",
       "      <th>input_size</th>\n",
       "      <th>output_size</th>\n",
       "      <th>stride_size</th>\n",
       "      <th>mem_kb_actual</th>\n",
       "      <th>mem_kb_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>55488</td>\n",
       "      <td>55488</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-3.304109e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>117600</td>\n",
       "      <td>117600</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>470.400</td>\n",
       "      <td>-3.304109e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>12288</td>\n",
       "      <td>12288</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-3.304109e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>512.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>100352</td>\n",
       "      <td>100352</td>\n",
       "      <td>1.0</td>\n",
       "      <td>401.408</td>\n",
       "      <td>-3.304106e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>58800</td>\n",
       "      <td>58800</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-3.304109e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     units  filters  kernel_size  activation_linear  activation_relu  \\\n",
       "222   -1.0     -1.0         -1.0                  0                0   \n",
       "84    -1.0     -1.0         -1.0                  0                1   \n",
       "274   -1.0     -1.0         -1.0                  0                0   \n",
       "16    -1.0    512.0          9.0                  0                1   \n",
       "23    -1.0     -1.0         -1.0                  0                0   \n",
       "\n",
       "     activation_softmax  activation_nan  activation_selu  activation_elu  \\\n",
       "222                   0               1             -1.0            -1.0   \n",
       "84                    0               0             -1.0            -1.0   \n",
       "274                   0               1             -1.0            -1.0   \n",
       "16                    0               0             -1.0            -1.0   \n",
       "23                    0               1             -1.0            -1.0   \n",
       "\n",
       "     activation_softplus  activation_softsign  activation_tanh  \\\n",
       "222                 -1.0                 -1.0             -1.0   \n",
       "84                  -1.0                 -1.0             -1.0   \n",
       "274                 -1.0                 -1.0             -1.0   \n",
       "16                  -1.0                 -1.0             -1.0   \n",
       "23                  -1.0                 -1.0             -1.0   \n",
       "\n",
       "     activation_sigmoid  activation_hard_sigmoid  activation_exponential  \\\n",
       "222                -1.0                     -1.0                    -1.0   \n",
       "84                 -1.0                     -1.0                    -1.0   \n",
       "274                -1.0                     -1.0                    -1.0   \n",
       "16                 -1.0                     -1.0                    -1.0   \n",
       "23                 -1.0                     -1.0                    -1.0   \n",
       "\n",
       "     input_size  output_size  stride_size  mem_kb_actual   mem_kb_pred  \n",
       "222       55488        55488         -1.0          0.000 -3.304109e+09  \n",
       "84       117600       117600         -1.0        470.400 -3.304109e+09  \n",
       "274       12288        12288         -1.0          0.000 -3.304109e+09  \n",
       "16       100352       100352          1.0        401.408 -3.304106e+09  \n",
       "23        58800        58800         -1.0          0.000 -3.304109e+09  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lstm stacked mem\n",
    "cnn_mem_stacked_2, X_test, y_test = stacked_regression_model_2(cleaned, '[mem KB]')\n",
    "\n",
    "y_pred = cnn_mem_stacked_2.predict(X_test)\n",
    "\n",
    "print(\"MSE:\", mean_squared_error(y_test, y_pred))\n",
    "cnn_mem_stacked_2_mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "pd.concat([X_test, pd.DataFrame({'mem_kb_actual': y_test, 'mem_kb_pred': y_pred})], axis=1).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/brian/anaconda/lib/python3.6/site-packages/tensorflow/python/keras/initializers.py:119: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /Users/brian/anaconda/lib/python3.6/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Retrieving saved model and benchmark results.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>[node type]</th>\n",
       "      <th>[start]</th>\n",
       "      <th>[first]</th>\n",
       "      <th>[avg ms]</th>\n",
       "      <th>[%]</th>\n",
       "      <th>[cdf%]</th>\n",
       "      <th>[mem KB]</th>\n",
       "      <th>[times called]</th>\n",
       "      <th>[Name]</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Enter</td>\n",
       "      <td>171.058</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.002%</td>\n",
       "      <td>9.435%</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1</td>\n",
       "      <td>lstm5/while/TensorArrayReadV3/Enter_1</td>\n",
       "      <td>lstm5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>Const</td>\n",
       "      <td>-24.271</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.001%</td>\n",
       "      <td>75.558%</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1</td>\n",
       "      <td>lstm2/kernel</td>\n",
       "      <td>lstm2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>Switch</td>\n",
       "      <td>-0.856</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.341%</td>\n",
       "      <td>88.465%</td>\n",
       "      <td>0.000</td>\n",
       "      <td>251</td>\n",
       "      <td>lstm1/while/Switch_2</td>\n",
       "      <td>lstm1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>Enter</td>\n",
       "      <td>-24.129</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.001%</td>\n",
       "      <td>75.611%</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1</td>\n",
       "      <td>lstm3/while/Enter_1</td>\n",
       "      <td>lstm3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>460</th>\n",
       "      <td>Range</td>\n",
       "      <td>-23.890</td>\n",
       "      <td>0.045</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.005%</td>\n",
       "      <td>84.005%</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1</td>\n",
       "      <td>lstm1/TensorArrayUnstack/range</td>\n",
       "      <td>lstm1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>Const</td>\n",
       "      <td>190.609</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.229%</td>\n",
       "      <td>15.452%</td>\n",
       "      <td>0.000</td>\n",
       "      <td>250</td>\n",
       "      <td>ConstantFolding/lstm5/while/split_1-folded-1</td>\n",
       "      <td>ConstantFolding</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>Enter</td>\n",
       "      <td>120.857</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.003%</td>\n",
       "      <td>34.794%</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1</td>\n",
       "      <td>lstm4/while/TensorArrayReadV3/Enter</td>\n",
       "      <td>lstm4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>Mul</td>\n",
       "      <td>46.095</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.221%</td>\n",
       "      <td>62.502%</td>\n",
       "      <td>0.000</td>\n",
       "      <td>250</td>\n",
       "      <td>lstm2/while/Mul</td>\n",
       "      <td>lstm2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>Const</td>\n",
       "      <td>-24.330</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.001%</td>\n",
       "      <td>75.544%</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1</td>\n",
       "      <td>lstm5/bias</td>\n",
       "      <td>lstm5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>Less</td>\n",
       "      <td>190.664</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.338%</td>\n",
       "      <td>17.811%</td>\n",
       "      <td>0.001</td>\n",
       "      <td>251</td>\n",
       "      <td>lstm5/while/Less_1</td>\n",
       "      <td>lstm5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465</th>\n",
       "      <td>Identity</td>\n",
       "      <td>-5.152</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.242%</td>\n",
       "      <td>85.160%</td>\n",
       "      <td>0.000</td>\n",
       "      <td>250</td>\n",
       "      <td>lstm1/while/Identity</td>\n",
       "      <td>lstm1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>Const</td>\n",
       "      <td>41.708</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.233%</td>\n",
       "      <td>74.002%</td>\n",
       "      <td>0.000</td>\n",
       "      <td>250</td>\n",
       "      <td>lstm2/while/strided_slice_1</td>\n",
       "      <td>lstm2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>NextIteration</td>\n",
       "      <td>91.052</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.420%</td>\n",
       "      <td>52.040%</td>\n",
       "      <td>0.000</td>\n",
       "      <td>250</td>\n",
       "      <td>lstm3/while/NextIteration</td>\n",
       "      <td>lstm3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>Const</td>\n",
       "      <td>-24.249</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.001%</td>\n",
       "      <td>75.563%</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1</td>\n",
       "      <td>lstm5/strided_slice_7/stack</td>\n",
       "      <td>lstm5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>Merge</td>\n",
       "      <td>144.830</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.437%</td>\n",
       "      <td>34.792%</td>\n",
       "      <td>0.004</td>\n",
       "      <td>251</td>\n",
       "      <td>lstm4/while/Merge_3</td>\n",
       "      <td>lstm4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  [node type]  [start]  [first]  [avg ms]       [%]    [cdf%]  \\\n",
       "39                      Enter  171.058    0.006     0.004    0.002%    9.435%   \n",
       "380                     Const  -24.271    0.002     0.003    0.001%   75.558%   \n",
       "485                    Switch   -0.856    0.008     0.003    0.341%   88.465%   \n",
       "417                     Enter  -24.129    0.003     0.003    0.001%   75.611%   \n",
       "460                     Range  -23.890    0.045     0.013    0.005%   84.005%   \n",
       "63                      Const  190.609    0.003     0.002    0.229%   15.452%   \n",
       "151                     Enter  120.857    0.023     0.006    0.003%   34.794%   \n",
       "288                       Mul   46.095    0.006     0.002    0.221%   62.502%   \n",
       "362                     Const  -24.330    0.003     0.002    0.001%   75.544%   \n",
       "72                       Less  190.664    0.008     0.003    0.338%   17.811%   \n",
       "465                  Identity   -5.152    0.006     0.002    0.242%   85.160%   \n",
       "340                     Const   41.708    0.005     0.002    0.233%   74.002%   \n",
       "238             NextIteration   91.052    0.006     0.004    0.420%   52.040%   \n",
       "387                     Const  -24.249    0.002     0.002    0.001%   75.563%   \n",
       "150                     Merge  144.830    0.025     0.004    0.437%   34.792%   \n",
       "\n",
       "     [mem KB]  [times called]                                        [Name]  \\\n",
       "39      0.000               1         lstm5/while/TensorArrayReadV3/Enter_1   \n",
       "380     0.000               1                                  lstm2/kernel   \n",
       "485     0.000             251                          lstm1/while/Switch_2   \n",
       "417     0.000               1                           lstm3/while/Enter_1   \n",
       "460     1.000               1                lstm1/TensorArrayUnstack/range   \n",
       "63      0.000             250  ConstantFolding/lstm5/while/split_1-folded-1   \n",
       "151     0.000               1           lstm4/while/TensorArrayReadV3/Enter   \n",
       "288     0.000             250                               lstm2/while/Mul   \n",
       "362     0.000               1                                    lstm5/bias   \n",
       "72      0.001             251                            lstm5/while/Less_1   \n",
       "465     0.000             250                          lstm1/while/Identity   \n",
       "340     0.000             250                   lstm2/while/strided_slice_1   \n",
       "238     0.000             250                     lstm3/while/NextIteration   \n",
       "387     0.000               1                   lstm5/strided_slice_7/stack   \n",
       "150     0.004             251                           lstm4/while/Merge_3   \n",
       "\n",
       "                name  \n",
       "39             lstm5  \n",
       "380            lstm2  \n",
       "485            lstm1  \n",
       "417            lstm3  \n",
       "460            lstm1  \n",
       "63   ConstantFolding  \n",
       "151            lstm4  \n",
       "288            lstm2  \n",
       "362            lstm5  \n",
       "72             lstm5  \n",
       "465            lstm1  \n",
       "340            lstm2  \n",
       "238            lstm3  \n",
       "387            lstm5  \n",
       "150            lstm4  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lstm.summary()\n",
    "\n",
    "tf.keras.backend.clear_session() # IMPORTANT for layer names to match up.\n",
    "\n",
    "lstm = create_lstm()\n",
    "\n",
    "# tf.keras.backend.set_learning_phase(0)\n",
    "lstm_benchmark = benchmark_model(lstm)\n",
    "lstm_benchmark.sample(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lstm_features = get_layer_features(lstm)\n",
    "lstm_df = join_benchmark(lstm_features, lstm_benchmark)\n",
    "cleaned_lstm = clean(lstm_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.003043146131333064\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>units</th>\n",
       "      <th>filters</th>\n",
       "      <th>kernel_size</th>\n",
       "      <th>activation_relu</th>\n",
       "      <th>activation_sigmoid</th>\n",
       "      <th>activation_tanh</th>\n",
       "      <th>activation_nan</th>\n",
       "      <th>activation_selu</th>\n",
       "      <th>activation_elu</th>\n",
       "      <th>activation_softmax</th>\n",
       "      <th>activation_softplus</th>\n",
       "      <th>activation_softsign</th>\n",
       "      <th>activation_hard_sigmoid</th>\n",
       "      <th>activation_exponential</th>\n",
       "      <th>activation_linear</th>\n",
       "      <th>input_size</th>\n",
       "      <th>output_size</th>\n",
       "      <th>stride_size</th>\n",
       "      <th>avg_ms_actual</th>\n",
       "      <th>avg_ms_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>48.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>32000</td>\n",
       "      <td>48</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.941</td>\n",
       "      <td>0.900587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>16000</td>\n",
       "      <td>16000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.166</td>\n",
       "      <td>0.242828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>64.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>8000</td>\n",
       "      <td>16000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.940</td>\n",
       "      <td>0.900079</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   units  filters  kernel_size  activation_relu  activation_sigmoid  \\\n",
       "7   48.0     -1.0         -1.0                0                   0   \n",
       "1   -1.0     32.0          3.0                1                   0   \n",
       "5   64.0     -1.0         -1.0                0                   0   \n",
       "\n",
       "   activation_tanh  activation_nan  activation_selu  activation_elu  \\\n",
       "7                1               0             -1.0            -1.0   \n",
       "1                0               0             -1.0            -1.0   \n",
       "5                1               0             -1.0            -1.0   \n",
       "\n",
       "   activation_softmax  activation_softplus  activation_softsign  \\\n",
       "7                -1.0                 -1.0                 -1.0   \n",
       "1                -1.0                 -1.0                 -1.0   \n",
       "5                -1.0                 -1.0                 -1.0   \n",
       "\n",
       "   activation_hard_sigmoid  activation_exponential  activation_linear  \\\n",
       "7                     -1.0                    -1.0               -1.0   \n",
       "1                     -1.0                    -1.0               -1.0   \n",
       "5                     -1.0                    -1.0               -1.0   \n",
       "\n",
       "   input_size  output_size  stride_size  avg_ms_actual  avg_ms_pred  \n",
       "7       32000           48         -1.0          0.941     0.900587  \n",
       "1       16000        16000          1.0          0.166     0.242828  \n",
       "5        8000        16000         -1.0          0.940     0.900079  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf, X_test, y_test = rf_regression_model(cleaned_lstm, '[avg ms]')\n",
    "\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "print(\"MSE:\", mean_squared_error(y_test, y_pred))\n",
    "\n",
    "pd.concat([X_test, pd.DataFrame({'avg_ms_actual': y_test, 'avg_ms_pred': y_pred})], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 363.04756968992393\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>units</th>\n",
       "      <th>filters</th>\n",
       "      <th>kernel_size</th>\n",
       "      <th>activation_relu</th>\n",
       "      <th>activation_sigmoid</th>\n",
       "      <th>activation_tanh</th>\n",
       "      <th>activation_nan</th>\n",
       "      <th>activation_selu</th>\n",
       "      <th>activation_elu</th>\n",
       "      <th>activation_softmax</th>\n",
       "      <th>activation_softplus</th>\n",
       "      <th>activation_softsign</th>\n",
       "      <th>activation_hard_sigmoid</th>\n",
       "      <th>activation_exponential</th>\n",
       "      <th>activation_linear</th>\n",
       "      <th>input_size</th>\n",
       "      <th>output_size</th>\n",
       "      <th>stride_size</th>\n",
       "      <th>mem_kb_actual</th>\n",
       "      <th>mem_kb_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>48.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>32000</td>\n",
       "      <td>48</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>25.184864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>16000</td>\n",
       "      <td>16000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>31.712296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>64.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>8000</td>\n",
       "      <td>16000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>32.448108</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   units  filters  kernel_size  activation_relu  activation_sigmoid  \\\n",
       "7   48.0     -1.0         -1.0                0                   0   \n",
       "1   -1.0     32.0          3.0                1                   0   \n",
       "5   64.0     -1.0         -1.0                0                   0   \n",
       "\n",
       "   activation_tanh  activation_nan  activation_selu  activation_elu  \\\n",
       "7                1               0             -1.0            -1.0   \n",
       "1                0               0             -1.0            -1.0   \n",
       "5                1               0             -1.0            -1.0   \n",
       "\n",
       "   activation_softmax  activation_softplus  activation_softsign  \\\n",
       "7                -1.0                 -1.0                 -1.0   \n",
       "1                -1.0                 -1.0                 -1.0   \n",
       "5                -1.0                 -1.0                 -1.0   \n",
       "\n",
       "   activation_hard_sigmoid  activation_exponential  activation_linear  \\\n",
       "7                     -1.0                    -1.0               -1.0   \n",
       "1                     -1.0                    -1.0               -1.0   \n",
       "5                     -1.0                    -1.0               -1.0   \n",
       "\n",
       "   input_size  output_size  stride_size  mem_kb_actual  mem_kb_pred  \n",
       "7       32000           48         -1.0           32.0    25.184864  \n",
       "1       16000        16000          1.0           64.0    31.712296  \n",
       "5        8000        16000         -1.0           32.0    32.448108  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf, X_test, y_test = rf_regression_model(cleaned_lstm, '[mem KB]')\n",
    "\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "print(\"MSE:\", mean_squared_error(y_test, y_pred))\n",
    "\n",
    "pd.concat([X_test, pd.DataFrame({'mem_kb_actual': y_test, 'mem_kb_pred': y_pred})], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brian/anaconda/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.32148484991487053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brian/anaconda/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/brian/anaconda/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/brian/anaconda/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/brian/anaconda/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/brian/anaconda/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>units</th>\n",
       "      <th>filters</th>\n",
       "      <th>kernel_size</th>\n",
       "      <th>activation_relu</th>\n",
       "      <th>activation_sigmoid</th>\n",
       "      <th>activation_tanh</th>\n",
       "      <th>activation_nan</th>\n",
       "      <th>activation_selu</th>\n",
       "      <th>activation_elu</th>\n",
       "      <th>activation_softmax</th>\n",
       "      <th>activation_softplus</th>\n",
       "      <th>activation_softsign</th>\n",
       "      <th>activation_hard_sigmoid</th>\n",
       "      <th>activation_exponential</th>\n",
       "      <th>activation_linear</th>\n",
       "      <th>input_size</th>\n",
       "      <th>output_size</th>\n",
       "      <th>stride_size</th>\n",
       "      <th>avg_ms_actual</th>\n",
       "      <th>avg_ms_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>16000</td>\n",
       "      <td>16000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.166</td>\n",
       "      <td>-0.343861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.850315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2500</td>\n",
       "      <td>8000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.941</td>\n",
       "      <td>0.947790</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   units  filters  kernel_size  activation_relu  activation_sigmoid  \\\n",
       "1   -1.0     32.0          3.0                1                   0   \n",
       "8    1.0     -1.0         -1.0                0                   1   \n",
       "4   32.0     -1.0         -1.0                0                   0   \n",
       "\n",
       "   activation_tanh  activation_nan  activation_selu  activation_elu  \\\n",
       "1                0               0             -1.0            -1.0   \n",
       "8                0               0             -1.0            -1.0   \n",
       "4                1               0             -1.0            -1.0   \n",
       "\n",
       "   activation_softmax  activation_softplus  activation_softsign  \\\n",
       "1                -1.0                 -1.0                 -1.0   \n",
       "8                -1.0                 -1.0                 -1.0   \n",
       "4                -1.0                 -1.0                 -1.0   \n",
       "\n",
       "   activation_hard_sigmoid  activation_exponential  activation_linear  \\\n",
       "1                     -1.0                    -1.0               -1.0   \n",
       "8                     -1.0                    -1.0               -1.0   \n",
       "4                     -1.0                    -1.0               -1.0   \n",
       "\n",
       "   input_size  output_size  stride_size  avg_ms_actual  avg_ms_pred  \n",
       "1       16000        16000          1.0          0.166    -0.343861  \n",
       "8          48            1         -1.0          0.011     0.850315  \n",
       "4        2500         8000         -1.0          0.941     0.947790  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lstm stacked avg ms\n",
    "rf, X_test, y_test = stacked_regression_model(cleaned_lstm, '[avg ms]')\n",
    "\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "print(\"MSE:\", mean_squared_error(y_test, y_pred))\n",
    "\n",
    "pd.concat([X_test, pd.DataFrame({'avg_ms_actual': y_test, 'avg_ms_pred': y_pred})], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brian/anaconda/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 1780.7031965625222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brian/anaconda/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/brian/anaconda/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/brian/anaconda/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/brian/anaconda/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>units</th>\n",
       "      <th>filters</th>\n",
       "      <th>kernel_size</th>\n",
       "      <th>activation_relu</th>\n",
       "      <th>activation_sigmoid</th>\n",
       "      <th>activation_tanh</th>\n",
       "      <th>activation_nan</th>\n",
       "      <th>activation_selu</th>\n",
       "      <th>activation_elu</th>\n",
       "      <th>activation_softmax</th>\n",
       "      <th>activation_softplus</th>\n",
       "      <th>activation_softsign</th>\n",
       "      <th>activation_hard_sigmoid</th>\n",
       "      <th>activation_exponential</th>\n",
       "      <th>activation_linear</th>\n",
       "      <th>input_size</th>\n",
       "      <th>output_size</th>\n",
       "      <th>stride_size</th>\n",
       "      <th>mem_kb_actual</th>\n",
       "      <th>mem_kb_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>48.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>32000</td>\n",
       "      <td>48</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>35.150173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>128.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>16000</td>\n",
       "      <td>32000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>104.931036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>8000</td>\n",
       "      <td>2500</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>28.359949</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   units  filters  kernel_size  activation_relu  activation_sigmoid  \\\n",
       "7   48.0     -1.0         -1.0                0                   0   \n",
       "6  128.0     -1.0         -1.0                0                   0   \n",
       "3   10.0     -1.0         -1.0                0                   0   \n",
       "\n",
       "   activation_tanh  activation_nan  activation_selu  activation_elu  \\\n",
       "7                1               0             -1.0            -1.0   \n",
       "6                1               0             -1.0            -1.0   \n",
       "3                1               0             -1.0            -1.0   \n",
       "\n",
       "   activation_softmax  activation_softplus  activation_softsign  \\\n",
       "7                -1.0                 -1.0                 -1.0   \n",
       "6                -1.0                 -1.0                 -1.0   \n",
       "3                -1.0                 -1.0                 -1.0   \n",
       "\n",
       "   activation_hard_sigmoid  activation_exponential  activation_linear  \\\n",
       "7                     -1.0                    -1.0               -1.0   \n",
       "6                     -1.0                    -1.0               -1.0   \n",
       "3                     -1.0                    -1.0               -1.0   \n",
       "\n",
       "   input_size  output_size  stride_size  mem_kb_actual  mem_kb_pred  \n",
       "7       32000           48         -1.0           32.0    35.150173  \n",
       "6       16000        32000         -1.0           32.0   104.931036  \n",
       "3        8000         2500         -1.0           32.0    28.359949  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lstm stacked mem\n",
    "rf, X_test, y_test = stacked_regression_model(cleaned_lstm, '[mem KB]')\n",
    "\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "print(\"MSE:\", mean_squared_error(y_test, y_pred))\n",
    "\n",
    "pd.concat([X_test, pd.DataFrame({'mem_kb_actual': y_test, 'mem_kb_pred': y_pred})], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brian/anaconda/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 1.6067859381992454e+16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brian/anaconda/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/brian/anaconda/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/brian/anaconda/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/brian/anaconda/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/brian/anaconda/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>units</th>\n",
       "      <th>filters</th>\n",
       "      <th>kernel_size</th>\n",
       "      <th>activation_relu</th>\n",
       "      <th>activation_sigmoid</th>\n",
       "      <th>activation_tanh</th>\n",
       "      <th>activation_nan</th>\n",
       "      <th>activation_selu</th>\n",
       "      <th>activation_elu</th>\n",
       "      <th>activation_softmax</th>\n",
       "      <th>activation_softplus</th>\n",
       "      <th>activation_softsign</th>\n",
       "      <th>activation_hard_sigmoid</th>\n",
       "      <th>activation_exponential</th>\n",
       "      <th>activation_linear</th>\n",
       "      <th>input_size</th>\n",
       "      <th>output_size</th>\n",
       "      <th>stride_size</th>\n",
       "      <th>avg_ms_actual</th>\n",
       "      <th>avg_ms_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>64.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>8000</td>\n",
       "      <td>16000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.940</td>\n",
       "      <td>-1.267589e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>8000</td>\n",
       "      <td>2500</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.952</td>\n",
       "      <td>-1.267531e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2500</td>\n",
       "      <td>8000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.941</td>\n",
       "      <td>-1.267652e+08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   units  filters  kernel_size  activation_relu  activation_sigmoid  \\\n",
       "5   64.0     -1.0         -1.0                0                   0   \n",
       "3   10.0     -1.0         -1.0                0                   0   \n",
       "4   32.0     -1.0         -1.0                0                   0   \n",
       "\n",
       "   activation_tanh  activation_nan  activation_selu  activation_elu  \\\n",
       "5                1               0             -1.0            -1.0   \n",
       "3                1               0             -1.0            -1.0   \n",
       "4                1               0             -1.0            -1.0   \n",
       "\n",
       "   activation_softmax  activation_softplus  activation_softsign  \\\n",
       "5                -1.0                 -1.0                 -1.0   \n",
       "3                -1.0                 -1.0                 -1.0   \n",
       "4                -1.0                 -1.0                 -1.0   \n",
       "\n",
       "   activation_hard_sigmoid  activation_exponential  activation_linear  \\\n",
       "5                     -1.0                    -1.0               -1.0   \n",
       "3                     -1.0                    -1.0               -1.0   \n",
       "4                     -1.0                    -1.0               -1.0   \n",
       "\n",
       "   input_size  output_size  stride_size  avg_ms_actual   avg_ms_pred  \n",
       "5        8000        16000         -1.0          0.940 -1.267589e+08  \n",
       "3        8000         2500         -1.0          0.952 -1.267531e+08  \n",
       "4        2500         8000         -1.0          0.941 -1.267652e+08  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lstm stacked avg ms\n",
    "rf, X_test, y_test = stacked_regression_model_2(cleaned_lstm, '[avg ms]')\n",
    "\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "print(\"MSE:\", mean_squared_error(y_test, y_pred))\n",
    "\n",
    "pd.concat([X_test, pd.DataFrame({'avg_ms_actual': y_test, 'avg_ms_pred': y_pred})], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brian/anaconda/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/brian/anaconda/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/brian/anaconda/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/brian/anaconda/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/brian/anaconda/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/brian/anaconda/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 23843351824817.754\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>units</th>\n",
       "      <th>filters</th>\n",
       "      <th>kernel_size</th>\n",
       "      <th>activation_relu</th>\n",
       "      <th>activation_sigmoid</th>\n",
       "      <th>activation_tanh</th>\n",
       "      <th>activation_nan</th>\n",
       "      <th>activation_selu</th>\n",
       "      <th>activation_elu</th>\n",
       "      <th>activation_softmax</th>\n",
       "      <th>activation_softplus</th>\n",
       "      <th>activation_softsign</th>\n",
       "      <th>activation_hard_sigmoid</th>\n",
       "      <th>activation_exponential</th>\n",
       "      <th>activation_linear</th>\n",
       "      <th>input_size</th>\n",
       "      <th>output_size</th>\n",
       "      <th>stride_size</th>\n",
       "      <th>mem_kb_actual</th>\n",
       "      <th>mem_kb_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2500</td>\n",
       "      <td>8000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>4.903031e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>16000</td>\n",
       "      <td>16000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>4.843128e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>64.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>8000</td>\n",
       "      <td>16000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>4.902622e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   units  filters  kernel_size  activation_relu  activation_sigmoid  \\\n",
       "4   32.0     -1.0         -1.0                0                   0   \n",
       "1   -1.0     32.0          3.0                1                   0   \n",
       "5   64.0     -1.0         -1.0                0                   0   \n",
       "\n",
       "   activation_tanh  activation_nan  activation_selu  activation_elu  \\\n",
       "4                1               0             -1.0            -1.0   \n",
       "1                0               0             -1.0            -1.0   \n",
       "5                1               0             -1.0            -1.0   \n",
       "\n",
       "   activation_softmax  activation_softplus  activation_softsign  \\\n",
       "4                -1.0                 -1.0                 -1.0   \n",
       "1                -1.0                 -1.0                 -1.0   \n",
       "5                -1.0                 -1.0                 -1.0   \n",
       "\n",
       "   activation_hard_sigmoid  activation_exponential  activation_linear  \\\n",
       "4                     -1.0                    -1.0               -1.0   \n",
       "1                     -1.0                    -1.0               -1.0   \n",
       "5                     -1.0                    -1.0               -1.0   \n",
       "\n",
       "   input_size  output_size  stride_size  mem_kb_actual   mem_kb_pred  \n",
       "4        2500         8000         -1.0           32.0  4.903031e+06  \n",
       "1       16000        16000          1.0           64.0  4.843128e+06  \n",
       "5        8000        16000         -1.0           32.0  4.902622e+06  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lstm stacked mem\n",
    "rf, X_test, y_test = stacked_regression_model_2(cleaned_lstm, '[mem KB]')\n",
    "\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "print(\"MSE:\", mean_squared_error(y_test, y_pred))\n",
    "\n",
    "pd.concat([X_test, pd.DataFrame({'mem_kb_actual': y_test, 'mem_kb_pred': y_pred})], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving saved model and benchmark results.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>[node type]</th>\n",
       "      <th>[start]</th>\n",
       "      <th>[first]</th>\n",
       "      <th>[avg ms]</th>\n",
       "      <th>[%]</th>\n",
       "      <th>[cdf%]</th>\n",
       "      <th>[mem KB]</th>\n",
       "      <th>[times called]</th>\n",
       "      <th>[Name]</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Const</td>\n",
       "      <td>-0.108</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.377%</td>\n",
       "      <td>2.587%</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1</td>\n",
       "      <td>lstm1/strided_slice/stack</td>\n",
       "      <td>lstm1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Const</td>\n",
       "      <td>0.052</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.556%</td>\n",
       "      <td>35.641%</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1</td>\n",
       "      <td>ConstantFolding/lstm1/while/split-folded-0</td>\n",
       "      <td>ConstantFolding</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>Enter</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.757%</td>\n",
       "      <td>67.111%</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1</td>\n",
       "      <td>lstm1/while/TensorArrayReadV3/Enter_1</td>\n",
       "      <td>lstm1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Enter</td>\n",
       "      <td>-0.083</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.415%</td>\n",
       "      <td>6.624%</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1</td>\n",
       "      <td>lstm1/while/Enter</td>\n",
       "      <td>lstm1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>MatMul</td>\n",
       "      <td>0.041</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.012</td>\n",
       "      <td>2.926%</td>\n",
       "      <td>81.040%</td>\n",
       "      <td>1.024</td>\n",
       "      <td>1</td>\n",
       "      <td>lstm1/while/MatMul_3</td>\n",
       "      <td>lstm1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 [node type]  [start]  [first]  [avg ms]       [%]    [cdf%]  \\\n",
       "5                      Const   -0.108    0.002     0.002    0.377%    2.587%   \n",
       "47                     Const    0.052    0.003     0.002    0.556%   35.641%   \n",
       "59                     Enter    0.007    0.009     0.003    0.757%   67.111%   \n",
       "14                     Enter   -0.083    0.002     0.002    0.415%    6.624%   \n",
       "66                    MatMul    0.041    0.016     0.012    2.926%   81.040%   \n",
       "\n",
       "    [mem KB]  [times called]                                      [Name]  \\\n",
       "5      0.000               1                   lstm1/strided_slice/stack   \n",
       "47     0.000               1  ConstantFolding/lstm1/while/split-folded-0   \n",
       "59     0.000               1       lstm1/while/TensorArrayReadV3/Enter_1   \n",
       "14     0.000               1                           lstm1/while/Enter   \n",
       "66     1.024               1                        lstm1/while/MatMul_3   \n",
       "\n",
       "               name  \n",
       "5             lstm1  \n",
       "47  ConstantFolding  \n",
       "59            lstm1  \n",
       "14            lstm1  \n",
       "66            lstm1  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lstm.summary()\n",
    "\n",
    "tf.keras.backend.clear_session() # IMPORTANT for layer names to match up.\n",
    "\n",
    "enc, dec = create_seq2seq()\n",
    "\n",
    "# tf.keras.backend.set_learning_phase(0)\n",
    "enc_benchmark = benchmark_model(enc, '../tensorflow/bazel-bin/tensorflow/tools/benchmark/benchmark_model --graph=encoder.pbtxt --input_layer=\"input_1:0\" --input_layer_shape=\"1,1,71\" --output_layer=\"lstm1/while/Exit_2:0\"')\n",
    "enc_benchmark.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving saved model and benchmark results.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>[node type]</th>\n",
       "      <th>[start]</th>\n",
       "      <th>[first]</th>\n",
       "      <th>[avg ms]</th>\n",
       "      <th>[%]</th>\n",
       "      <th>[cdf%]</th>\n",
       "      <th>[mem KB]</th>\n",
       "      <th>[times called]</th>\n",
       "      <th>[Name]</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>Minimum</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.612%</td>\n",
       "      <td>82.161%</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>lstm2_1/while/clip_by_value_1/Minimum</td>\n",
       "      <td>lstm2_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Const</td>\n",
       "      <td>-0.121</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.555%</td>\n",
       "      <td>0.943%</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>lstm2/kernel</td>\n",
       "      <td>lstm2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Const</td>\n",
       "      <td>-0.101</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.247%</td>\n",
       "      <td>2.685%</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>lstm2_1/TensorArrayUnstack/strided_slice/stack_1</td>\n",
       "      <td>lstm2_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>Prod</td>\n",
       "      <td>0.271</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.358%</td>\n",
       "      <td>98.355%</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>dense1_1/Tensordot/Prod_1</td>\n",
       "      <td>dense1_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Const</td>\n",
       "      <td>0.044</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.411%</td>\n",
       "      <td>27.194%</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>lstm2_1/while/strided_slice_1</td>\n",
       "      <td>lstm2_1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  [node type]  [start]  [first]  [avg ms]       [%]    [cdf%]  \\\n",
       "91                    Minimum    0.130    0.010     0.004    0.612%   82.161%   \n",
       "1                       Const   -0.121    0.009     0.004    0.555%    0.943%   \n",
       "8                       Const   -0.101    0.002     0.002    0.247%    2.685%   \n",
       "118                      Prod    0.271    0.002     0.002    0.358%   98.355%   \n",
       "49                      Const    0.044    0.003     0.003    0.411%   27.194%   \n",
       "\n",
       "     [mem KB]  [times called]  \\\n",
       "91        0.0               1   \n",
       "1         0.0               1   \n",
       "8         0.0               1   \n",
       "118       0.0               1   \n",
       "49        0.0               1   \n",
       "\n",
       "                                               [Name]      name  \n",
       "91              lstm2_1/while/clip_by_value_1/Minimum   lstm2_1  \n",
       "1                                        lstm2/kernel     lstm2  \n",
       "8    lstm2_1/TensorArrayUnstack/strided_slice/stack_1   lstm2_1  \n",
       "118                         dense1_1/Tensordot/Prod_1  dense1_1  \n",
       "49                      lstm2_1/while/strided_slice_1   lstm2_1  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dec_benchmark = benchmark_model(dec, '../tensorflow/bazel-bin/tensorflow/tools/benchmark/benchmark_model --graph=decoder.pbtxt --input_layer=\"input_2:0,input_3:0,input_4:0\" --input_layer_shape=\"1,1,93:1,256:1,256\" --input_layer_type=float,float,float --output_layer=\"dense1_1/truediv:0\"')\n",
    "dec_benchmark.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seq2seq_benchmark = pd.concat([enc_benchmark, dec_benchmark])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "enc_features = get_layer_features(enc)\n",
    "dec_features = get_layer_features(dec)\n",
    "seq2seq_features = pd.concat([enc_features, dec_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seq2seq_df = join_benchmark(seq2seq_features, seq2seq_benchmark)\n",
    "cleaned_seq2seq = clean(seq2seq_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brian/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:1: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>[avg ms]</th>\n",
       "      <th>[mem KB]</th>\n",
       "      <th>activation_elu</th>\n",
       "      <th>activation_exponential</th>\n",
       "      <th>activation_hard_sigmoid</th>\n",
       "      <th>activation_linear</th>\n",
       "      <th>activation_nan</th>\n",
       "      <th>activation_relu</th>\n",
       "      <th>activation_selu</th>\n",
       "      <th>activation_sigmoid</th>\n",
       "      <th>...</th>\n",
       "      <th>filters</th>\n",
       "      <th>input_shape</th>\n",
       "      <th>input_size</th>\n",
       "      <th>kernel_size</th>\n",
       "      <th>name</th>\n",
       "      <th>output_shape</th>\n",
       "      <th>output_size</th>\n",
       "      <th>stride_size</th>\n",
       "      <th>strides</th>\n",
       "      <th>units</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.166</td>\n",
       "      <td>64.000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>32.0</td>\n",
       "      <td>(None, 500, 32)</td>\n",
       "      <td>16000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>conv1d</td>\n",
       "      <td>(None, 500, 32)</td>\n",
       "      <td>16000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>(1,)</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.011</td>\n",
       "      <td>0.004</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>(None, 48)</td>\n",
       "      <td>48</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>dense</td>\n",
       "      <td>(None, 1)</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.033</td>\n",
       "      <td>64.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>(None, 500)</td>\n",
       "      <td>500</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>embedding</td>\n",
       "      <td>(None, 500, 32)</td>\n",
       "      <td>16000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.039</td>\n",
       "      <td>32.000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>(None, 500, 32)</td>\n",
       "      <td>16000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>max_pooling1d</td>\n",
       "      <td>(None, 250, 32)</td>\n",
       "      <td>8000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>(2,)</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.941</td>\n",
       "      <td>32.000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>(None, 250, 10)</td>\n",
       "      <td>2500</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>lstm2</td>\n",
       "      <td>(None, 250, 32)</td>\n",
       "      <td>8000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.965</td>\n",
       "      <td>32.000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>(None, 250, 64)</td>\n",
       "      <td>16000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>lstm4</td>\n",
       "      <td>(None, 250, 128)</td>\n",
       "      <td>32000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>128.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.952</td>\n",
       "      <td>32.000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>(None, 250, 32)</td>\n",
       "      <td>8000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>lstm1</td>\n",
       "      <td>(None, 250, 10)</td>\n",
       "      <td>2500</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.940</td>\n",
       "      <td>32.000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>(None, 250, 32)</td>\n",
       "      <td>8000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>lstm3</td>\n",
       "      <td>(None, 250, 64)</td>\n",
       "      <td>16000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>64.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.941</td>\n",
       "      <td>32.000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>(None, 250, 128)</td>\n",
       "      <td>32000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>lstm5</td>\n",
       "      <td>(None, 48)</td>\n",
       "      <td>48</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>48.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.382</td>\n",
       "      <td>1.024</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>(None, None, 71)</td>\n",
       "      <td>71</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>lstm1</td>\n",
       "      <td>[(None, 256), (None, 256), (None, 256)]</td>\n",
       "      <td>768</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>256.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   [avg ms]  [mem KB]  activation_elu  activation_exponential  \\\n",
       "1     0.166    64.000            -1.0                    -1.0   \n",
       "8     0.011     0.004            -1.0                    -1.0   \n",
       "0     0.033    64.000             0.0                     0.0   \n",
       "2     0.039    32.000            -1.0                    -1.0   \n",
       "4     0.941    32.000            -1.0                    -1.0   \n",
       "6     0.965    32.000            -1.0                    -1.0   \n",
       "3     0.952    32.000            -1.0                    -1.0   \n",
       "5     0.940    32.000            -1.0                    -1.0   \n",
       "7     0.941    32.000            -1.0                    -1.0   \n",
       "1     0.382     1.024            -1.0                    -1.0   \n",
       "\n",
       "   activation_hard_sigmoid  activation_linear  activation_nan  \\\n",
       "1                     -1.0               -1.0               0   \n",
       "8                     -1.0               -1.0               0   \n",
       "0                      0.0                0.0               1   \n",
       "2                     -1.0               -1.0               1   \n",
       "4                     -1.0               -1.0               0   \n",
       "6                     -1.0               -1.0               0   \n",
       "3                     -1.0               -1.0               0   \n",
       "5                     -1.0               -1.0               0   \n",
       "7                     -1.0               -1.0               0   \n",
       "1                     -1.0               -1.0               0   \n",
       "\n",
       "   activation_relu  activation_selu  activation_sigmoid  ...  filters  \\\n",
       "1              1.0             -1.0                 0.0  ...     32.0   \n",
       "8              0.0             -1.0                 1.0  ...     -1.0   \n",
       "0              0.0              0.0                 0.0  ...     -1.0   \n",
       "2              0.0             -1.0                 0.0  ...     -1.0   \n",
       "4              0.0             -1.0                 0.0  ...     -1.0   \n",
       "6              0.0             -1.0                 0.0  ...     -1.0   \n",
       "3              0.0             -1.0                 0.0  ...     -1.0   \n",
       "5              0.0             -1.0                 0.0  ...     -1.0   \n",
       "7              0.0             -1.0                 0.0  ...     -1.0   \n",
       "1             -1.0             -1.0                -1.0  ...     -1.0   \n",
       "\n",
       "        input_shape  input_size  kernel_size           name  \\\n",
       "1   (None, 500, 32)       16000          3.0         conv1d   \n",
       "8        (None, 48)          48         -1.0          dense   \n",
       "0       (None, 500)         500         -1.0      embedding   \n",
       "2   (None, 500, 32)       16000         -1.0  max_pooling1d   \n",
       "4   (None, 250, 10)        2500         -1.0          lstm2   \n",
       "6   (None, 250, 64)       16000         -1.0          lstm4   \n",
       "3   (None, 250, 32)        8000         -1.0          lstm1   \n",
       "5   (None, 250, 32)        8000         -1.0          lstm3   \n",
       "7  (None, 250, 128)       32000         -1.0          lstm5   \n",
       "1  (None, None, 71)          71         -1.0          lstm1   \n",
       "\n",
       "                              output_shape  output_size  stride_size strides  \\\n",
       "1                          (None, 500, 32)        16000          1.0    (1,)   \n",
       "8                                (None, 1)            1         -1.0      -1   \n",
       "0                          (None, 500, 32)        16000         -1.0      -1   \n",
       "2                          (None, 250, 32)         8000          2.0    (2,)   \n",
       "4                          (None, 250, 32)         8000         -1.0      -1   \n",
       "6                         (None, 250, 128)        32000         -1.0      -1   \n",
       "3                          (None, 250, 10)         2500         -1.0      -1   \n",
       "5                          (None, 250, 64)        16000         -1.0      -1   \n",
       "7                               (None, 48)           48         -1.0      -1   \n",
       "1  [(None, 256), (None, 256), (None, 256)]          768         -1.0      -1   \n",
       "\n",
       "   units  \n",
       "1   -1.0  \n",
       "8    1.0  \n",
       "0   -1.0  \n",
       "2   -1.0  \n",
       "4   32.0  \n",
       "6  128.0  \n",
       "3   10.0  \n",
       "5   64.0  \n",
       "7   48.0  \n",
       "1  256.0  \n",
       "\n",
       "[10 rows x 24 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_rnn = pd.concat([cleaned_lstm, cleaned_seq2seq]).fillna(0)\n",
    "cleaned_rnn.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.2941177649690035\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>activation_elu</th>\n",
       "      <th>activation_exponential</th>\n",
       "      <th>activation_hard_sigmoid</th>\n",
       "      <th>activation_linear</th>\n",
       "      <th>activation_nan</th>\n",
       "      <th>activation_relu</th>\n",
       "      <th>activation_selu</th>\n",
       "      <th>activation_sigmoid</th>\n",
       "      <th>activation_softmax</th>\n",
       "      <th>activation_softplus</th>\n",
       "      <th>activation_softsign</th>\n",
       "      <th>activation_tanh</th>\n",
       "      <th>filters</th>\n",
       "      <th>input_size</th>\n",
       "      <th>kernel_size</th>\n",
       "      <th>output_size</th>\n",
       "      <th>stride_size</th>\n",
       "      <th>units</th>\n",
       "      <th>avg_ms_actual</th>\n",
       "      <th>avg_ms_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>8000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>16000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.940</td>\n",
       "      <td>0.919003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>500</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>16000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.256547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>71</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>768</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>256.0</td>\n",
       "      <td>0.382</td>\n",
       "      <td>0.921677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>605</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>768</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>256.0</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.921677</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   activation_elu  activation_exponential  activation_hard_sigmoid  \\\n",
       "5            -1.0                    -1.0                     -1.0   \n",
       "0             0.0                     0.0                      0.0   \n",
       "1            -1.0                    -1.0                     -1.0   \n",
       "3            -1.0                    -1.0                     -1.0   \n",
       "\n",
       "   activation_linear  activation_nan  activation_relu  activation_selu  \\\n",
       "5               -1.0               0              0.0             -1.0   \n",
       "0                0.0               1              0.0              0.0   \n",
       "1               -1.0               0             -1.0             -1.0   \n",
       "3               -1.0               0             -1.0             -1.0   \n",
       "\n",
       "   activation_sigmoid  activation_softmax  activation_softplus  \\\n",
       "5                 0.0                -1.0                 -1.0   \n",
       "0                 0.0                 0.0                  0.0   \n",
       "1                -1.0                -1.0                 -1.0   \n",
       "3                -1.0                -1.0                 -1.0   \n",
       "\n",
       "   activation_softsign  activation_tanh  filters  input_size  kernel_size  \\\n",
       "5                 -1.0                1     -1.0        8000         -1.0   \n",
       "0                  0.0                0     -1.0         500         -1.0   \n",
       "1                 -1.0                1     -1.0          71         -1.0   \n",
       "3                 -1.0                1     -1.0         605         -1.0   \n",
       "\n",
       "   output_size  stride_size  units  avg_ms_actual  avg_ms_pred  \n",
       "5        16000         -1.0   64.0          0.940     0.919003  \n",
       "0        16000         -1.0   -1.0          0.033     0.256547  \n",
       "1          768         -1.0  256.0          0.382     0.921677  \n",
       "3          768         -1.0  256.0          0.008     0.921677  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn_ms_rf, X_test, y_test = rf_regression_model(cleaned_rnn, '[avg ms]')\n",
    "rnn_data = cleaned_rnn\n",
    "\n",
    "y_pred = rnn_ms_rf.predict(X_test)\n",
    "\n",
    "print(\"MSE:\", mean_squared_error(y_test, y_pred))\n",
    "rnn_ms_rf_mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "pd.concat([X_test, pd.DataFrame({'avg_ms_actual': y_test, 'avg_ms_pred': y_pred})], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 585.0930507439566\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>activation_elu</th>\n",
       "      <th>activation_exponential</th>\n",
       "      <th>activation_hard_sigmoid</th>\n",
       "      <th>activation_linear</th>\n",
       "      <th>activation_nan</th>\n",
       "      <th>activation_relu</th>\n",
       "      <th>activation_selu</th>\n",
       "      <th>activation_sigmoid</th>\n",
       "      <th>activation_softmax</th>\n",
       "      <th>activation_softplus</th>\n",
       "      <th>activation_softsign</th>\n",
       "      <th>activation_tanh</th>\n",
       "      <th>filters</th>\n",
       "      <th>input_size</th>\n",
       "      <th>kernel_size</th>\n",
       "      <th>output_size</th>\n",
       "      <th>stride_size</th>\n",
       "      <th>units</th>\n",
       "      <th>mem_kb_actual</th>\n",
       "      <th>mem_kb_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>8000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>16000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>32.000</td>\n",
       "      <td>32.992120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>500</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>16000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>64.000</td>\n",
       "      <td>27.936956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>71</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>768</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>256.0</td>\n",
       "      <td>1.024</td>\n",
       "      <td>23.297088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>605</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>768</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>256.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>23.297088</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   activation_elu  activation_exponential  activation_hard_sigmoid  \\\n",
       "5            -1.0                    -1.0                     -1.0   \n",
       "0             0.0                     0.0                      0.0   \n",
       "1            -1.0                    -1.0                     -1.0   \n",
       "3            -1.0                    -1.0                     -1.0   \n",
       "\n",
       "   activation_linear  activation_nan  activation_relu  activation_selu  \\\n",
       "5               -1.0               0              0.0             -1.0   \n",
       "0                0.0               1              0.0              0.0   \n",
       "1               -1.0               0             -1.0             -1.0   \n",
       "3               -1.0               0             -1.0             -1.0   \n",
       "\n",
       "   activation_sigmoid  activation_softmax  activation_softplus  \\\n",
       "5                 0.0                -1.0                 -1.0   \n",
       "0                 0.0                 0.0                  0.0   \n",
       "1                -1.0                -1.0                 -1.0   \n",
       "3                -1.0                -1.0                 -1.0   \n",
       "\n",
       "   activation_softsign  activation_tanh  filters  input_size  kernel_size  \\\n",
       "5                 -1.0                1     -1.0        8000         -1.0   \n",
       "0                  0.0                0     -1.0         500         -1.0   \n",
       "1                 -1.0                1     -1.0          71         -1.0   \n",
       "3                 -1.0                1     -1.0         605         -1.0   \n",
       "\n",
       "   output_size  stride_size  units  mem_kb_actual  mem_kb_pred  \n",
       "5        16000         -1.0   64.0         32.000    32.992120  \n",
       "0        16000         -1.0   -1.0         64.000    27.936956  \n",
       "1          768         -1.0  256.0          1.024    23.297088  \n",
       "3          768         -1.0  256.0          0.000    23.297088  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn_mem_rf, X_test, y_test = rf_regression_model(cleaned_rnn, '[mem KB]')\n",
    "\n",
    "y_pred = rnn_mem_rf.predict(X_test)\n",
    "\n",
    "print(\"MSE:\", mean_squared_error(y_test, y_pred))\n",
    "rnn_mem_rf_mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "pd.concat([X_test, pd.DataFrame({'mem_kb_actual': y_test, 'mem_kb_pred': y_pred})], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brian/anaconda/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.3017690844111648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brian/anaconda/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/brian/anaconda/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/brian/anaconda/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/brian/anaconda/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/brian/anaconda/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>activation_elu</th>\n",
       "      <th>activation_exponential</th>\n",
       "      <th>activation_hard_sigmoid</th>\n",
       "      <th>activation_linear</th>\n",
       "      <th>activation_nan</th>\n",
       "      <th>activation_relu</th>\n",
       "      <th>activation_selu</th>\n",
       "      <th>activation_sigmoid</th>\n",
       "      <th>activation_softmax</th>\n",
       "      <th>activation_softplus</th>\n",
       "      <th>activation_softsign</th>\n",
       "      <th>activation_tanh</th>\n",
       "      <th>filters</th>\n",
       "      <th>input_size</th>\n",
       "      <th>kernel_size</th>\n",
       "      <th>output_size</th>\n",
       "      <th>stride_size</th>\n",
       "      <th>units</th>\n",
       "      <th>avg_ms_actual</th>\n",
       "      <th>avg_ms_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>16000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>32000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>0.965</td>\n",
       "      <td>0.237778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>32000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>48</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0.941</td>\n",
       "      <td>0.394734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>8000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>16000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.940</td>\n",
       "      <td>0.324446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>71</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>768</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>256.0</td>\n",
       "      <td>0.382</td>\n",
       "      <td>0.412191</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   activation_elu  activation_exponential  activation_hard_sigmoid  \\\n",
       "6            -1.0                    -1.0                     -1.0   \n",
       "7            -1.0                    -1.0                     -1.0   \n",
       "5            -1.0                    -1.0                     -1.0   \n",
       "1            -1.0                    -1.0                     -1.0   \n",
       "\n",
       "   activation_linear  activation_nan  activation_relu  activation_selu  \\\n",
       "6               -1.0               0              0.0             -1.0   \n",
       "7               -1.0               0              0.0             -1.0   \n",
       "5               -1.0               0              0.0             -1.0   \n",
       "1               -1.0               0             -1.0             -1.0   \n",
       "\n",
       "   activation_sigmoid  activation_softmax  activation_softplus  \\\n",
       "6                 0.0                -1.0                 -1.0   \n",
       "7                 0.0                -1.0                 -1.0   \n",
       "5                 0.0                -1.0                 -1.0   \n",
       "1                -1.0                -1.0                 -1.0   \n",
       "\n",
       "   activation_softsign  activation_tanh  filters  input_size  kernel_size  \\\n",
       "6                 -1.0                1     -1.0       16000         -1.0   \n",
       "7                 -1.0                1     -1.0       32000         -1.0   \n",
       "5                 -1.0                1     -1.0        8000         -1.0   \n",
       "1                 -1.0                1     -1.0          71         -1.0   \n",
       "\n",
       "   output_size  stride_size  units  avg_ms_actual  avg_ms_pred  \n",
       "6        32000         -1.0  128.0          0.965     0.237778  \n",
       "7           48         -1.0   48.0          0.941     0.394734  \n",
       "5        16000         -1.0   64.0          0.940     0.324446  \n",
       "1          768         -1.0  256.0          0.382     0.412191  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn_ms_stacked_1, X_test, y_test = stacked_regression_model(cleaned_rnn, '[avg ms]')\n",
    "\n",
    "y_pred = rnn_ms_stacked_1.predict(X_test)\n",
    "\n",
    "print(\"MSE:\", mean_squared_error(y_test, y_pred))\n",
    "rnn_ms_stacked_1_mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "pd.concat([X_test, pd.DataFrame({'avg_ms_actual': y_test, 'avg_ms_pred': y_pred})], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brian/anaconda/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 610.3908272774386\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brian/anaconda/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/brian/anaconda/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/brian/anaconda/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/brian/anaconda/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/brian/anaconda/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>activation_elu</th>\n",
       "      <th>activation_exponential</th>\n",
       "      <th>activation_hard_sigmoid</th>\n",
       "      <th>activation_linear</th>\n",
       "      <th>activation_nan</th>\n",
       "      <th>activation_relu</th>\n",
       "      <th>activation_selu</th>\n",
       "      <th>activation_sigmoid</th>\n",
       "      <th>activation_softmax</th>\n",
       "      <th>activation_softplus</th>\n",
       "      <th>activation_softsign</th>\n",
       "      <th>activation_tanh</th>\n",
       "      <th>filters</th>\n",
       "      <th>input_size</th>\n",
       "      <th>kernel_size</th>\n",
       "      <th>output_size</th>\n",
       "      <th>stride_size</th>\n",
       "      <th>units</th>\n",
       "      <th>mem_kb_actual</th>\n",
       "      <th>mem_kb_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>16000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>16000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>64.000</td>\n",
       "      <td>36.045711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>32000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>48</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>32.000</td>\n",
       "      <td>27.091656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>71</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>768</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>256.0</td>\n",
       "      <td>1.024</td>\n",
       "      <td>7.303139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>500</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>16000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>64.000</td>\n",
       "      <td>24.042503</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   activation_elu  activation_exponential  activation_hard_sigmoid  \\\n",
       "1            -1.0                    -1.0                     -1.0   \n",
       "7            -1.0                    -1.0                     -1.0   \n",
       "1            -1.0                    -1.0                     -1.0   \n",
       "0             0.0                     0.0                      0.0   \n",
       "\n",
       "   activation_linear  activation_nan  activation_relu  activation_selu  \\\n",
       "1               -1.0               0              1.0             -1.0   \n",
       "7               -1.0               0              0.0             -1.0   \n",
       "1               -1.0               0             -1.0             -1.0   \n",
       "0                0.0               1              0.0              0.0   \n",
       "\n",
       "   activation_sigmoid  activation_softmax  activation_softplus  \\\n",
       "1                 0.0                -1.0                 -1.0   \n",
       "7                 0.0                -1.0                 -1.0   \n",
       "1                -1.0                -1.0                 -1.0   \n",
       "0                 0.0                 0.0                  0.0   \n",
       "\n",
       "   activation_softsign  activation_tanh  filters  input_size  kernel_size  \\\n",
       "1                 -1.0                0     32.0       16000          3.0   \n",
       "7                 -1.0                1     -1.0       32000         -1.0   \n",
       "1                 -1.0                1     -1.0          71         -1.0   \n",
       "0                  0.0                0     -1.0         500         -1.0   \n",
       "\n",
       "   output_size  stride_size  units  mem_kb_actual  mem_kb_pred  \n",
       "1        16000          1.0   -1.0         64.000    36.045711  \n",
       "7           48         -1.0   48.0         32.000    27.091656  \n",
       "1          768         -1.0  256.0          1.024     7.303139  \n",
       "0        16000         -1.0   -1.0         64.000    24.042503  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn_mem_stacked_1, X_test, y_test = stacked_regression_model(cleaned_rnn, '[mem KB]')\n",
    "\n",
    "y_pred = rnn_mem_stacked_1.predict(X_test)\n",
    "\n",
    "print(\"MSE:\", mean_squared_error(y_test, y_pred))\n",
    "rnn_mem_stacked_1_mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "pd.concat([X_test, pd.DataFrame({'mem_kb_actual': y_test, 'mem_kb_pred': y_pred})], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brian/anaconda/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.2947922495872289\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brian/anaconda/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/brian/anaconda/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/brian/anaconda/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/brian/anaconda/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/brian/anaconda/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>activation_elu</th>\n",
       "      <th>activation_exponential</th>\n",
       "      <th>activation_hard_sigmoid</th>\n",
       "      <th>activation_linear</th>\n",
       "      <th>activation_nan</th>\n",
       "      <th>activation_relu</th>\n",
       "      <th>activation_selu</th>\n",
       "      <th>activation_sigmoid</th>\n",
       "      <th>activation_softmax</th>\n",
       "      <th>activation_softplus</th>\n",
       "      <th>activation_softsign</th>\n",
       "      <th>activation_tanh</th>\n",
       "      <th>filters</th>\n",
       "      <th>input_size</th>\n",
       "      <th>kernel_size</th>\n",
       "      <th>output_size</th>\n",
       "      <th>stride_size</th>\n",
       "      <th>units</th>\n",
       "      <th>avg_ms_actual</th>\n",
       "      <th>avg_ms_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2500</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>8000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.941</td>\n",
       "      <td>0.598679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>605</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>768</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>256.0</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.631385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>16000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>8000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.610192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>48</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.600166</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   activation_elu  activation_exponential  activation_hard_sigmoid  \\\n",
       "4            -1.0                    -1.0                     -1.0   \n",
       "3            -1.0                    -1.0                     -1.0   \n",
       "2            -1.0                    -1.0                     -1.0   \n",
       "8            -1.0                    -1.0                     -1.0   \n",
       "\n",
       "   activation_linear  activation_nan  activation_relu  activation_selu  \\\n",
       "4               -1.0               0              0.0             -1.0   \n",
       "3               -1.0               0             -1.0             -1.0   \n",
       "2               -1.0               1              0.0             -1.0   \n",
       "8               -1.0               0              0.0             -1.0   \n",
       "\n",
       "   activation_sigmoid  activation_softmax  activation_softplus  \\\n",
       "4                 0.0                -1.0                 -1.0   \n",
       "3                -1.0                -1.0                 -1.0   \n",
       "2                 0.0                -1.0                 -1.0   \n",
       "8                 1.0                -1.0                 -1.0   \n",
       "\n",
       "   activation_softsign  activation_tanh  filters  input_size  kernel_size  \\\n",
       "4                 -1.0                1     -1.0        2500         -1.0   \n",
       "3                 -1.0                1     -1.0         605         -1.0   \n",
       "2                 -1.0                0     -1.0       16000         -1.0   \n",
       "8                 -1.0                0     -1.0          48         -1.0   \n",
       "\n",
       "   output_size  stride_size  units  avg_ms_actual  avg_ms_pred  \n",
       "4         8000         -1.0   32.0          0.941     0.598679  \n",
       "3          768         -1.0  256.0          0.008     0.631385  \n",
       "2         8000          2.0   -1.0          0.039     0.610192  \n",
       "8            1         -1.0    1.0          0.011     0.600166  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn_ms_stacked_2, X_test, y_test = stacked_regression_model_2(cleaned_rnn, '[avg ms]')\n",
    "\n",
    "y_pred = rnn_ms_stacked_2.predict(X_test)\n",
    "\n",
    "print(\"MSE:\", mean_squared_error(y_test, y_pred))\n",
    "rnn_ms_stacked_2_mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "pd.concat([X_test, pd.DataFrame({'avg_ms_actual': y_test, 'avg_ms_pred': y_pred})], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brian/anaconda/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 631.1786728780157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brian/anaconda/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/brian/anaconda/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/brian/anaconda/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/brian/anaconda/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/brian/anaconda/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>activation_elu</th>\n",
       "      <th>activation_exponential</th>\n",
       "      <th>activation_hard_sigmoid</th>\n",
       "      <th>activation_linear</th>\n",
       "      <th>activation_nan</th>\n",
       "      <th>activation_relu</th>\n",
       "      <th>activation_selu</th>\n",
       "      <th>activation_sigmoid</th>\n",
       "      <th>activation_softmax</th>\n",
       "      <th>activation_softplus</th>\n",
       "      <th>activation_softsign</th>\n",
       "      <th>activation_tanh</th>\n",
       "      <th>filters</th>\n",
       "      <th>input_size</th>\n",
       "      <th>kernel_size</th>\n",
       "      <th>output_size</th>\n",
       "      <th>stride_size</th>\n",
       "      <th>units</th>\n",
       "      <th>mem_kb_actual</th>\n",
       "      <th>mem_kb_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>500</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>16000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>64.000</td>\n",
       "      <td>41.050608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>8000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>16000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>32.000</td>\n",
       "      <td>50.459367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>16000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>32000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>32.000</td>\n",
       "      <td>67.846760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>48</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.004</td>\n",
       "      <td>19.299120</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   activation_elu  activation_exponential  activation_hard_sigmoid  \\\n",
       "0             0.0                     0.0                      0.0   \n",
       "5            -1.0                    -1.0                     -1.0   \n",
       "6            -1.0                    -1.0                     -1.0   \n",
       "8            -1.0                    -1.0                     -1.0   \n",
       "\n",
       "   activation_linear  activation_nan  activation_relu  activation_selu  \\\n",
       "0                0.0               1              0.0              0.0   \n",
       "5               -1.0               0              0.0             -1.0   \n",
       "6               -1.0               0              0.0             -1.0   \n",
       "8               -1.0               0              0.0             -1.0   \n",
       "\n",
       "   activation_sigmoid  activation_softmax  activation_softplus  \\\n",
       "0                 0.0                 0.0                  0.0   \n",
       "5                 0.0                -1.0                 -1.0   \n",
       "6                 0.0                -1.0                 -1.0   \n",
       "8                 1.0                -1.0                 -1.0   \n",
       "\n",
       "   activation_softsign  activation_tanh  filters  input_size  kernel_size  \\\n",
       "0                  0.0                0     -1.0         500         -1.0   \n",
       "5                 -1.0                1     -1.0        8000         -1.0   \n",
       "6                 -1.0                1     -1.0       16000         -1.0   \n",
       "8                 -1.0                0     -1.0          48         -1.0   \n",
       "\n",
       "   output_size  stride_size  units  mem_kb_actual  mem_kb_pred  \n",
       "0        16000         -1.0   -1.0         64.000    41.050608  \n",
       "5        16000         -1.0   64.0         32.000    50.459367  \n",
       "6        32000         -1.0  128.0         32.000    67.846760  \n",
       "8            1         -1.0    1.0          0.004    19.299120  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn_mem_stacked_2, X_test, y_test = stacked_regression_model(cleaned_rnn, '[mem KB]')\n",
    "\n",
    "y_pred = rnn_mem_stacked_2.predict(X_test)\n",
    "\n",
    "print(\"MSE:\", mean_squared_error(y_test, y_pred))\n",
    "rnn_mem_stacked_2_mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "pd.concat([X_test, pd.DataFrame({'mem_kb_actual': y_test, 'mem_kb_pred': y_pred})], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3Xe8XFW99/HPF0IPEEJCL0EIXYh4\naAKKRBBEyvUaARETQPLgtYAoiN4rRVFBecRHLNdICxGRXhRFMBKKYiSBELogJICUHJDQa/g9f6w1\nZjOZOTPnJPtMkv19v17zml3WXmvtMvu3y+y1FRGYmVl1LdHpCpiZWWc5EJiZVZwDgZlZxTkQmJlV\nnAOBmVnFORCYmVWcA8EiSMm5kp6T9LdO16cMkl6S9K5+LnM5Sb+R9LykS/qzbJtL0j2Sdu3nMg+W\ndF1/lrkwcSBog6QZkt6QNKRu+DRJIWlY7l9H0mWSnsk7k7skjcnjhuW0L9V9DuhDlXYGdgfWiYjt\nGtR3jKQ5Of8XJN0p6aN9KKdjImJgRDzcz8V+HFgdWDUiRjVKIGljSZcU1vF0ScdIWrKwjq+pm+aX\nkk7K3bvmND+pS3NLbVvpbbnzO9MLUv6tfKgX6c+TdEpxWERsERGTFnC97in85uZIeq3Q//WIuCAi\n9liQZS5KHAja9whwUK1H0ruB5erSTAAeA9YHVgU+DTxdl2ZQ3snVPhf1oS7rAzMi4uUe0twaEQOB\nQcBPgV9LGtSHsnokacCCzrOD1gf+HhFvNRopaUNgMmkdvzsiVgZGAV3AioWkO0jaqYdyXgY+XTuA\naKUX5VoTObgMzL+Jm4HPF36D3+l0/TouIvxp8QFmAP8D3FYYdjrw30AAw/Kwl4ARTfIYltMOaLPM\ntYCrgX8BDwFH5OGHA68Bc3J5JzeYdgxwS6F/+Vz2toVhOwB/AWYDdwK7FsZtANwEvAj8EfgJ8Mu6\n+TgceBS4qY38xgAP5/weAQ7OwzcCbgSeB54BLipME8BGuXtl4HygG5iZ18USxXnN6+O5nP9ePSzX\nzYBJuZ73APvm4ScDbwBv5uV6eINpfwlc00PetWXzVeCGuulOyt27Ao8DZwLnFtLcAoxpkm+P5eY0\n++b5mZ3nb7O67fdYYDopCJ1NOvP5fWEdr1I3D2OBJ4AngS8X8joPOKXQvyvweO6eALwNvJqX4XF5\n+CXAU3k93wRskYePzcv7jZz+N4X6fih3LwP8MNflidy9TN2y/DIwK9f10DZ+W5OAz7T4zQTwX8CD\neRl9C9gQuBV4AbgYWLqQ/qPAtLz8/wJs1Z/7qPn9dLwCi8KntmECD5B2JEsy98i/GAj+CPwZOBBY\nry6P2g+s3UBwI+lIfllgBGknODKPe8dG22Daf4/Pdf1c/rGtloetDTwLfIR0Vrh77h+ax99K2rEu\nTboM9QLzBoLzgRVIZ0VN88tpXgA2ydOvWdgRXEgKpkvk+dy5MA/FQHA+cBXp6HcY8HfyjjrP65vA\nEXleP0vaYajBclmKFFS/nudtt/wjr9XtpNp8NlmuT9HDjqawbAYC/2TuzqxRIFijbrn0FAhalbsx\naQe/e57H4/J8Ll3Yfv9K2vmvTdpp3g68h7Sj/RNwYt08XJjX3btJ215tXs6jSSAo/lbq6ndYXne1\nnfq0wrh35FefB/DNXPfVSNvTX4BvFcp+K6dZirT9vUIOaj0sr0m0FwiuBlYCtgBeByYC7yIdmNwL\njM5pt8nLdHvSNjg6z8Mynd53tfvxpaHemUC63LM7cD/px140inTa+Q3gkXwPYdu6NM9Iml34bFZf\niKR1STvgr0bEaxExDTgLOKQXdd1B0mzS2cPpwKciYlYe9yngdxHxu4h4OyKuB6YAH5G0HrAtcEJE\nvBERt5B+EPVOioiXI+LVnvLLad8GtpS0XEQ8GRH35OFvkoLpWnk+b2mwLJYEDgC+FhEvRsQM4P/W\nLYuZEfGLiJgDjCcFm9UbLRPSTvrUPG9/An5L4ZJfC6uSjjpbeQ34NnBKswQR8RTwv6Sd2PyWewDp\njOH6iHiTtL6XA95XSHNmRDwdEf8kbaOTI+KOiHgduIIUFIpOzuv3LuBc2l9G84iIc/K6e50UbLeW\ntHKbkx8MfDMiZkVEN+nMrbju38zj34yI35HOLDbpa13rnBYRL+Tt9W7guoh4OCKeJ51N1ZbZEcDP\nI2JyRMyJiPGkwLHDAqpH6RwIemcC8EnS0cP59SMj4rmIOD4itiDtiKYBV0pSIdmQiBhU+NzXoJy1\ngH9FxIuFYTNJR3Pt+mtEDAJWIe3IdymMWx8YVQxIpMCzZqHsVwrpH2uQf3FY0/wi3cc4ADgSeFLS\nNZI2zdMdBwj4W76Zd1iDcoaQjt5nFobVL4unah2Feg9skNdawGMR8XYPefXkWdIyascvgNUl7dND\nmtOAD0vaej7LXYvC8snz9xjvnK/ivapXG/TXL6/i+p2Zy+i1fBP9VEn/kPQC6UgZ0nptxzvmrUFd\nno133tN5hcbrvi/aXWbrA1+u2/7XpY/LrBMcCHohImaSrkF/BLi8RdpnSEdmawGDe1nUE8BgScUb\ngesx7xlISxHxEula5yGSakcwjwET6gLSChFxKunIc7Ck5QvZrNso60J3T/kREX+IiN1JO7P7STtJ\nIuKpiDgiItYC/g/wU0kb1ZXzDHPPHOZrWZCW67qSitt9b/L6I/Cf7STMR+Ynk64tq0maZ0mXSr41\nn+U+QWH55AOPdenbMqoprvP1chmQLkEVt4016qarb874k8B+pEurK5MuPcHcZdKq+eN3zFtdXRYW\njwHfrtv+l4+ICztdsXY5EPTe4cBu0eAfO5JOk7SlpAF5J/5Z4KH8g29bRDxGuhb6XUnLStoql3tB\nXyqcyz8LOCEP+iWwj6QP5yO2ZfPfGtfJwW4KcJKkpSXtCPR0VNtjfpJWl7SvpBVIp8svkW50I2mU\npHVyHs+Rdgpz6uo+h3Rj7tuSVpS0PnBMLrO3JpN2ZMdJWkrpv+r7AL9uc/oTgfdJ+r6kNfI8bJT/\nHtroH1kTSNfF9+whzx+QLuHMc4mwF+VeDOwtaaSkpUg3T18nbUN99Q1Jy0vaAjgUqP27bRrpEuLg\nXJej66Z7mnQdvWbFXJdnSQGk/h869enrXQj8j6ShSn/fPoG+rfsy/QI4UtL2SlaQtHfdgdxCzYGg\nlyLiHxExpcno5UnXW2eT/iWzPunfHEWz9c7nCI5pktdBpKOnJ3KeJ+Zr7331Q9IPeKscaPYj3TTt\nJh3RHMvc7eFgYEfSj/cU0k7g9WYZt8hvCdKO6QnSP6A+QDpDgXQvYrKkl0iXr46KiEcaFPEF0g78\nYdJN1V8B5/R2AUTEG6T1sRfpTOOnwKcj4v42p/8HabkMA+6R9DxwGSlwvtgg/RzSTrzpGWFEvAB8\nr0WaHsuNiAdI92nOzPO1D7BPnt++upF0w3kicHpE1B62mkD6V9gM4DrmBoia75J23LMlfYV0CXUm\n6ezkXtKN36Kzgc1z+isb1OOUPJ/TgbtIN7mb3nvphLw/OAL4MemA5iHS5eNFhiL8YhrrmaSLgPsj\n4sRO18XKlZ9teARYKpo8T2GLH58R2DwkbStpQ0lLSNqTdLTf6GjNzBYDi9NTobbgrEG6Gb4q6T/v\nn42IOzpbJTMriy8NmZlVnC8NmZlV3CJxaWjIkCExbNiwTlfDzGyRMnXq1GciYmirdItEIBg2bBhT\npjT7x6aZmTUiaWbrVL40ZGZWeQ4EZmYV50BgZlZxDgRmZhXnQGBmVnGlBgJJX8rtzN8t6cLcKuUG\nkiZLelDSRZKWLrMOZmbWs9ICgaS1gS8CXRGxJekVbgeSXsZxRkQMJ7XUd3hZdTAzs9bKvjQ0AFhO\n0gBSE81Pkt4Te2kePx7Yv+Q6mJlZD0oLBPndqKcDj5ICwPPAVGB2oXnbx2nymkBJYyVNkTSlu7u7\nrGqamVVeaU8WS1qF1HzxBqQXtVxCeiFIvYat3kXEOGAcQFdXl1vGM1tIDTv+mk5XYbE149S9+6Wc\nMi8NfQh4JCK68/tbLye9km9QvlQEsA4L3/tHzcwqpcxA8CiwQ37vqYCRpFfV3QB8PKcZDVxVYh3M\nzKyFMu8RTCbdFL6d9K7RJUiXer4KHCPpIdKLT84uqw5mZtZaqa2P5nfc1r/n9mFguzLLNTOz9vnJ\nYjOzinMgMDOrOAcCM7OKcyAwM6s4BwIzs4pzIDAzqzgHAjOzinMgMDOrOAcCM7OKcyAwM6s4BwIz\ns4pzIDAzqzgHAjOzinMgMDOrOAcCM7OKcyAwM6s4BwIzs4orLRBI2kTStMLnBUlHSxos6XpJD+bv\nVcqqg5mZtVbmO4sfiIgRETECeC/wCnAFcDwwMSKGAxNzv5mZdUh/XRoaCfwjImYC+wHj8/DxwP79\nVAczM2ugvwLBgcCFuXv1iHgSIH+v1mgCSWMlTZE0pbu7u5+qaWZWPaUHAklLA/sCl/RmuogYFxFd\nEdE1dOjQcipnZmb9ckawF3B7RDyd+5+WtCZA/p7VD3UwM7Mm+iMQHMTcy0IAVwOjc/do4Kp+qIOZ\nmTVRaiCQtDywO3B5YfCpwO6SHszjTi2zDmZm1rMBZWYeEa8Aq9YNe5b0LyIzM1sI+MliM7OKcyAw\nM6s4BwIzs4pzIDAzqzgHAjOzinMgMDOrOAcCM7OKcyAwM6s4BwIzs4pzIDAzqzgHAjOzinMgMDOr\nOAcCM7OKcyAwM6s4BwIzs4pzIDAzqzgHAjOziiv7VZWDJF0q6X5J90naUdJgSddLejB/r1JmHczM\nrGdlnxH8P+DaiNgU2Bq4DzgemBgRw4GJud/MzDqktEAgaSXg/cDZABHxRkTMBvYDxudk44H9y6qD\nmZm1VuYZwbuAbuBcSXdIOkvSCsDqEfEkQP5erdHEksZKmiJpSnd3d4nVNDOrtjIDwQBgG+BnEfEe\n4GV6cRkoIsZFRFdEdA0dOrSsOpqZVV6ZgeBx4PGImJz7LyUFhqclrQmQv2eVWAczM2uhtEAQEU8B\nj0naJA8aCdwLXA2MzsNGA1eVVQczM2ttQMn5fwG4QNLSwMPAoaTgc7Gkw4FHgVEl18HMzHpQaiCI\niGlAV4NRI8ss18zM2ucni83MKs6BwMys4hwIzMwqzoHAzKziHAjMzCrOgcDMrOIcCMzMKs6BwMys\n4hwIzMwqzoHAzKziHAjMzCrOgcDMrOIcCMzMKs6BwMys4hwIzMwqzoHAzKziHAjMzCqu1DeUSZoB\nvAjMAd6KiC5Jg4GLgGHADOATEfFcmfUwM7Pm+uOM4IMRMSIiaq+sPB6YGBHDgYm538zMOqQTl4b2\nA8bn7vHA/h2og5mZZWUHggCukzRV0tg8bPWIeBIgf6/WaEJJYyVNkTSlu7u75GqamVVXqfcIgJ0i\n4glJqwHXS7q/3QkjYhwwDqCrqyvKqqCZWdWVekYQEU/k71nAFcB2wNOS1gTI37PKrIOZmfWstEAg\naQVJK9a6gT2Au4GrgdE52WjgqrLqYGZmrZV5aWh14ApJtXJ+FRHXSroNuFjS4cCjwKgS62BmZi2U\nFggi4mFg6wbDnwVGllWumZn1jp8sNjOrOAcCM7OKcyAwM6s4BwIzs4pzIDAzqzgHAjOzinMgMDOr\nuB4DgaRPFbp3qhv3+bIqZWZm/afVGcExhe4z68YdtoDrYmZmHdAqEKhJd6N+MzNbBLUKBNGku1G/\nmZktglq1NbSppOmko/8Ncze5/12l1szMzPpFq0CwWb/UwszMOqbHQBARM4v9klYF3g88GhFTy6yY\nmZn1j1Z/H/2tpC1z95qkF8scBkyQdHQ/1M/MzErW6mbxBhFxd+4+FLg+IvYBtsd/HzUzWyy0CgRv\nFrpHAr8DiIgXgbfLqpSZmfWfVoHgMUlfkPQfwDbAtQCSlgOWaqcASUtKukPSb3P/BpImS3pQ0kWS\nlp6fGTAzs/nTKhAcDmwBjAEOiIjZefgOwLltlnEUcF+h/zTgjIgYDjyXyzAzsw7pMRBExKyIODIi\n9ouI6wrDb4iI01tlLmkdYG/grNwvYDfg0pxkPLB/XytvZmbzr8e/j0q6uqfxEbFvi/x/CBwHrJj7\nVwVmR8Rbuf9xYO0mZY8FxgKst956LYoxM7O+avVA2Y7AY8CFwGR60b6QpI8CsyJiqqRda4MbJG3Y\nVEVEjAPGAXR1dbk5CzOzkrQKBGsAuwMHAZ8ErgEujIh72sh7J2BfSR8BlgVWIp0hDJI0IJ8VrAM8\n0dfKm5nZ/Gt1j2BORFwbEaNJN4gfAiZJ+kKrjCPiaxGxTkQMAw4E/hQRBwM3AB/PyUYDV83PDJiZ\n2fxp+YYySctI+hjwS+BzwI+Ay+ejzK8Cx0h6iHTP4Oz5yMvMzOZTq5vF44Etgd8DJxeeMu6ViJgE\nTMrdDwPb9SUfMzNb8FrdIzgEeBnYGPhi+vcnkG76RkSsVGLdzMysH7RqfdQvtzczW8x5R29mVnEO\nBGZmFedAYGZWcQ4EZmYV50BgZlZxDgRmZhXnQGBmVnEOBGZmFedAYGZWcQ4EZmYV50BgZlZxDgRm\nZhXnQGBmVnEOBGZmFedAYGZWcaUFAknLSvqbpDsl3SPp5Dx8A0mTJT0o6SJJS5dVBzMza63MM4LX\ngd0iYmtgBLCnpB2A04AzImI48BxweIl1MDOzFkoLBJG8lHuXyp8AdgMuzcPHA/uXVQczM2ut1HsE\nkpaUNA2YBVwP/AOYHRFv5SSPA2s3mXaspCmSpnR3d5dZTTOzSis1EETEnIgYAawDbAds1ihZk2nH\nRURXRHQNHTq0zGqamVVav/xrKCJmA5OAHYBBkgbkUesAT/RHHczMrLEy/zU0VNKg3L0c8CHgPuAG\n4OM52WjgqrLqYGZmrQ1onaTP1gTGS1qSFHAujojfSroX+LWkU4A7gLNLrIOZmbVQWiCIiOnAexoM\nf5h0v8DMzBYCfrLYzKziHAjMzCrOgcDMrOIcCMzMKs6BwMys4hwIzMwqzoHAzKziHAjMzCrOgcDM\nrOIcCMzMKs6BwMys4hwIzMwqzoHAzKziHAjMzCrOgcDMrOIcCMzMKs6BwMys4sp8Z/G6km6QdJ+k\neyQdlYcPlnS9pAfz9ypl1cHMzFor84zgLeDLEbEZsAPwOUmbA8cDEyNiODAx95uZWYeUFggi4smI\nuD13vwjcB6wN7AeMz8nGA/uXVQczM2utX+4RSBpGepH9ZGD1iHgSUrAAVmsyzVhJUyRN6e7u7o9q\nmplVUumBQNJA4DLg6Ih4od3pImJcRHRFRNfQoUPLq6CZWcWVGggkLUUKAhdExOV58NOS1szj1wRm\nlVkHMzPrWZn/GhJwNnBfRPygMOpqYHTuHg1cVVYdzMystQEl5r0TcAhwl6RpedjXgVOBiyUdDjwK\njCqxDmZm1kJpgSAibgHUZPTIsso1M7Pe8ZPFZmYV50BgZlZxDgRmZhXnQGBmVnEOBGZmFedAYGZW\ncQ4EZmYV50BgZlZxDgRmZhXnQGBmVnEOBGZmFedAYGZWcQ4EZmYV50BgZlZxDgRmZhXnQGBmVnEO\nBGZmFVfmO4vPkTRL0t2FYYMlXS/pwfy9Slnlm5lZe8o8IzgP2LNu2PHAxIgYDkzM/WZm1kGlBYKI\nuAn4V93g/YDxuXs8sH9Z5ZuZWXv6+x7B6hHxJED+Xq1ZQkljJU2RNKW7u7vfKmhmVjUL7c3iiBgX\nEV0R0TV06NBOV8fMbLHV34HgaUlrAuTvWf1cvpmZ1envQHA1MDp3jwau6ufyzcysTpl/H70QuBXY\nRNLjkg4HTgV2l/QgsHvuNzOzDhpQVsYRcVCTUSPLKtPMzHpvob1ZbGZm/cOBwMys4hwIzMwqzoHA\nzKziHAjMzCrOgcDMrOIcCMzMKs6BwMys4hwIzMwqzoHAzKziHAjMzCrOgcDMrOIcCMzMKs6BwMys\n4kprhtqsr4Ydf02nq7DYmnHq3p2ugi2EfEZgZlZxDgRmZhXXkUAgaU9JD0h6SNLxnaiDmZkl/R4I\nJC0J/ATYC9gcOEjS5v1dDzMzSzpxs3g74KGIeBhA0q+B/YB7yyjMNx7L4xuPZouHTgSCtYHHCv2P\nA9vXJ5I0Fhibe1+S9EA/1G1hMAR4ptOVaIdO63QNFgqLzPoCr7NskVlnC2B9rd9Ook4EAjUYFvMM\niBgHjCu/OgsXSVMioqvT9bD2eH0terzO5tWJm8WPA+sW+tcBnuhAPczMjM4EgtuA4ZI2kLQ0cCBw\ndQfqYWZmdODSUES8JenzwB+AJYFzIuKe/q7HQqxyl8MWcV5fix6vszqKmOfyvJmZVYifLDYzqzgH\nAjOziqt0IJA0R9I0SXdL+o2kQQso32GS7l4QedXle5Kkf+Y6T5N06oIuo1DWCEkfKSv/3pD035Lu\nkTQ9z/f2efjRkpbvY55jJP14Puo0Q9KQPkx3Vu1JeklfLwxva5up2wbulXRQYdx5kh4pbB9fbLNO\nXr5z0xWX792S9m0j/Vd6W88FoTivPaSZJKnlX2UrHQiAVyNiRERsCfwL+FynK9SGM3KdR0RE2+00\n5aY9emME0PFAIGlH4KPANhGxFfAh5j6QeDTQpx1Vp0TEZyKi9hT913tM3NwZETGC9ET+zyUtVRh3\nbGH7+FGrjLx8G6ot31HAOZIWyv1k3bzOl4VyBjvkVtJTz0gaKGmipNsl3SVpvzx8mKT7JP0iH0Fd\nJ2m5PO69ku6UdCuFgCJpWUnn5nzukPTBPHyMpCvzmcgjkj4v6Zic5q+SBrdbcUkj83R3STpH0jJ5\n+AxJJ0i6BRglaUNJ10qaKulmSZvmdKPy0c+dkm7Kf+v9JnBAPjI6YIEs4b5ZE3gmIl4HiIhnIuKJ\nfLS7FnCDpBsAJP1M0pS8bk6uZSBpW0l/yfP3N0krFguQtLekWyUNkTRU0mWSbsufnXKaVfP6vkPS\nz2nwYKSkT0j6Qe4+SlKtGZUN8zr49xGa0tnccnn5XpCzWLLRttVMRDwIvAKs0vvF+m9evk1ExH3A\nW8AQSevnfcL0/L1eXd02lHR7oX+4pKm5e4akkzV3f1L73Q3O+4Dp+Te/VR5+kqTxuY4zJH1M0vfy\ntNcqB34VjvabrZu2RURlP8BL+XtJ4BJgz9w/AFgpdw8BHiJtmMPyhjEij7sY+FTung58IHd/H7g7\nd38ZODd3bwo8CiwLjMn5rggMBZ4HjszpzgCOblDfk4B/AtPy58M5r8eAjXOa82vTAjOA4wrTTwSG\n5+7tgT/l7ruAtXP3oPw9BvjxQrCOBuZ5/Tvw09oyLszfkEL/4ML6nARsBSwNPAxsm8etlNfvGODH\nwH8ANwOr5PG/AnbO3esB9+XuHwEn5O69SU/DD6mr6xrAbbn7UtIzM2sDo4Hv5uGTgK7i9pe7m25b\nDbaBr+TubYCbC+POAx4pbB/v9vKdr+W7PelhVwG/AUbn4YcBVzZIf0Mh/+8AXygsx1r3fwFn5e4z\ngRNz927AtEKetwBLAVuTgv1eedwVwP4N5nWedVOfpqdP1d9QtpykaaSNZCpwfR4u4DuS3g+8TdrY\nVs/jHomIabl7KjBM0sqkHeiNefgEUuuqADuTVjgRcb+kmcDGedwNEfEi8KKk50kbG6Qd81ZN6nxG\nRJxe65G0da7T3/Og8aQzkh/m/otyuoHA+4BLpH8fbC2Tv/8MnCfpYuDyJuV2RES8JOm9wC7AB4GL\nJB0fEec1SP4JpTaqBpCOdDcn7VCejIjbcn4vAORl8EGgC9ijNpx0aWTzwjJaKR/hvh/4WM7jGknP\nNajrU0pnkyuSnp7/VZ5uF9pbrvNsW03SfUnSEcC7gD3rxh0bEZe2UVatzl6+8/qSpE8BLwIHREQo\nXUL7WB4/Afheg+nOAg6VdAxwAKmBzZpa/aYW8tkZ+M88b3/KZ0Ur53G/j4g3Jd1F2rlfm4ff1aTe\njdbN9CbzN4+qXxp6NdK1wPVJRza1SzoHk47S35vHP0068gZ4vTD9HNKCFw3aS8oata1UU8zr7UL/\n27T/sF9P+QO8nL+XAGbH3OvHIyJiM4CIOBL4H9KPa5qkVdssu19ExJyImBQRJwKfJ/94iiRtAHwF\nGBnpWvc1pHXW07p5mHRGtnFh2BLAjoVltHYO1vSQT9GtwKHAA6Qj4V2AHUnBtpVG21YjZ0TEJqSd\nzfmSlm2Sri1evvOo3YfbJSJubpKmUV0vIx0AfhSYGhHPNii7WG5P7a7VLtW9DbwZ+fCeBvuGHtZN\n26oeCACIiOeBLwJfydffVgZm5Yj8QVq04BcRs4HnJe2cBx1cGH1TrV/SxqTT4QXZkur9pLOSjXL/\nIcCN9YnyEdkjkkbluiifTSBpw4iYHBEnkFplXJd0NLRifT79TdImkoYXBo0AZubuYh1XIgW95yWt\nztwzsvuBtSRtm/NbUVLthzSTdHR2vqQt8rDrSDvDWvkjcmdxPe5F8+vyN5F+lDcBd5COil/P21i9\nN/XOG729EhGXA1NIl0b6xMu3bX8hNYdDruct9Qki4jVSiwk/A85tI8/iPO9KulfzQo9TNNZs3bTN\ngSCLiDuAO0kr+wKgS9IU0oq6v40sDgV+onSz+NXC8J+SblLdRbpMMybyjbkFVO/XctmX5DLeBv63\nSfKDgcMl3QncQ/rXCcD3842ou0kb552k652bq/M3iwcC45X+KjmddMp7Uh43Dvi9pBsi4k7SjuEe\n4BzyEWJEvEE6cj4zz/f1FI6WIuIB0nK5RNKGpAOCrnwD717gyJz0ZOD9+YbgHqR7PY3cTAqkN0XE\nHNL9m3l2GoX6T9fcm5l98U3gGPX9ny1evu35Iumyz3TSwdZRTdJdQDqqv66NPE8iLwvgVPoY0Jut\nm95wExNmZguI0jMFK0fENzpdl96o+s1iM7MFQtIVwIakfwAtUnxGYGZWcb5HYGZWcQ4EZmYV50Bg\nZlZxvllsizVJc0hPYw4gNb9wSH7uw8wynxHY4q6UFmYLD02VTr1vOdasVxwIrEr+3cIsgKRjlVrA\nnK53tqb5DUn3S7pe0oX5v+G11h6/I+lG4Cg1b0nzA5r7ToA78tO2ayq17Fpr536XnPag2sN8kk4r\n1OElSd+UNJnUhIJZaXxpyCohH1WPBM7O/XsAw0kNgwm4WqmRwVdIbe28h/T7uJ3UUFjNoIj4QM7j\nV6R2aW5Rapb4D8BmpCYQPhe9kWdXAAABrElEQVQRf1Zq7O81YCzwh4j4dq7L8pLWAk4D3gs8B1wn\naf+IuBJYgdSC7QnlLRWzxIHAFnfNWpjdI3/uyP0DSYFhReCqiHgVQNJveKeLCt3NWtL8M/CD3LTB\n5RHxuKTbSC85WYrUhPE0SbsBkyKiO5d1Aak1zStJjZNdtiAWgFkrvjRki7tmLcyK1IZ9rRXMjSLi\nbNpvzRWatKQZEacCnwGWA/4qadOIuIm0k/8nMEHSp1uU9VpuS8esdA4EVgkNWpj9A3BYvnSDpLUl\nrUZqwGwfpTfLDSS9JKWZhi1p5tZc74qI00itg24qaX1Si7a/IF2e2gaYDHxA6c1dSwIH0aDlWLOy\n+dKQVUZE3JFbyDwwIiZI2gy4NV/aeYn0xqrbJF1NaoF1JmlH3qiJY0iB5Se59cgBpJZbjwSOVmq+\nfA5wL/B7Uqu2x0p6M5f16Yh4UtLXSC29CvhdRFxVysyb9cBtDZnVkTQwv7lredLOfWxE3N5qOrNF\nlc8IzOY1TtLmpHb1xzsI2OLOZwRmZhXnm8VmZhXnQGBmVnEOBGZmFedAYGZWcQ4EZmYV9/8Bvj6f\nsRF38IIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cnn_ms = [cnn_ms_rf_mse, cnn_ms_stacked_1_mse,cnn_ms_stacked_2_mse]\n",
    "plt.bar([i for i in range(len(cnn_ms))], cnn_ms, tick_label=[\n",
    "    'Random Forest',\n",
    "    'Stacked with RF',\n",
    "    'Stacked with Polynomial',\n",
    "])\n",
    "plt.title('MSE of Regression of CNN Computation Time')\n",
    "plt.ylabel('MSE')\n",
    "\n",
    "plt.xlabel('Regressor')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEWCAYAAACXGLsWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rnn_ms = [rnn_ms_rf_mse, rnn_ms_stacked_1_mse]#, rnn_ms_stacked_2_mse]\n",
    "\n",
    "plt.bar([i for i in range(len(rnn_ms))], rnn_ms, tick_label=[\n",
    "    'Random Forest',\n",
    "    'Stacked with RF',\n",
    "#     'Stacked with Polynomial',\n",
    "])\n",
    "plt.title('MSE of Regression of RNN Computation Time')\n",
    "plt.ylabel('MSE')\n",
    "\n",
    "plt.xlabel('Regressor')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaEAAAEWCAYAAADPZygPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nsLWdAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cnn_mem = [cnn_mem_rf_mse, cnn_mem_stacked_1_mse]\n",
    "plt.bar(range(len(cnn_mem)), cnn_mem, tick_label=[\"Random Forest\", \"Stacked with RF\"])\n",
    "\n",
    "plt.title('MSE of Regression of CNN Memory Usage')\n",
    "plt.ylabel('MSE')\n",
    "plt.xlabel('Regressor')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nMyv6Pz4dwQS7IDhJAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rnn_mem = [rnn_mem_rf_mse, rnn_mem_stacked_1_mse, rnn_mem_stacked_2_mse]\n",
    "\n",
    "plt.bar(range(len(rnn_mem)), rnn_mem, tick_label=[\n",
    "    \"Random Forest\",\n",
    "    \"Stacked with RF\",\n",
    "    \"Stacked with Polynomial\",\n",
    "])\n",
    "\n",
    "plt.title('MSE of Regression of RNN Memory Usage')\n",
    "plt.ylabel('MSE')\n",
    "plt.xlabel('Regressor')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_cnn_ms(model):\n",
    "    \n",
    "    layer_features = get_layer_features(model)\n",
    "    cleaned_features = clean(layer_features, inference=True)\n",
    "    \n",
    "    X = cleaned_features.drop(['name', 'input_shape', 'output_shape', 'strides'], axis=1)  # Features\n",
    "    \n",
    "    predicted = cnn_ms_rf.predict(X)\n",
    "    \n",
    "    return pd.DataFrame({'name': cleaned_features['name'], 'pred_ms': predicted})\n",
    "\n",
    "def predict_cnn_mem(model):\n",
    "    \n",
    "    layer_features = get_layer_features(model)\n",
    "    cleaned_features = clean(layer_features, inference=True)\n",
    "    \n",
    "    X = cleaned_features.drop(['name', 'input_shape', 'output_shape', 'strides'], axis=1)  # Features\n",
    "    \n",
    "    predicted = cnn_mem_rf.predict(X)\n",
    "    \n",
    "    return pd.DataFrame({'name': cleaned_features['name'], 'pred_mem': predicted})\n",
    "\n",
    "def predict_rnn_ms(model):\n",
    "    \n",
    "    layer_features = get_layer_features(model)\n",
    "    cleaned_features = clean(layer_features, inference=True)\n",
    "    \n",
    "    X = cleaned_features.drop(['name', 'input_shape', 'output_shape', 'strides'], axis=1)  # Features\n",
    "    \n",
    "    predicted = rnn_ms_rf.predict(X)\n",
    "    \n",
    "    return pd.DataFrame({'name': cleaned_features['name'], 'pred_ms': predicted})\n",
    "\n",
    "def predict_rnn_mem(model):\n",
    "    \n",
    "    layer_features = get_layer_features(model)\n",
    "    cleaned_features = clean(layer_features, inference=True)\n",
    "    \n",
    "    X = cleaned_features.drop(['name', 'input_shape', 'output_shape', 'strides'], axis=1)  # Features\n",
    "    \n",
    "    predicted = rnn_mem_rf.predict(X)\n",
    "    \n",
    "    return pd.DataFrame({'name': cleaned_features['name'], 'pred_mem': predicted})\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "test_model = tf.keras.applications.resnet50.ResNet50(\n",
    "    include_top=True,\n",
    "    weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving saved model and benchmark results.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>[node type]</th>\n",
       "      <th>[start]</th>\n",
       "      <th>[first]</th>\n",
       "      <th>[avg ms]</th>\n",
       "      <th>[%]</th>\n",
       "      <th>[cdf%]</th>\n",
       "      <th>[mem KB]</th>\n",
       "      <th>[times called]</th>\n",
       "      <th>[Name]</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NoOp</td>\n",
       "      <td>-6.821</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014%</td>\n",
       "      <td>0.014%</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>_SOURCE</td>\n",
       "      <td>_SOURCE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Const</td>\n",
       "      <td>-6.790</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005%</td>\n",
       "      <td>0.019%</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>bn2b_branch2c/gamma</td>\n",
       "      <td>bn2b_branch2c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Const</td>\n",
       "      <td>-6.783</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002%</td>\n",
       "      <td>0.022%</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>bn2c_branch2b/beta</td>\n",
       "      <td>bn2c_branch2b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Const</td>\n",
       "      <td>-6.779</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002%</td>\n",
       "      <td>0.024%</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>bn3a_branch2c/beta</td>\n",
       "      <td>bn3a_branch2c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Const</td>\n",
       "      <td>-6.776</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002%</td>\n",
       "      <td>0.026%</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>bn3b_branch2c/moving_mean</td>\n",
       "      <td>bn3b_branch2c</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                [node type]  [start]  [first]  [avg ms]       [%]    [cdf%]  \\\n",
       "0                      NoOp   -6.821    0.034     0.014    0.014%    0.014%   \n",
       "1                     Const   -6.790    0.017     0.005    0.005%    0.019%   \n",
       "2                     Const   -6.783    0.004     0.002    0.002%    0.022%   \n",
       "3                     Const   -6.779    0.004     0.002    0.002%    0.024%   \n",
       "4                     Const   -6.776    0.003     0.002    0.002%    0.026%   \n",
       "\n",
       "   [mem KB]  [times called]                     [Name]           name  \n",
       "0       0.0               1                    _SOURCE        _SOURCE  \n",
       "1       0.0               1        bn2b_branch2c/gamma  bn2b_branch2c  \n",
       "2       0.0               1         bn2c_branch2b/beta  bn2c_branch2b  \n",
       "3       0.0               1         bn3a_branch2c/beta  bn3a_branch2c  \n",
       "4       0.0               1  bn3b_branch2c/moving_mean  bn3b_branch2c  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet_benchmark = benchmark_model(test_model)\n",
    "resnet_benchmark.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "resnet_cpu = resnet_benchmark[['name', '[avg ms]']].groupby('name').sum()\n",
    "resnet_mem = resnet_benchmark[['name', '[mem KB]']].groupby('name').max()\n",
    "\n",
    "bench_cpu = resnet_cpu.merge(predict_cnn_ms(test_model), on='name')\n",
    "bench_mem = resnet_mem.merge(predict_cnn_mem(test_model), on='name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.24975750164106\n",
      "892257.5725697743\n"
     ]
    }
   ],
   "source": [
    "print(mean_squared_error(bench_cpu['pred_ms'], bench_cpu['[avg ms]']))\n",
    "print(mean_squared_error(bench_mem['pred_mem'], bench_mem['[mem KB]']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/brian/anaconda/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /Users/brian/anaconda/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:97: calling Orthogonal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /Users/brian/anaconda/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>pred_ms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>embedding</td>\n",
       "      <td>0.130042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bidirectional</td>\n",
       "      <td>0.145918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dropout</td>\n",
       "      <td>0.130042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dense</td>\n",
       "      <td>0.148489</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            name   pred_ms\n",
       "0      embedding  0.130042\n",
       "1  bidirectional  0.145918\n",
       "2        dropout  0.130042\n",
       "3          dense  0.148489"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.compat.v1.keras.models import Sequential\n",
    "# from keras.layers import Dense, Dropout, Embedding, LSTM, Bidirectional\n",
    "\n",
    "max_features = 20000\n",
    "maxlen = 100\n",
    "batch_size = 32\n",
    "rnn_model = Sequential()\n",
    "rnn_model.add(layers.Embedding(max_features, 128, input_length=maxlen))\n",
    "rnn_model.add(layers.Bidirectional(layers.LSTM(64)))\n",
    "rnn_model.add(layers.Dropout(0.5))\n",
    "rnn_model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "# try using different optimizers and different optimizer configs\n",
    "rnn_model.compile('adam', 'binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "predict_rnn_ms(rnn_model)\n",
    "\n",
    "# get_layer_features(rnn_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>pred_mem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>embedding</td>\n",
       "      <td>24.705252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bidirectional</td>\n",
       "      <td>29.568892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dropout</td>\n",
       "      <td>24.705252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dense</td>\n",
       "      <td>24.705252</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            name   pred_mem\n",
       "0      embedding  24.705252\n",
       "1  bidirectional  29.568892\n",
       "2        dropout  24.705252\n",
       "3          dense  24.705252"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_rnn_mem(rnn_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>input_shape</th>\n",
       "      <th>output_shape</th>\n",
       "      <th>units</th>\n",
       "      <th>filters</th>\n",
       "      <th>strides</th>\n",
       "      <th>kernel_size</th>\n",
       "      <th>activation_linear</th>\n",
       "      <th>activation_relu</th>\n",
       "      <th>activation_softmax</th>\n",
       "      <th>...</th>\n",
       "      <th>activation_elu</th>\n",
       "      <th>activation_softplus</th>\n",
       "      <th>activation_softsign</th>\n",
       "      <th>activation_tanh</th>\n",
       "      <th>activation_sigmoid</th>\n",
       "      <th>activation_hard_sigmoid</th>\n",
       "      <th>activation_exponential</th>\n",
       "      <th>input_size</th>\n",
       "      <th>output_size</th>\n",
       "      <th>stride_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>input_1</td>\n",
       "      <td>[(None, 224, 224, 3)]</td>\n",
       "      <td>[(None, 224, 224, 3)]</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>150528</td>\n",
       "      <td>150528</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>conv1_pad</td>\n",
       "      <td>(None, 224, 224, 3)</td>\n",
       "      <td>(None, 230, 230, 3)</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>150528</td>\n",
       "      <td>158700</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>conv1</td>\n",
       "      <td>(None, 230, 230, 3)</td>\n",
       "      <td>(None, 112, 112, 64)</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>49.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>158700</td>\n",
       "      <td>802816</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bn_conv1</td>\n",
       "      <td>(None, 112, 112, 64)</td>\n",
       "      <td>(None, 112, 112, 64)</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>802816</td>\n",
       "      <td>802816</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>activation</td>\n",
       "      <td>(None, 112, 112, 64)</td>\n",
       "      <td>(None, 112, 112, 64)</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>802816</td>\n",
       "      <td>802816</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>pool1_pad</td>\n",
       "      <td>(None, 112, 112, 64)</td>\n",
       "      <td>(None, 114, 114, 64)</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>802816</td>\n",
       "      <td>831744</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>max_pooling2d</td>\n",
       "      <td>(None, 114, 114, 64)</td>\n",
       "      <td>(None, 56, 56, 64)</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>831744</td>\n",
       "      <td>200704</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>res2a_branch2a</td>\n",
       "      <td>(None, 56, 56, 64)</td>\n",
       "      <td>(None, 56, 56, 64)</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>200704</td>\n",
       "      <td>200704</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>bn2a_branch2a</td>\n",
       "      <td>(None, 56, 56, 64)</td>\n",
       "      <td>(None, 56, 56, 64)</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>200704</td>\n",
       "      <td>200704</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>activation_1</td>\n",
       "      <td>(None, 56, 56, 64)</td>\n",
       "      <td>(None, 56, 56, 64)</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>200704</td>\n",
       "      <td>200704</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>res2a_branch2b</td>\n",
       "      <td>(None, 56, 56, 64)</td>\n",
       "      <td>(None, 56, 56, 64)</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>200704</td>\n",
       "      <td>200704</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>bn2a_branch2b</td>\n",
       "      <td>(None, 56, 56, 64)</td>\n",
       "      <td>(None, 56, 56, 64)</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>200704</td>\n",
       "      <td>200704</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>activation_2</td>\n",
       "      <td>(None, 56, 56, 64)</td>\n",
       "      <td>(None, 56, 56, 64)</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>200704</td>\n",
       "      <td>200704</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>res2a_branch2c</td>\n",
       "      <td>(None, 56, 56, 64)</td>\n",
       "      <td>(None, 56, 56, 256)</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>256.0</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>200704</td>\n",
       "      <td>802816</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>res2a_branch1</td>\n",
       "      <td>(None, 56, 56, 64)</td>\n",
       "      <td>(None, 56, 56, 256)</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>256.0</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>200704</td>\n",
       "      <td>802816</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>bn2a_branch2c</td>\n",
       "      <td>(None, 56, 56, 256)</td>\n",
       "      <td>(None, 56, 56, 256)</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>802816</td>\n",
       "      <td>802816</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>bn2a_branch1</td>\n",
       "      <td>(None, 56, 56, 256)</td>\n",
       "      <td>(None, 56, 56, 256)</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>802816</td>\n",
       "      <td>802816</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>add</td>\n",
       "      <td>[(None, 56, 56, 256), (None, 56, 56, 256)]</td>\n",
       "      <td>(None, 56, 56, 256)</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1605632</td>\n",
       "      <td>802816</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>activation_3</td>\n",
       "      <td>(None, 56, 56, 256)</td>\n",
       "      <td>(None, 56, 56, 256)</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>802816</td>\n",
       "      <td>802816</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>res2b_branch2a</td>\n",
       "      <td>(None, 56, 56, 256)</td>\n",
       "      <td>(None, 56, 56, 64)</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>802816</td>\n",
       "      <td>200704</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>bn2b_branch2a</td>\n",
       "      <td>(None, 56, 56, 64)</td>\n",
       "      <td>(None, 56, 56, 64)</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>200704</td>\n",
       "      <td>200704</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>activation_4</td>\n",
       "      <td>(None, 56, 56, 64)</td>\n",
       "      <td>(None, 56, 56, 64)</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>200704</td>\n",
       "      <td>200704</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>res2b_branch2b</td>\n",
       "      <td>(None, 56, 56, 64)</td>\n",
       "      <td>(None, 56, 56, 64)</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>200704</td>\n",
       "      <td>200704</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>bn2b_branch2b</td>\n",
       "      <td>(None, 56, 56, 64)</td>\n",
       "      <td>(None, 56, 56, 64)</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>200704</td>\n",
       "      <td>200704</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>activation_5</td>\n",
       "      <td>(None, 56, 56, 64)</td>\n",
       "      <td>(None, 56, 56, 64)</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>200704</td>\n",
       "      <td>200704</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>res2b_branch2c</td>\n",
       "      <td>(None, 56, 56, 64)</td>\n",
       "      <td>(None, 56, 56, 256)</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>256.0</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>200704</td>\n",
       "      <td>802816</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>bn2b_branch2c</td>\n",
       "      <td>(None, 56, 56, 256)</td>\n",
       "      <td>(None, 56, 56, 256)</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>802816</td>\n",
       "      <td>802816</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>add_1</td>\n",
       "      <td>[(None, 56, 56, 256), (None, 56, 56, 256)]</td>\n",
       "      <td>(None, 56, 56, 256)</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1605632</td>\n",
       "      <td>802816</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>activation_6</td>\n",
       "      <td>(None, 56, 56, 256)</td>\n",
       "      <td>(None, 56, 56, 256)</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>802816</td>\n",
       "      <td>802816</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>res2c_branch2a</td>\n",
       "      <td>(None, 56, 56, 256)</td>\n",
       "      <td>(None, 56, 56, 64)</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>802816</td>\n",
       "      <td>200704</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>bn5a_branch2b</td>\n",
       "      <td>(None, 7, 7, 512)</td>\n",
       "      <td>(None, 7, 7, 512)</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>25088</td>\n",
       "      <td>25088</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>activation_41</td>\n",
       "      <td>(None, 7, 7, 512)</td>\n",
       "      <td>(None, 7, 7, 512)</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>25088</td>\n",
       "      <td>25088</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>res5a_branch2c</td>\n",
       "      <td>(None, 7, 7, 512)</td>\n",
       "      <td>(None, 7, 7, 2048)</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2048.0</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>25088</td>\n",
       "      <td>100352</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>res5a_branch1</td>\n",
       "      <td>(None, 14, 14, 1024)</td>\n",
       "      <td>(None, 7, 7, 2048)</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2048.0</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>200704</td>\n",
       "      <td>100352</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>bn5a_branch2c</td>\n",
       "      <td>(None, 7, 7, 2048)</td>\n",
       "      <td>(None, 7, 7, 2048)</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>100352</td>\n",
       "      <td>100352</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>bn5a_branch1</td>\n",
       "      <td>(None, 7, 7, 2048)</td>\n",
       "      <td>(None, 7, 7, 2048)</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>100352</td>\n",
       "      <td>100352</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>add_13</td>\n",
       "      <td>[(None, 7, 7, 2048), (None, 7, 7, 2048)]</td>\n",
       "      <td>(None, 7, 7, 2048)</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>200704</td>\n",
       "      <td>100352</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>activation_42</td>\n",
       "      <td>(None, 7, 7, 2048)</td>\n",
       "      <td>(None, 7, 7, 2048)</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>100352</td>\n",
       "      <td>100352</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>res5b_branch2a</td>\n",
       "      <td>(None, 7, 7, 2048)</td>\n",
       "      <td>(None, 7, 7, 512)</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>512.0</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>100352</td>\n",
       "      <td>25088</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>bn5b_branch2a</td>\n",
       "      <td>(None, 7, 7, 512)</td>\n",
       "      <td>(None, 7, 7, 512)</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>25088</td>\n",
       "      <td>25088</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>activation_43</td>\n",
       "      <td>(None, 7, 7, 512)</td>\n",
       "      <td>(None, 7, 7, 512)</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>25088</td>\n",
       "      <td>25088</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>res5b_branch2b</td>\n",
       "      <td>(None, 7, 7, 512)</td>\n",
       "      <td>(None, 7, 7, 512)</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>512.0</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>25088</td>\n",
       "      <td>25088</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>bn5b_branch2b</td>\n",
       "      <td>(None, 7, 7, 512)</td>\n",
       "      <td>(None, 7, 7, 512)</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>25088</td>\n",
       "      <td>25088</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>activation_44</td>\n",
       "      <td>(None, 7, 7, 512)</td>\n",
       "      <td>(None, 7, 7, 512)</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>25088</td>\n",
       "      <td>25088</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>res5b_branch2c</td>\n",
       "      <td>(None, 7, 7, 512)</td>\n",
       "      <td>(None, 7, 7, 2048)</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2048.0</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>25088</td>\n",
       "      <td>100352</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>bn5b_branch2c</td>\n",
       "      <td>(None, 7, 7, 2048)</td>\n",
       "      <td>(None, 7, 7, 2048)</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>100352</td>\n",
       "      <td>100352</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>add_14</td>\n",
       "      <td>[(None, 7, 7, 2048), (None, 7, 7, 2048)]</td>\n",
       "      <td>(None, 7, 7, 2048)</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>200704</td>\n",
       "      <td>100352</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>activation_45</td>\n",
       "      <td>(None, 7, 7, 2048)</td>\n",
       "      <td>(None, 7, 7, 2048)</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>100352</td>\n",
       "      <td>100352</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>res5c_branch2a</td>\n",
       "      <td>(None, 7, 7, 2048)</td>\n",
       "      <td>(None, 7, 7, 512)</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>512.0</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>100352</td>\n",
       "      <td>25088</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>bn5c_branch2a</td>\n",
       "      <td>(None, 7, 7, 512)</td>\n",
       "      <td>(None, 7, 7, 512)</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>25088</td>\n",
       "      <td>25088</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>activation_46</td>\n",
       "      <td>(None, 7, 7, 512)</td>\n",
       "      <td>(None, 7, 7, 512)</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>25088</td>\n",
       "      <td>25088</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>res5c_branch2b</td>\n",
       "      <td>(None, 7, 7, 512)</td>\n",
       "      <td>(None, 7, 7, 512)</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>512.0</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>25088</td>\n",
       "      <td>25088</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>bn5c_branch2b</td>\n",
       "      <td>(None, 7, 7, 512)</td>\n",
       "      <td>(None, 7, 7, 512)</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>25088</td>\n",
       "      <td>25088</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>activation_47</td>\n",
       "      <td>(None, 7, 7, 512)</td>\n",
       "      <td>(None, 7, 7, 512)</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>25088</td>\n",
       "      <td>25088</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>res5c_branch2c</td>\n",
       "      <td>(None, 7, 7, 512)</td>\n",
       "      <td>(None, 7, 7, 2048)</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2048.0</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>25088</td>\n",
       "      <td>100352</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>bn5c_branch2c</td>\n",
       "      <td>(None, 7, 7, 2048)</td>\n",
       "      <td>(None, 7, 7, 2048)</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>100352</td>\n",
       "      <td>100352</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>add_15</td>\n",
       "      <td>[(None, 7, 7, 2048), (None, 7, 7, 2048)]</td>\n",
       "      <td>(None, 7, 7, 2048)</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>200704</td>\n",
       "      <td>100352</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>activation_48</td>\n",
       "      <td>(None, 7, 7, 2048)</td>\n",
       "      <td>(None, 7, 7, 2048)</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>100352</td>\n",
       "      <td>100352</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>avg_pool</td>\n",
       "      <td>(None, 7, 7, 2048)</td>\n",
       "      <td>(None, 2048)</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>100352</td>\n",
       "      <td>2048</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>fc1000</td>\n",
       "      <td>(None, 2048)</td>\n",
       "      <td>(None, 1000)</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2048</td>\n",
       "      <td>1000</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>177 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               name                                 input_shape  \\\n",
       "0           input_1                       [(None, 224, 224, 3)]   \n",
       "1         conv1_pad                         (None, 224, 224, 3)   \n",
       "2             conv1                         (None, 230, 230, 3)   \n",
       "3          bn_conv1                        (None, 112, 112, 64)   \n",
       "4        activation                        (None, 112, 112, 64)   \n",
       "5         pool1_pad                        (None, 112, 112, 64)   \n",
       "6     max_pooling2d                        (None, 114, 114, 64)   \n",
       "7    res2a_branch2a                          (None, 56, 56, 64)   \n",
       "8     bn2a_branch2a                          (None, 56, 56, 64)   \n",
       "9      activation_1                          (None, 56, 56, 64)   \n",
       "10   res2a_branch2b                          (None, 56, 56, 64)   \n",
       "11    bn2a_branch2b                          (None, 56, 56, 64)   \n",
       "12     activation_2                          (None, 56, 56, 64)   \n",
       "13   res2a_branch2c                          (None, 56, 56, 64)   \n",
       "14    res2a_branch1                          (None, 56, 56, 64)   \n",
       "15    bn2a_branch2c                         (None, 56, 56, 256)   \n",
       "16     bn2a_branch1                         (None, 56, 56, 256)   \n",
       "17              add  [(None, 56, 56, 256), (None, 56, 56, 256)]   \n",
       "18     activation_3                         (None, 56, 56, 256)   \n",
       "19   res2b_branch2a                         (None, 56, 56, 256)   \n",
       "20    bn2b_branch2a                          (None, 56, 56, 64)   \n",
       "21     activation_4                          (None, 56, 56, 64)   \n",
       "22   res2b_branch2b                          (None, 56, 56, 64)   \n",
       "23    bn2b_branch2b                          (None, 56, 56, 64)   \n",
       "24     activation_5                          (None, 56, 56, 64)   \n",
       "25   res2b_branch2c                          (None, 56, 56, 64)   \n",
       "26    bn2b_branch2c                         (None, 56, 56, 256)   \n",
       "27            add_1  [(None, 56, 56, 256), (None, 56, 56, 256)]   \n",
       "28     activation_6                         (None, 56, 56, 256)   \n",
       "29   res2c_branch2a                         (None, 56, 56, 256)   \n",
       "..              ...                                         ...   \n",
       "147   bn5a_branch2b                           (None, 7, 7, 512)   \n",
       "148   activation_41                           (None, 7, 7, 512)   \n",
       "149  res5a_branch2c                           (None, 7, 7, 512)   \n",
       "150   res5a_branch1                        (None, 14, 14, 1024)   \n",
       "151   bn5a_branch2c                          (None, 7, 7, 2048)   \n",
       "152    bn5a_branch1                          (None, 7, 7, 2048)   \n",
       "153          add_13    [(None, 7, 7, 2048), (None, 7, 7, 2048)]   \n",
       "154   activation_42                          (None, 7, 7, 2048)   \n",
       "155  res5b_branch2a                          (None, 7, 7, 2048)   \n",
       "156   bn5b_branch2a                           (None, 7, 7, 512)   \n",
       "157   activation_43                           (None, 7, 7, 512)   \n",
       "158  res5b_branch2b                           (None, 7, 7, 512)   \n",
       "159   bn5b_branch2b                           (None, 7, 7, 512)   \n",
       "160   activation_44                           (None, 7, 7, 512)   \n",
       "161  res5b_branch2c                           (None, 7, 7, 512)   \n",
       "162   bn5b_branch2c                          (None, 7, 7, 2048)   \n",
       "163          add_14    [(None, 7, 7, 2048), (None, 7, 7, 2048)]   \n",
       "164   activation_45                          (None, 7, 7, 2048)   \n",
       "165  res5c_branch2a                          (None, 7, 7, 2048)   \n",
       "166   bn5c_branch2a                           (None, 7, 7, 512)   \n",
       "167   activation_46                           (None, 7, 7, 512)   \n",
       "168  res5c_branch2b                           (None, 7, 7, 512)   \n",
       "169   bn5c_branch2b                           (None, 7, 7, 512)   \n",
       "170   activation_47                           (None, 7, 7, 512)   \n",
       "171  res5c_branch2c                           (None, 7, 7, 512)   \n",
       "172   bn5c_branch2c                          (None, 7, 7, 2048)   \n",
       "173          add_15    [(None, 7, 7, 2048), (None, 7, 7, 2048)]   \n",
       "174   activation_48                          (None, 7, 7, 2048)   \n",
       "175        avg_pool                          (None, 7, 7, 2048)   \n",
       "176          fc1000                                (None, 2048)   \n",
       "\n",
       "              output_shape   units  filters strides  kernel_size  \\\n",
       "0    [(None, 224, 224, 3)]    -1.0     -1.0      -1         -1.0   \n",
       "1      (None, 230, 230, 3)    -1.0     -1.0      -1         -1.0   \n",
       "2     (None, 112, 112, 64)    -1.0     64.0  (2, 2)         49.0   \n",
       "3     (None, 112, 112, 64)    -1.0     -1.0      -1         -1.0   \n",
       "4     (None, 112, 112, 64)    -1.0     -1.0      -1         -1.0   \n",
       "5     (None, 114, 114, 64)    -1.0     -1.0      -1         -1.0   \n",
       "6       (None, 56, 56, 64)    -1.0     -1.0  (2, 2)         -1.0   \n",
       "7       (None, 56, 56, 64)    -1.0     64.0  (1, 1)          1.0   \n",
       "8       (None, 56, 56, 64)    -1.0     -1.0      -1         -1.0   \n",
       "9       (None, 56, 56, 64)    -1.0     -1.0      -1         -1.0   \n",
       "10      (None, 56, 56, 64)    -1.0     64.0  (1, 1)          9.0   \n",
       "11      (None, 56, 56, 64)    -1.0     -1.0      -1         -1.0   \n",
       "12      (None, 56, 56, 64)    -1.0     -1.0      -1         -1.0   \n",
       "13     (None, 56, 56, 256)    -1.0    256.0  (1, 1)          1.0   \n",
       "14     (None, 56, 56, 256)    -1.0    256.0  (1, 1)          1.0   \n",
       "15     (None, 56, 56, 256)    -1.0     -1.0      -1         -1.0   \n",
       "16     (None, 56, 56, 256)    -1.0     -1.0      -1         -1.0   \n",
       "17     (None, 56, 56, 256)    -1.0     -1.0      -1         -1.0   \n",
       "18     (None, 56, 56, 256)    -1.0     -1.0      -1         -1.0   \n",
       "19      (None, 56, 56, 64)    -1.0     64.0  (1, 1)          1.0   \n",
       "20      (None, 56, 56, 64)    -1.0     -1.0      -1         -1.0   \n",
       "21      (None, 56, 56, 64)    -1.0     -1.0      -1         -1.0   \n",
       "22      (None, 56, 56, 64)    -1.0     64.0  (1, 1)          9.0   \n",
       "23      (None, 56, 56, 64)    -1.0     -1.0      -1         -1.0   \n",
       "24      (None, 56, 56, 64)    -1.0     -1.0      -1         -1.0   \n",
       "25     (None, 56, 56, 256)    -1.0    256.0  (1, 1)          1.0   \n",
       "26     (None, 56, 56, 256)    -1.0     -1.0      -1         -1.0   \n",
       "27     (None, 56, 56, 256)    -1.0     -1.0      -1         -1.0   \n",
       "28     (None, 56, 56, 256)    -1.0     -1.0      -1         -1.0   \n",
       "29      (None, 56, 56, 64)    -1.0     64.0  (1, 1)          1.0   \n",
       "..                     ...     ...      ...     ...          ...   \n",
       "147      (None, 7, 7, 512)    -1.0     -1.0      -1         -1.0   \n",
       "148      (None, 7, 7, 512)    -1.0     -1.0      -1         -1.0   \n",
       "149     (None, 7, 7, 2048)    -1.0   2048.0  (1, 1)          1.0   \n",
       "150     (None, 7, 7, 2048)    -1.0   2048.0  (2, 2)          1.0   \n",
       "151     (None, 7, 7, 2048)    -1.0     -1.0      -1         -1.0   \n",
       "152     (None, 7, 7, 2048)    -1.0     -1.0      -1         -1.0   \n",
       "153     (None, 7, 7, 2048)    -1.0     -1.0      -1         -1.0   \n",
       "154     (None, 7, 7, 2048)    -1.0     -1.0      -1         -1.0   \n",
       "155      (None, 7, 7, 512)    -1.0    512.0  (1, 1)          1.0   \n",
       "156      (None, 7, 7, 512)    -1.0     -1.0      -1         -1.0   \n",
       "157      (None, 7, 7, 512)    -1.0     -1.0      -1         -1.0   \n",
       "158      (None, 7, 7, 512)    -1.0    512.0  (1, 1)          9.0   \n",
       "159      (None, 7, 7, 512)    -1.0     -1.0      -1         -1.0   \n",
       "160      (None, 7, 7, 512)    -1.0     -1.0      -1         -1.0   \n",
       "161     (None, 7, 7, 2048)    -1.0   2048.0  (1, 1)          1.0   \n",
       "162     (None, 7, 7, 2048)    -1.0     -1.0      -1         -1.0   \n",
       "163     (None, 7, 7, 2048)    -1.0     -1.0      -1         -1.0   \n",
       "164     (None, 7, 7, 2048)    -1.0     -1.0      -1         -1.0   \n",
       "165      (None, 7, 7, 512)    -1.0    512.0  (1, 1)          1.0   \n",
       "166      (None, 7, 7, 512)    -1.0     -1.0      -1         -1.0   \n",
       "167      (None, 7, 7, 512)    -1.0     -1.0      -1         -1.0   \n",
       "168      (None, 7, 7, 512)    -1.0    512.0  (1, 1)          9.0   \n",
       "169      (None, 7, 7, 512)    -1.0     -1.0      -1         -1.0   \n",
       "170      (None, 7, 7, 512)    -1.0     -1.0      -1         -1.0   \n",
       "171     (None, 7, 7, 2048)    -1.0   2048.0  (1, 1)          1.0   \n",
       "172     (None, 7, 7, 2048)    -1.0     -1.0      -1         -1.0   \n",
       "173     (None, 7, 7, 2048)    -1.0     -1.0      -1         -1.0   \n",
       "174     (None, 7, 7, 2048)    -1.0     -1.0      -1         -1.0   \n",
       "175           (None, 2048)    -1.0     -1.0      -1         -1.0   \n",
       "176           (None, 1000)  1000.0     -1.0      -1         -1.0   \n",
       "\n",
       "     activation_linear  activation_relu  activation_softmax  ...  \\\n",
       "0                    0                0                   0  ...   \n",
       "1                    0                0                   0  ...   \n",
       "2                    1                0                   0  ...   \n",
       "3                    0                0                   0  ...   \n",
       "4                    0                1                   0  ...   \n",
       "5                    0                0                   0  ...   \n",
       "6                    0                0                   0  ...   \n",
       "7                    1                0                   0  ...   \n",
       "8                    0                0                   0  ...   \n",
       "9                    0                1                   0  ...   \n",
       "10                   1                0                   0  ...   \n",
       "11                   0                0                   0  ...   \n",
       "12                   0                1                   0  ...   \n",
       "13                   1                0                   0  ...   \n",
       "14                   1                0                   0  ...   \n",
       "15                   0                0                   0  ...   \n",
       "16                   0                0                   0  ...   \n",
       "17                   0                0                   0  ...   \n",
       "18                   0                1                   0  ...   \n",
       "19                   1                0                   0  ...   \n",
       "20                   0                0                   0  ...   \n",
       "21                   0                1                   0  ...   \n",
       "22                   1                0                   0  ...   \n",
       "23                   0                0                   0  ...   \n",
       "24                   0                1                   0  ...   \n",
       "25                   1                0                   0  ...   \n",
       "26                   0                0                   0  ...   \n",
       "27                   0                0                   0  ...   \n",
       "28                   0                1                   0  ...   \n",
       "29                   1                0                   0  ...   \n",
       "..                 ...              ...                 ...  ...   \n",
       "147                  0                0                   0  ...   \n",
       "148                  0                1                   0  ...   \n",
       "149                  1                0                   0  ...   \n",
       "150                  1                0                   0  ...   \n",
       "151                  0                0                   0  ...   \n",
       "152                  0                0                   0  ...   \n",
       "153                  0                0                   0  ...   \n",
       "154                  0                1                   0  ...   \n",
       "155                  1                0                   0  ...   \n",
       "156                  0                0                   0  ...   \n",
       "157                  0                1                   0  ...   \n",
       "158                  1                0                   0  ...   \n",
       "159                  0                0                   0  ...   \n",
       "160                  0                1                   0  ...   \n",
       "161                  1                0                   0  ...   \n",
       "162                  0                0                   0  ...   \n",
       "163                  0                0                   0  ...   \n",
       "164                  0                1                   0  ...   \n",
       "165                  1                0                   0  ...   \n",
       "166                  0                0                   0  ...   \n",
       "167                  0                1                   0  ...   \n",
       "168                  1                0                   0  ...   \n",
       "169                  0                0                   0  ...   \n",
       "170                  0                1                   0  ...   \n",
       "171                  1                0                   0  ...   \n",
       "172                  0                0                   0  ...   \n",
       "173                  0                0                   0  ...   \n",
       "174                  0                1                   0  ...   \n",
       "175                  0                0                   0  ...   \n",
       "176                  0                0                   1  ...   \n",
       "\n",
       "     activation_elu  activation_softplus  activation_softsign  \\\n",
       "0               0.0                  0.0                  0.0   \n",
       "1              -1.0                 -1.0                 -1.0   \n",
       "2              -1.0                 -1.0                 -1.0   \n",
       "3              -1.0                 -1.0                 -1.0   \n",
       "4              -1.0                 -1.0                 -1.0   \n",
       "5              -1.0                 -1.0                 -1.0   \n",
       "6              -1.0                 -1.0                 -1.0   \n",
       "7              -1.0                 -1.0                 -1.0   \n",
       "8              -1.0                 -1.0                 -1.0   \n",
       "9              -1.0                 -1.0                 -1.0   \n",
       "10             -1.0                 -1.0                 -1.0   \n",
       "11             -1.0                 -1.0                 -1.0   \n",
       "12             -1.0                 -1.0                 -1.0   \n",
       "13             -1.0                 -1.0                 -1.0   \n",
       "14             -1.0                 -1.0                 -1.0   \n",
       "15             -1.0                 -1.0                 -1.0   \n",
       "16             -1.0                 -1.0                 -1.0   \n",
       "17             -1.0                 -1.0                 -1.0   \n",
       "18             -1.0                 -1.0                 -1.0   \n",
       "19             -1.0                 -1.0                 -1.0   \n",
       "20             -1.0                 -1.0                 -1.0   \n",
       "21             -1.0                 -1.0                 -1.0   \n",
       "22             -1.0                 -1.0                 -1.0   \n",
       "23             -1.0                 -1.0                 -1.0   \n",
       "24             -1.0                 -1.0                 -1.0   \n",
       "25             -1.0                 -1.0                 -1.0   \n",
       "26             -1.0                 -1.0                 -1.0   \n",
       "27             -1.0                 -1.0                 -1.0   \n",
       "28             -1.0                 -1.0                 -1.0   \n",
       "29             -1.0                 -1.0                 -1.0   \n",
       "..              ...                  ...                  ...   \n",
       "147            -1.0                 -1.0                 -1.0   \n",
       "148            -1.0                 -1.0                 -1.0   \n",
       "149            -1.0                 -1.0                 -1.0   \n",
       "150            -1.0                 -1.0                 -1.0   \n",
       "151            -1.0                 -1.0                 -1.0   \n",
       "152            -1.0                 -1.0                 -1.0   \n",
       "153            -1.0                 -1.0                 -1.0   \n",
       "154            -1.0                 -1.0                 -1.0   \n",
       "155            -1.0                 -1.0                 -1.0   \n",
       "156            -1.0                 -1.0                 -1.0   \n",
       "157            -1.0                 -1.0                 -1.0   \n",
       "158            -1.0                 -1.0                 -1.0   \n",
       "159            -1.0                 -1.0                 -1.0   \n",
       "160            -1.0                 -1.0                 -1.0   \n",
       "161            -1.0                 -1.0                 -1.0   \n",
       "162            -1.0                 -1.0                 -1.0   \n",
       "163            -1.0                 -1.0                 -1.0   \n",
       "164            -1.0                 -1.0                 -1.0   \n",
       "165            -1.0                 -1.0                 -1.0   \n",
       "166            -1.0                 -1.0                 -1.0   \n",
       "167            -1.0                 -1.0                 -1.0   \n",
       "168            -1.0                 -1.0                 -1.0   \n",
       "169            -1.0                 -1.0                 -1.0   \n",
       "170            -1.0                 -1.0                 -1.0   \n",
       "171            -1.0                 -1.0                 -1.0   \n",
       "172            -1.0                 -1.0                 -1.0   \n",
       "173            -1.0                 -1.0                 -1.0   \n",
       "174            -1.0                 -1.0                 -1.0   \n",
       "175            -1.0                 -1.0                 -1.0   \n",
       "176            -1.0                 -1.0                 -1.0   \n",
       "\n",
       "     activation_tanh  activation_sigmoid  activation_hard_sigmoid  \\\n",
       "0                0.0                 0.0                      0.0   \n",
       "1               -1.0                -1.0                     -1.0   \n",
       "2               -1.0                -1.0                     -1.0   \n",
       "3               -1.0                -1.0                     -1.0   \n",
       "4               -1.0                -1.0                     -1.0   \n",
       "5               -1.0                -1.0                     -1.0   \n",
       "6               -1.0                -1.0                     -1.0   \n",
       "7               -1.0                -1.0                     -1.0   \n",
       "8               -1.0                -1.0                     -1.0   \n",
       "9               -1.0                -1.0                     -1.0   \n",
       "10              -1.0                -1.0                     -1.0   \n",
       "11              -1.0                -1.0                     -1.0   \n",
       "12              -1.0                -1.0                     -1.0   \n",
       "13              -1.0                -1.0                     -1.0   \n",
       "14              -1.0                -1.0                     -1.0   \n",
       "15              -1.0                -1.0                     -1.0   \n",
       "16              -1.0                -1.0                     -1.0   \n",
       "17              -1.0                -1.0                     -1.0   \n",
       "18              -1.0                -1.0                     -1.0   \n",
       "19              -1.0                -1.0                     -1.0   \n",
       "20              -1.0                -1.0                     -1.0   \n",
       "21              -1.0                -1.0                     -1.0   \n",
       "22              -1.0                -1.0                     -1.0   \n",
       "23              -1.0                -1.0                     -1.0   \n",
       "24              -1.0                -1.0                     -1.0   \n",
       "25              -1.0                -1.0                     -1.0   \n",
       "26              -1.0                -1.0                     -1.0   \n",
       "27              -1.0                -1.0                     -1.0   \n",
       "28              -1.0                -1.0                     -1.0   \n",
       "29              -1.0                -1.0                     -1.0   \n",
       "..               ...                 ...                      ...   \n",
       "147             -1.0                -1.0                     -1.0   \n",
       "148             -1.0                -1.0                     -1.0   \n",
       "149             -1.0                -1.0                     -1.0   \n",
       "150             -1.0                -1.0                     -1.0   \n",
       "151             -1.0                -1.0                     -1.0   \n",
       "152             -1.0                -1.0                     -1.0   \n",
       "153             -1.0                -1.0                     -1.0   \n",
       "154             -1.0                -1.0                     -1.0   \n",
       "155             -1.0                -1.0                     -1.0   \n",
       "156             -1.0                -1.0                     -1.0   \n",
       "157             -1.0                -1.0                     -1.0   \n",
       "158             -1.0                -1.0                     -1.0   \n",
       "159             -1.0                -1.0                     -1.0   \n",
       "160             -1.0                -1.0                     -1.0   \n",
       "161             -1.0                -1.0                     -1.0   \n",
       "162             -1.0                -1.0                     -1.0   \n",
       "163             -1.0                -1.0                     -1.0   \n",
       "164             -1.0                -1.0                     -1.0   \n",
       "165             -1.0                -1.0                     -1.0   \n",
       "166             -1.0                -1.0                     -1.0   \n",
       "167             -1.0                -1.0                     -1.0   \n",
       "168             -1.0                -1.0                     -1.0   \n",
       "169             -1.0                -1.0                     -1.0   \n",
       "170             -1.0                -1.0                     -1.0   \n",
       "171             -1.0                -1.0                     -1.0   \n",
       "172             -1.0                -1.0                     -1.0   \n",
       "173             -1.0                -1.0                     -1.0   \n",
       "174             -1.0                -1.0                     -1.0   \n",
       "175             -1.0                -1.0                     -1.0   \n",
       "176             -1.0                -1.0                     -1.0   \n",
       "\n",
       "     activation_exponential  input_size  output_size  stride_size  \n",
       "0                       0.0      150528       150528         -1.0  \n",
       "1                      -1.0      150528       158700         -1.0  \n",
       "2                      -1.0      158700       802816          4.0  \n",
       "3                      -1.0      802816       802816         -1.0  \n",
       "4                      -1.0      802816       802816         -1.0  \n",
       "5                      -1.0      802816       831744         -1.0  \n",
       "6                      -1.0      831744       200704          4.0  \n",
       "7                      -1.0      200704       200704          1.0  \n",
       "8                      -1.0      200704       200704         -1.0  \n",
       "9                      -1.0      200704       200704         -1.0  \n",
       "10                     -1.0      200704       200704          1.0  \n",
       "11                     -1.0      200704       200704         -1.0  \n",
       "12                     -1.0      200704       200704         -1.0  \n",
       "13                     -1.0      200704       802816          1.0  \n",
       "14                     -1.0      200704       802816          1.0  \n",
       "15                     -1.0      802816       802816         -1.0  \n",
       "16                     -1.0      802816       802816         -1.0  \n",
       "17                     -1.0     1605632       802816         -1.0  \n",
       "18                     -1.0      802816       802816         -1.0  \n",
       "19                     -1.0      802816       200704          1.0  \n",
       "20                     -1.0      200704       200704         -1.0  \n",
       "21                     -1.0      200704       200704         -1.0  \n",
       "22                     -1.0      200704       200704          1.0  \n",
       "23                     -1.0      200704       200704         -1.0  \n",
       "24                     -1.0      200704       200704         -1.0  \n",
       "25                     -1.0      200704       802816          1.0  \n",
       "26                     -1.0      802816       802816         -1.0  \n",
       "27                     -1.0     1605632       802816         -1.0  \n",
       "28                     -1.0      802816       802816         -1.0  \n",
       "29                     -1.0      802816       200704          1.0  \n",
       "..                      ...         ...          ...          ...  \n",
       "147                    -1.0       25088        25088         -1.0  \n",
       "148                    -1.0       25088        25088         -1.0  \n",
       "149                    -1.0       25088       100352          1.0  \n",
       "150                    -1.0      200704       100352          4.0  \n",
       "151                    -1.0      100352       100352         -1.0  \n",
       "152                    -1.0      100352       100352         -1.0  \n",
       "153                    -1.0      200704       100352         -1.0  \n",
       "154                    -1.0      100352       100352         -1.0  \n",
       "155                    -1.0      100352        25088          1.0  \n",
       "156                    -1.0       25088        25088         -1.0  \n",
       "157                    -1.0       25088        25088         -1.0  \n",
       "158                    -1.0       25088        25088          1.0  \n",
       "159                    -1.0       25088        25088         -1.0  \n",
       "160                    -1.0       25088        25088         -1.0  \n",
       "161                    -1.0       25088       100352          1.0  \n",
       "162                    -1.0      100352       100352         -1.0  \n",
       "163                    -1.0      200704       100352         -1.0  \n",
       "164                    -1.0      100352       100352         -1.0  \n",
       "165                    -1.0      100352        25088          1.0  \n",
       "166                    -1.0       25088        25088         -1.0  \n",
       "167                    -1.0       25088        25088         -1.0  \n",
       "168                    -1.0       25088        25088          1.0  \n",
       "169                    -1.0       25088        25088         -1.0  \n",
       "170                    -1.0       25088        25088         -1.0  \n",
       "171                    -1.0       25088       100352          1.0  \n",
       "172                    -1.0      100352       100352         -1.0  \n",
       "173                    -1.0      200704       100352         -1.0  \n",
       "174                    -1.0      100352       100352         -1.0  \n",
       "175                    -1.0      100352         2048         -1.0  \n",
       "176                    -1.0        2048         1000         -1.0  \n",
       "\n",
       "[177 rows x 22 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean(get_layer_features(test_model), inference=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['nn_regressors/rnn_mem.joblib']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from joblib import dump, load\n",
    "dump({\n",
    "    'model': cnn_ms_rf,\n",
    "    'train_data': cleaned,\n",
    "}, 'nn_regressors/cnn_cpu.joblib') \n",
    "dump({\n",
    "    'model': cnn_mem_rf,\n",
    "    'train_data': cleaned,\n",
    "}, 'nn_regressors/cnn_mem.joblib') \n",
    "\n",
    "dump({\n",
    "    'model': rnn_ms_rf,\n",
    "    'train_data': rnn_data,\n",
    "}, 'nn_regressors/rnn_cpu.joblib') \n",
    "dump({\n",
    "    'model': rnn_mem_rf,\n",
    "    'train_data': rnn_data,\n",
    "}, 'nn_regressors/rnn_mem.joblib') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
